{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 1 слой 26 нейронов (сначала передать туда матрицу декодера, потом инициализировать рандомно) \n",
    "2. 2 слоя по 31 нейрона\n",
    "3. \n",
    "\n",
    "1. бинарный вход перевести в вещественный в [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "output_extras": [
      {
       "item_id": 5
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16335,
     "status": "ok",
     "timestamp": 1520077372397,
     "user": {
      "displayName": "Антон Архипов",
      "photoUrl": "//lh3.googleusercontent.com/-Q8cmDwP37qY/AAAAAAAAAAI/AAAAAAAAACQ/pXXJKjxusBQ/s50-c-k-no/photo.jpg",
      "userId": "115500452992359709286"
     },
     "user_tz": -180
    },
    "id": "jLgugF4GUq62",
    "outputId": "a7d13aa5-8cb1-4221-e872-0d8a5579af13"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "# !apt-get update -qq 2>&1 > /dev/null\n",
    "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# creds = GoogleCredentials.get_application_default()\n",
    "# import getpass\n",
    "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "# vcode = getpass.getpass()\n",
    "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1520077377725,
     "user": {
      "displayName": "Антон Архипов",
      "photoUrl": "//lh3.googleusercontent.com/-Q8cmDwP37qY/AAAAAAAAAAI/AAAAAAAAACQ/pXXJKjxusBQ/s50-c-k-no/photo.jpg",
      "userId": "115500452992359709286"
     },
     "user_tz": -180
    },
    "id": "-Up-zUgBVOr6",
    "outputId": "9a8bd1d5-78a7-42a6-cc4c-2f4098480642"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p drive\n",
    "# !google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pAb2ZFhFS2C2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import models\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "# from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from __future__ import absolute_import\n",
    "\n",
    "# os.chdir(\"/content/drive/Hamming\")\n",
    "# sys.path.append(\"Hamming\")\n",
    "# import functions as f\n",
    "# import model_lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1520077416786,
     "user": {
      "displayName": "Антон Архипов",
      "photoUrl": "//lh3.googleusercontent.com/-Q8cmDwP37qY/AAAAAAAAAAI/AAAAAAAAACQ/pXXJKjxusBQ/s50-c-k-no/photo.jpg",
      "userId": "115500452992359709286"
     },
     "user_tz": -180
    },
    "id": "GLXacC51fWKw",
    "outputId": "0af802ac-64f6-433e-eec8-48a644e8c340"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.hd5\tfunctions.py\t     model_lib.py  visualisation.ipynb\r\n",
      "dataset_files\thamming-codes.ipynb  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RsJUBrPieZ2a"
   },
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F_zimhx7Z8wu"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = './dataset_files/hamming.txt'  # \"/content/drive/Hamming/dataset_files/hamming.txt\"\n",
    "\n",
    "COLUMN_NAMES = ['id', 'plainword', 'codeword', \n",
    "                'id_error', 'bin_error', 'defective_codeword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qOJTCmD_Z-Zz"
   },
   "outputs": [],
   "source": [
    "def hamming_distance(first: str, second: str) -> int:\n",
    "    return len([1 for (x, y) in zip(first, second) if x != y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aAYas-44aA_h"
   },
   "outputs": [],
   "source": [
    "def loss_hamming(y, y_pred):  # , w):\n",
    "    return sum(1 for (a,b) in zip(y, y_pred) if y != y_pred) / y.shape[0] # надо ли делить????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nIyG2tDEaDHn"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv(TRAIN_PATH, sep=';', names=COLUMN_NAMES)\n",
    "\n",
    "    # make features\n",
    "#     data['dec_defective_codeword'] = data['defective_codeword'][:].apply(lambda x: int(x, 2))\n",
    "#     for j in range(len(data['defective_codeword'][0])):\n",
    "#         data['bin_' + str(j)] = data['defective_codeword'][:].apply(lambda x: int(x[j]))\n",
    "#     data['dec_plainword'] = data['plainword'][:].apply(lambda x: int(x, 2))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dqSfcsGwDOSF"
   },
   "outputs": [],
   "source": [
    "def make_features():\n",
    "    data['dec_defective_codeword'] = data['defective_codeword'][:].apply(lambda x: int(x, 2))\n",
    "\n",
    "    for j in range(len(data['codeword'][0])):\n",
    "        data['cod_' + str(j)] = data['codeword'][:].apply(lambda x: int(x[j]))\n",
    "\n",
    "    for j in range(len(data['defective_codeword'][0])):\n",
    "        data['def_' + str(j)] = data['defective_codeword'][:].apply(lambda x: int(x[j]))\n",
    "\n",
    "    for j in range(len(data['bin_error'][0])):\n",
    "        data['mask_' + str(j)] = data['bin_error'][:].apply(lambda x: int(x[j]))\n",
    "        \n",
    "    for j in range(len(data['plainword'][0])):\n",
    "        data['pln_' + str(j)] = data['plainword'][:].apply(lambda x: int(x[j]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MV-N_rg3aHeD"
   },
   "outputs": [],
   "source": [
    "def split_data(test_size):\n",
    "    train_data_defective, test_data_defective, train_labels_defective, test_labels_defective = \\\n",
    "    model_selection.train_test_split(data.loc[:, 'def_0':'def_30'], \n",
    "                                     data.loc[:, 'mask_0':'pln_25'], \n",
    "                                        test_size = test_size)\n",
    "    \n",
    "    train_data_plain, test_data_plain, train_labels_plain, test_labels_plain = \\\n",
    "    model_selection.train_test_split(data.loc[:, 'cod_0':'cod_30'], \n",
    "                                     data.loc[:, 'mask_0':'pln_25'], \n",
    "                                        test_size = test_size)\n",
    "    \n",
    "    train_data = np.vstack((np.array(train_data_defective), np.array(train_data_defective)))\n",
    "    test_data = np.vstack((np.array(test_data_defective), np.array(test_data_defective)))\n",
    "    train_labels = np.vstack((np.array(train_labels_defective), np.array(train_labels_defective)))\n",
    "    test_labels = np.vstack((np.array(test_labels_defective), np.array(test_labels_defective)))\n",
    "    \n",
    "    return train_data, test_data, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6QQ0swyyhrHK"
   },
   "outputs": [],
   "source": [
    "data = load_data() #pd.read_csv(functions.TRAIN_PATH, sep=';', names = functions.COLUMN_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LIU803RY5yWe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.15 s, sys: 160 ms, total: 4.31 s\n",
      "Wall time: 4.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "make_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 253,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1520077460673,
     "user": {
      "displayName": "Антон Архипов",
      "photoUrl": "//lh3.googleusercontent.com/-Q8cmDwP37qY/AAAAAAAAAAI/AAAAAAAAACQ/pXXJKjxusBQ/s50-c-k-no/photo.jpg",
      "userId": "115500452992359709286"
     },
     "user_tz": -180
    },
    "id": "tqpQciG7r_Ql",
    "outputId": "875fadba-9b52-4f57-ecdc-f1f2e4aee561"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>plainword</th>\n",
       "      <th>codeword</th>\n",
       "      <th>id_error</th>\n",
       "      <th>bin_error</th>\n",
       "      <th>defective_codeword</th>\n",
       "      <th>dec_defective_codeword</th>\n",
       "      <th>cod_0</th>\n",
       "      <th>cod_1</th>\n",
       "      <th>cod_2</th>\n",
       "      <th>...</th>\n",
       "      <th>pln_16</th>\n",
       "      <th>pln_17</th>\n",
       "      <th>pln_18</th>\n",
       "      <th>pln_19</th>\n",
       "      <th>pln_20</th>\n",
       "      <th>pln_21</th>\n",
       "      <th>pln_22</th>\n",
       "      <th>pln_23</th>\n",
       "      <th>pln_24</th>\n",
       "      <th>pln_25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10110000001111101100000100</td>\n",
       "      <td>0001001100000011111011000001000</td>\n",
       "      <td>8</td>\n",
       "      <td>0000000010000000000000000000000</td>\n",
       "      <td>0001001110000011111011000001000</td>\n",
       "      <td>163706376</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00101011010000101000111100</td>\n",
       "      <td>1001101010110100001010001111000</td>\n",
       "      <td>17</td>\n",
       "      <td>0000000000000000010000000000000</td>\n",
       "      <td>1001101010110100011010001111000</td>\n",
       "      <td>1297757304</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10010100110111111111111100</td>\n",
       "      <td>1101100101001101111111111111000</td>\n",
       "      <td>18</td>\n",
       "      <td>0000000000000000001000000000000</td>\n",
       "      <td>1101100101001101110111111111000</td>\n",
       "      <td>1822879736</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00011000001101000100010111</td>\n",
       "      <td>1011100110000011010001000101110</td>\n",
       "      <td>13</td>\n",
       "      <td>0000000000000100000000000000000</td>\n",
       "      <td>1011100110000111010001000101110</td>\n",
       "      <td>1556324910</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>10011101101000001100111011</td>\n",
       "      <td>0011000111011010000011001110110</td>\n",
       "      <td>19</td>\n",
       "      <td>0000000000000000000100000000000</td>\n",
       "      <td>0011000111011010000111001110110</td>\n",
       "      <td>418188918</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   plainword                         codeword  id_error  \\\n",
       "0   0  10110000001111101100000100  0001001100000011111011000001000         8   \n",
       "1   1  00101011010000101000111100  1001101010110100001010001111000        17   \n",
       "2   2  10010100110111111111111100  1101100101001101111111111111000        18   \n",
       "3   3  00011000001101000100010111  1011100110000011010001000101110        13   \n",
       "4   4  10011101101000001100111011  0011000111011010000011001110110        19   \n",
       "\n",
       "                         bin_error               defective_codeword  \\\n",
       "0  0000000010000000000000000000000  0001001110000011111011000001000   \n",
       "1  0000000000000000010000000000000  1001101010110100011010001111000   \n",
       "2  0000000000000000001000000000000  1101100101001101110111111111000   \n",
       "3  0000000000000100000000000000000  1011100110000111010001000101110   \n",
       "4  0000000000000000000100000000000  0011000111011010000111001110110   \n",
       "\n",
       "   dec_defective_codeword  cod_0  cod_1  cod_2   ...    pln_16  pln_17  \\\n",
       "0               163706376      0      0      0   ...         1       1   \n",
       "1              1297757304      1      0      0   ...         1       0   \n",
       "2              1822879736      1      1      0   ...         1       1   \n",
       "3              1556324910      1      0      1   ...         0       1   \n",
       "4               418188918      0      0      1   ...         1       1   \n",
       "\n",
       "   pln_18  pln_19  pln_20  pln_21  pln_22  pln_23  pln_24  pln_25  \n",
       "0       0       0       0       0       0       1       0       0  \n",
       "1       0       0       1       1       1       1       0       0  \n",
       "2       1       1       1       1       1       1       0       0  \n",
       "3       0       0       0       1       0       1       1       1  \n",
       "4       0       0       1       1       1       0       1       1  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nikwGJe7OP9V"
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = split_data(test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "decoder = []\n",
    "with open('./dataset_files/h.txt') as f:\n",
    "    decoder = pd.read_csv(f, header=None, names=['h'], dtype=str) #, sep='\\n')\n",
    "for j in range(len(decoder['h'][0])):\n",
    "    decoder['bin_' + str(j)] = decoder['h'][:].apply(lambda x: int(x[j]))\n",
    "decoder = decoder.drop(['h'], axis=1)\n",
    "decoder_np = decoder.as_matrix()\n",
    "print(decoder_np[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(31, input_shape=(31,), \n",
    "#                 weights=decoder_np, \n",
    "                activation='relu', name='d1'))\n",
    "# model.add(Dense(100, activation='relu', name='d2'))\n",
    "# model.add(Dense(31, activation='softmax', name='d3'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy', # энтропия Шелдона / бинарная\n",
    "              metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MCP = ModelCheckpoint('best_model.hd5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels_categor = to_categorical(train_labels, num_classes=31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model.fit(x=train_data, y=train_labels_categor, validation_split=0.2,  shuffle=True, epochs=100, callbacks=[MCP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM;\n",
    "\n",
    "матринчая нейронная сеть, каждый слой - логические ячейки xor...\n",
    "метрика хэмминга\n",
    "\n",
    "подавать и правильные и неправильные\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "поставить керас\n",
    "from keras... import\n",
    "inp = Input(shape=(31,))\n",
    "x = Dense(128, activation='elu')(inp)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "test = Dense(.....)(x)\n",
    "\n",
    "m = Dense(26, activation='пороговая функция типа step которой уже нет 'sigmoid')(x)\n",
    "\n",
    "test = Dense(...)(test)\n",
    "test= Dense(31....)(test)\n",
    "m = Concatinate()([test,m])\n",
    "          \n",
    "model = Model(inp, m, 'm')\n",
    "model.compile() , summary, fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "метки = бинарный код ошибки + информационное слово\n",
    "\n",
    "лосс - бинарная кросс энтропия\n",
    "оптимизатор - Адам\n",
    "стартовая точноесть - 1е-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73400 samples, validate on 18350 samples\n",
      "Epoch 1/100\n",
      "73400/73400 [==============================] - 7s 94us/step - loss: 0.3898 - acc: 0.9442 - val_loss: 0.3617 - val_acc: 0.9593\n",
      "Epoch 2/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3618 - acc: 0.9592 - val_loss: 0.3614 - val_acc: 0.9592\n",
      "Epoch 3/100\n",
      "73400/73400 [==============================] - 7s 100us/step - loss: 0.3616 - acc: 0.9591 - val_loss: 0.3612 - val_acc: 0.9591\n",
      "Epoch 4/100\n",
      "73400/73400 [==============================] - 7s 95us/step - loss: 0.3613 - acc: 0.9592 - val_loss: 0.3604 - val_acc: 0.9594\n",
      "Epoch 5/100\n",
      "73400/73400 [==============================] - 7s 97us/step - loss: 0.3611 - acc: 0.9592 - val_loss: 0.3613 - val_acc: 0.9591\n",
      "Epoch 6/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3608 - acc: 0.9592 - val_loss: 0.3611 - val_acc: 0.9594\n",
      "Epoch 7/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3606 - acc: 0.9592 - val_loss: 0.3609 - val_acc: 0.9594\n",
      "Epoch 8/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3605 - acc: 0.9593 - val_loss: 0.3601 - val_acc: 0.9592\n",
      "Epoch 9/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3602 - acc: 0.9592 - val_loss: 0.3601 - val_acc: 0.9594\n",
      "Epoch 10/100\n",
      "73400/73400 [==============================] - 6s 84us/step - loss: 0.3600 - acc: 0.9592 - val_loss: 0.3606 - val_acc: 0.9591\n",
      "Epoch 11/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3599 - acc: 0.9594 - val_loss: 0.3610 - val_acc: 0.9594\n",
      "Epoch 12/100\n",
      "73400/73400 [==============================] - 7s 93us/step - loss: 0.3597 - acc: 0.9594 - val_loss: 0.3595 - val_acc: 0.9595\n",
      "Epoch 13/100\n",
      "73400/73400 [==============================] - 7s 94us/step - loss: 0.3595 - acc: 0.9594 - val_loss: 0.3606 - val_acc: 0.9595\n",
      "Epoch 14/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3594 - acc: 0.9594 - val_loss: 0.3599 - val_acc: 0.9592\n",
      "Epoch 15/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3593 - acc: 0.9594 - val_loss: 0.3603 - val_acc: 0.9595\n",
      "Epoch 16/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3591 - acc: 0.9594 - val_loss: 0.3600 - val_acc: 0.9595\n",
      "Epoch 17/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3590 - acc: 0.9594 - val_loss: 0.3611 - val_acc: 0.9595\n",
      "Epoch 18/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3589 - acc: 0.9594 - val_loss: 0.3599 - val_acc: 0.9595\n",
      "Epoch 19/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3588 - acc: 0.9595 - val_loss: 0.3597 - val_acc: 0.9595\n",
      "Epoch 20/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3587 - acc: 0.9595 - val_loss: 0.3598 - val_acc: 0.9594\n",
      "Epoch 21/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3586 - acc: 0.9595 - val_loss: 0.3599 - val_acc: 0.9594\n",
      "Epoch 22/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3585 - acc: 0.9595 - val_loss: 0.3598 - val_acc: 0.9595\n",
      "Epoch 23/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3584 - acc: 0.9595 - val_loss: 0.3599 - val_acc: 0.9594\n",
      "Epoch 24/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3583 - acc: 0.9595 - val_loss: 0.3597 - val_acc: 0.9596\n",
      "Epoch 25/100\n",
      "73400/73400 [==============================] - 7s 96us/step - loss: 0.3582 - acc: 0.9595 - val_loss: 0.3596 - val_acc: 0.9595\n",
      "Epoch 26/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3581 - acc: 0.9595 - val_loss: 0.3591 - val_acc: 0.9593\n",
      "Epoch 27/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3580 - acc: 0.9595 - val_loss: 0.3599 - val_acc: 0.9594\n",
      "Epoch 28/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3580 - acc: 0.9595 - val_loss: 0.3595 - val_acc: 0.9595\n",
      "Epoch 29/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3578 - acc: 0.9595 - val_loss: 0.3596 - val_acc: 0.9597\n",
      "Epoch 30/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3578 - acc: 0.9595 - val_loss: 0.3595 - val_acc: 0.9595\n",
      "Epoch 31/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3577 - acc: 0.9595 - val_loss: 0.3596 - val_acc: 0.9596\n",
      "Epoch 32/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3576 - acc: 0.9596 - val_loss: 0.3600 - val_acc: 0.9596\n",
      "Epoch 33/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3576 - acc: 0.9596 - val_loss: 0.3598 - val_acc: 0.9597\n",
      "Epoch 34/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3575 - acc: 0.9596 - val_loss: 0.3594 - val_acc: 0.9596\n",
      "Epoch 35/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3574 - acc: 0.9596 - val_loss: 0.3593 - val_acc: 0.9597\n",
      "Epoch 36/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3573 - acc: 0.9596 - val_loss: 0.3592 - val_acc: 0.9596\n",
      "Epoch 37/100\n",
      "73400/73400 [==============================] - 6s 86us/step - loss: 0.3573 - acc: 0.9596 - val_loss: 0.3597 - val_acc: 0.9596\n",
      "Epoch 38/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3572 - acc: 0.9596 - val_loss: 0.3593 - val_acc: 0.9596\n",
      "Epoch 39/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3571 - acc: 0.9596 - val_loss: 0.3591 - val_acc: 0.9594\n",
      "Epoch 40/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3571 - acc: 0.9596 - val_loss: 0.3597 - val_acc: 0.9594\n",
      "Epoch 41/100\n",
      "73400/73400 [==============================] - 7s 95us/step - loss: 0.3570 - acc: 0.9596 - val_loss: 0.3593 - val_acc: 0.9596\n",
      "Epoch 42/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3570 - acc: 0.9597 - val_loss: 0.3594 - val_acc: 0.9595\n",
      "Epoch 43/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3569 - acc: 0.9596 - val_loss: 0.3596 - val_acc: 0.9596\n",
      "Epoch 44/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3569 - acc: 0.9596 - val_loss: 0.3590 - val_acc: 0.9597\n",
      "Epoch 45/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3568 - acc: 0.9596 - val_loss: 0.3599 - val_acc: 0.9595\n",
      "Epoch 46/100\n",
      "73400/73400 [==============================] - 6s 87us/step - loss: 0.3567 - acc: 0.9596 - val_loss: 0.3591 - val_acc: 0.9594\n",
      "Epoch 47/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3567 - acc: 0.9597 - val_loss: 0.3598 - val_acc: 0.9596\n",
      "Epoch 48/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3566 - acc: 0.9597 - val_loss: 0.3596 - val_acc: 0.9596\n",
      "Epoch 49/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3565 - acc: 0.9597 - val_loss: 0.3591 - val_acc: 0.9596\n",
      "Epoch 50/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3565 - acc: 0.9597 - val_loss: 0.3590 - val_acc: 0.9595\n",
      "Epoch 51/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3564 - acc: 0.9597 - val_loss: 0.3589 - val_acc: 0.9595\n",
      "Epoch 52/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3564 - acc: 0.9597 - val_loss: 0.3591 - val_acc: 0.9595\n",
      "Epoch 53/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3563 - acc: 0.9597 - val_loss: 0.3595 - val_acc: 0.9595\n",
      "Epoch 54/100\n",
      "73400/73400 [==============================] - 7s 93us/step - loss: 0.3562 - acc: 0.9597 - val_loss: 0.3594 - val_acc: 0.9596\n",
      "Epoch 55/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3562 - acc: 0.9597 - val_loss: 0.3588 - val_acc: 0.9596\n",
      "Epoch 56/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3562 - acc: 0.9597 - val_loss: 0.3595 - val_acc: 0.9595\n",
      "Epoch 57/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3561 - acc: 0.9597 - val_loss: 0.3594 - val_acc: 0.9596\n",
      "Epoch 58/100\n",
      "73400/73400 [==============================] - 7s 93us/step - loss: 0.3561 - acc: 0.9597 - val_loss: 0.3599 - val_acc: 0.9595\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73400/73400 [==============================] - 7s 101us/step - loss: 0.3560 - acc: 0.9597 - val_loss: 0.3593 - val_acc: 0.9596\n",
      "Epoch 60/100\n",
      "73400/73400 [==============================] - 7s 96us/step - loss: 0.3559 - acc: 0.9597 - val_loss: 0.3591 - val_acc: 0.9596\n",
      "Epoch 61/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3560 - acc: 0.9597 - val_loss: 0.3588 - val_acc: 0.9597\n",
      "Epoch 62/100\n",
      "73400/73400 [==============================] - 7s 95us/step - loss: 0.3559 - acc: 0.9597 - val_loss: 0.3590 - val_acc: 0.9596\n",
      "Epoch 63/100\n",
      "73400/73400 [==============================] - 7s 96us/step - loss: 0.3559 - acc: 0.9597 - val_loss: 0.3590 - val_acc: 0.9596\n",
      "Epoch 64/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3558 - acc: 0.9597 - val_loss: 0.3586 - val_acc: 0.9596\n",
      "Epoch 65/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3558 - acc: 0.9598 - val_loss: 0.3589 - val_acc: 0.9597\n",
      "Epoch 66/100\n",
      "73400/73400 [==============================] - 6s 86us/step - loss: 0.3558 - acc: 0.9598 - val_loss: 0.3596 - val_acc: 0.9596\n",
      "Epoch 67/100\n",
      "73400/73400 [==============================] - 7s 95us/step - loss: 0.3557 - acc: 0.9597 - val_loss: 0.3589 - val_acc: 0.9595\n",
      "Epoch 68/100\n",
      "73400/73400 [==============================] - 6s 85us/step - loss: 0.3557 - acc: 0.9597 - val_loss: 0.3588 - val_acc: 0.9596\n",
      "Epoch 69/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3556 - acc: 0.9597 - val_loss: 0.3587 - val_acc: 0.9596\n",
      "Epoch 70/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3556 - acc: 0.9598 - val_loss: 0.3589 - val_acc: 0.9597\n",
      "Epoch 71/100\n",
      "73400/73400 [==============================] - 7s 94us/step - loss: 0.3556 - acc: 0.9598 - val_loss: 0.3598 - val_acc: 0.9593\n",
      "Epoch 72/100\n",
      "73400/73400 [==============================] - 6s 84us/step - loss: 0.3555 - acc: 0.9598 - val_loss: 0.3588 - val_acc: 0.9596\n",
      "Epoch 73/100\n",
      "73400/73400 [==============================] - 7s 98us/step - loss: 0.3555 - acc: 0.9599 - val_loss: 0.3590 - val_acc: 0.9597\n",
      "Epoch 74/100\n",
      "73400/73400 [==============================] - 7s 96us/step - loss: 0.3555 - acc: 0.9598 - val_loss: 0.3592 - val_acc: 0.9593\n",
      "Epoch 75/100\n",
      "73400/73400 [==============================] - 7s 94us/step - loss: 0.3554 - acc: 0.9599 - val_loss: 0.3587 - val_acc: 0.9596\n",
      "Epoch 76/100\n",
      "73400/73400 [==============================] - 6s 86us/step - loss: 0.3554 - acc: 0.9598 - val_loss: 0.3591 - val_acc: 0.9596\n",
      "Epoch 77/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3554 - acc: 0.9598 - val_loss: 0.3590 - val_acc: 0.9595\n",
      "Epoch 78/100\n",
      "73400/73400 [==============================] - 7s 96us/step - loss: 0.3553 - acc: 0.9598 - val_loss: 0.3592 - val_acc: 0.9596\n",
      "Epoch 79/100\n",
      "73400/73400 [==============================] - 6s 85us/step - loss: 0.3553 - acc: 0.9598 - val_loss: 0.3588 - val_acc: 0.9597\n",
      "Epoch 80/100\n",
      "73400/73400 [==============================] - 7s 91us/step - loss: 0.3552 - acc: 0.9598 - val_loss: 0.3591 - val_acc: 0.9595\n",
      "Epoch 81/100\n",
      "73400/73400 [==============================] - 6s 85us/step - loss: 0.3552 - acc: 0.9598 - val_loss: 0.3589 - val_acc: 0.9597\n",
      "Epoch 82/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3552 - acc: 0.9598 - val_loss: 0.3592 - val_acc: 0.9597\n",
      "Epoch 83/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3552 - acc: 0.9599 - val_loss: 0.3588 - val_acc: 0.9595\n",
      "Epoch 84/100\n",
      "73400/73400 [==============================] - 7s 93us/step - loss: 0.3552 - acc: 0.9598 - val_loss: 0.3588 - val_acc: 0.9596\n",
      "Epoch 85/100\n",
      "73400/73400 [==============================] - 7s 94us/step - loss: 0.3551 - acc: 0.9598 - val_loss: 0.3590 - val_acc: 0.9596\n",
      "Epoch 86/100\n",
      "73400/73400 [==============================] - 6s 87us/step - loss: 0.3551 - acc: 0.9598 - val_loss: 0.3589 - val_acc: 0.9596\n",
      "Epoch 87/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3551 - acc: 0.9598 - val_loss: 0.3586 - val_acc: 0.9597\n",
      "Epoch 88/100\n",
      "73400/73400 [==============================] - 7s 90us/step - loss: 0.3550 - acc: 0.9598 - val_loss: 0.3592 - val_acc: 0.9596\n",
      "Epoch 89/100\n",
      "73400/73400 [==============================] - 7s 92us/step - loss: 0.3550 - acc: 0.9598 - val_loss: 0.3591 - val_acc: 0.9596\n",
      "Epoch 90/100\n",
      "73400/73400 [==============================] - 6s 87us/step - loss: 0.3549 - acc: 0.9598 - val_loss: 0.3588 - val_acc: 0.9594\n",
      "Epoch 91/100\n",
      "73400/73400 [==============================] - 6s 83us/step - loss: 0.3550 - acc: 0.9599 - val_loss: 0.3592 - val_acc: 0.9597\n",
      "Epoch 92/100\n",
      "73400/73400 [==============================] - 6s 85us/step - loss: 0.3549 - acc: 0.9598 - val_loss: 0.3592 - val_acc: 0.9597\n",
      "Epoch 93/100\n",
      "73400/73400 [==============================] - 6s 84us/step - loss: 0.3549 - acc: 0.9599 - val_loss: 0.3590 - val_acc: 0.9597\n",
      "Epoch 94/100\n",
      "73400/73400 [==============================] - 6s 86us/step - loss: 0.3549 - acc: 0.9599 - val_loss: 0.3593 - val_acc: 0.9596\n",
      "Epoch 95/100\n",
      "73400/73400 [==============================] - 6s 87us/step - loss: 0.3548 - acc: 0.9599 - val_loss: 0.3594 - val_acc: 0.9597\n",
      "Epoch 96/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3548 - acc: 0.9598 - val_loss: 0.3597 - val_acc: 0.9597\n",
      "Epoch 97/100\n",
      "73400/73400 [==============================] - 6s 87us/step - loss: 0.3548 - acc: 0.9599 - val_loss: 0.3595 - val_acc: 0.9596\n",
      "Epoch 98/100\n",
      "73400/73400 [==============================] - 6s 86us/step - loss: 0.3548 - acc: 0.9598 - val_loss: 0.3586 - val_acc: 0.9596\n",
      "Epoch 99/100\n",
      "73400/73400 [==============================] - 7s 89us/step - loss: 0.3548 - acc: 0.9598 - val_loss: 0.3591 - val_acc: 0.9597\n",
      "Epoch 100/100\n",
      "73400/73400 [==============================] - 6s 88us/step - loss: 0.3547 - acc: 0.9598 - val_loss: 0.3589 - val_acc: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdd66a47be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = Input(shape=(31,))\n",
    "x = Dense(128, activation='relu',  name='d1')(inp)\n",
    "x = Dense(128, activation='relu',  name='d2')(x)\n",
    "\n",
    "t = Dense(128, activation='elu', name='t1')(x)\n",
    "t = Dense(128, activation='relu', name='t2')(t)\n",
    "t = Dense(31, activation='relu', name='t3')(t)\n",
    "\n",
    "m = Dense(26, activation='sigmoid',  name='d3')(x)\n",
    "m = Concatenate()([t, m])\n",
    "\n",
    "model = Model(inp, m, 'm')\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='Adam')\n",
    "model.fit(x=train_data, y=train_labels, validation_split=0.2,  shuffle=True, epochs=100)#, callbacks=[MCP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "hamming-codes.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
