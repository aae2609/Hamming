{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17337,
     "status": "ok",
     "timestamp": 1523701899795,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "jLgugF4GUq62",
    "outputId": "833dd7df-86a3-47fe-a290-da9cc3d32309"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "# !add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "# !apt-get update -qq 2>&1 > /dev/null\n",
    "# !apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "# from google.colab import auth\n",
    "# auth.authenticate_user()\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# creds = GoogleCredentials.get_application_default()\n",
    "# import getpass\n",
    "# !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "# vcode = getpass.getpass()\n",
    "# !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "-Up-zUgBVOr6"
   },
   "outputs": [],
   "source": [
    "# !mkdir -p drive\n",
    "# !google-drive-ocamlfuse drive\n",
    "# !pip install -q keras\n",
    "# !pip install -q pandas\n",
    "# !pip install -q numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pAb2ZFhFS2C2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anton/.local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# cp ~/.config/google-chrome/Default/Cookies ~/.config/google-chrome/Default/Cookies.bak\n",
    "# cp ~/.config/google-chrome/Default/Cookies ~/.config/google-chrome/Default/Cookies.bak\n",
    "import os \n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv1D, Reshape, Flatten, MaxPooling1D, UpSampling1D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Input, Dense, Concatenate, CuDNNLSTM\n",
    "from keras.callbacks import History, ModelCheckpoint \n",
    "\n",
    "from iteration_utilities import flatten\n",
    "from sklearn import model_selection\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pAb2ZFhFS2C2"
   },
   "outputs": [],
   "source": [
    "# os.chdir(\"/content/drive/Hamming\")\n",
    "# sys.path.append(\"Hamming\")\n",
    "\n",
    "# import functions as f\n",
    "# import model_lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10324,
     "status": "ok",
     "timestamp": 1523701925502,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "GLXacC51fWKw",
    "outputId": "78820a97-2b84-4c7f-c4cb-1b40c495a6f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set code params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N, K_ = 31, 26\n",
    "N, K_= 16, 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save model, history, sub_datasets and pictures\n",
    "model_directory = 'model_checkpoints_stratificate_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F_zimhx7Z8wu"
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = './dataset_files/hamming_15_11.txt'\n",
    "TEST_PATH = './dataset_files/hamming_15_11_all.txt'\n",
    "\n",
    "COLUMN_NAMES = ['plainword', 'codeword', \n",
    "                'id_error', 'bin_error', 'defective_codeword']\n",
    "types = [str, str, int, str, str]\n",
    "types = dict(zip(COLUMN_NAMES, types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F_zimhx7Z8wu"
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path, sep=';', names=COLUMN_NAMES, dtype=types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "qOJTCmD_Z-Zz"
   },
   "outputs": [],
   "source": [
    "def hamming_distance(first: str, second: str) -> int:\n",
    "    return len([1 for (x, y) in zip(first, second) if x != y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dqSfcsGwDOSF"
   },
   "outputs": [],
   "source": [
    "def make_features():\n",
    "#     data['dec_defective_codeword'] = data['defective_codeword'][:].apply(lambda x: int(x, 2))\n",
    "\n",
    "    for j in range(len(data['codeword'][0])):\n",
    "        data['cod_' + str(j)] = data['codeword'][:].apply(lambda x: int(x[j]))\n",
    "\n",
    "    for j in range(len(data['defective_codeword'][0])):\n",
    "        data['def_' + str(j)] = data['defective_codeword'][:].apply(lambda x: int(x[j]))\n",
    "\n",
    "#     for j in range(len(data['bin_error'][0])):\n",
    "#         data['mask_' + str(j)] = data['bin_error'][:].apply(lambda x: int(x[j]))\n",
    "        \n",
    "    data['weight'] = 1\n",
    "    data.loc[data['codeword'] == data['defective_codeword'], 'weight'] = 10  ### 19\n",
    "    for j in range(len(data['plainword'][0])):\n",
    "        data['pln_' + str(j)] = data['plainword'][:].apply(lambda x: int(x[j]))\n",
    "    \n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratificate_split_data(test_size):\n",
    "    N1 = N + 1\n",
    "    to_test = round(N1 * test_size)  # count of lines from each \"pack\" \n",
    "    to_train = N1 - to_test\n",
    "\n",
    "    train_indices = [list(range(i*N1, i*N1 + to_train)) for i in range(2**K_)]\n",
    "    train_indices = list(flatten(train_indices))\n",
    "    test_indices = sorted(set(range(N1 * 2**K_)) - set(train_indices))\n",
    "    \n",
    "    train_data = data.loc[train_indices, 'def_0':'weight']\n",
    "    test_data = data.loc[test_indices, 'def_0':'weight']\n",
    "    \n",
    "    train_labels = data.loc[train_indices, 'cod_0':'cod_'+str(N-1)]\n",
    "    test_labels = data.loc[test_indices, 'cod_0':'cod_'+str(N-1)]\n",
    "    \n",
    "    train_weight = train_data.pop('weight')\n",
    "    test_data.drop(columns=['weight'], inplace=True)\n",
    "    return np.array(train_data), np.array(test_data), \\\n",
    "           np.array(train_labels), np.array(test_labels), \\\n",
    "           np.array(train_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "MV-N_rg3aHeD"
   },
   "outputs": [],
   "source": [
    "def split_data(test_size): \n",
    "    train_data, test_data, train_labels, test_labels = \\\n",
    "        model_selection.train_test_split(data.loc[:, 'def_0':'weight'], \n",
    "                                         data.loc[:, 'cod_0':'cod_'+str(N-1)], # 'mask_0':'pln_25' \n",
    "                                         test_size = test_size) \n",
    "    \n",
    "    train_weight = train_data.pop('weight')\n",
    "    test_data.drop(columns=['weight'], inplace=True)\n",
    "    return np.array(train_data), np.array(test_data), \\\n",
    "           np.array(train_labels), np.array(test_labels), \\\n",
    "           np.array(train_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_true, y_pred): \n",
    "    return -K.log(1 - K.abs(y_true - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploss(y_true, y_pred): \n",
    "    return K.exp(K.abs(y_true - y_pred)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aNQw6QTSU1rZ"
   },
   "outputs": [],
   "source": [
    "def probs_to_labels(predicted_probs):\n",
    "    return [int(x > 0.5) for x in predicted_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aNQw6QTSU1rZ"
   },
   "outputs": [],
   "source": [
    "def count_errors(y, y_pred):\n",
    "    count = 0\n",
    "    for i in range (0, N):\n",
    "        labelBit = y[i]\n",
    "        resultBit = y_pred[i]\n",
    "        if labelBit != resultBit:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 41551,
     "status": "ok",
     "timestamp": 1523702674149,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "97XAuvD0frXD",
    "outputId": "f2c45915-5eba-499a-8a0a-9be55ae075cb"
   },
   "outputs": [],
   "source": [
    "def get_error_stats(test_labels, y_pred):\n",
    "    errorStats = {0: 0}\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        resultArray = probs_to_labels(y_pred[i])\n",
    "        errorNum = count_errors(test_labels[i], resultArray)\n",
    "        if errorStats.get(errorNum) == None:\n",
    "            errorStats[errorNum] = 0\n",
    "        errorStats[errorNum] += 1\n",
    "    return errorStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aAYas-44aA_h"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(y, y_pred):\n",
    "    return sum(1 if np.array_equal(a, probs_to_labels(b)) else 0 for (a,b) in zip(y, y_pred)) / y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_fields(history, fields, save=False, num_dots_to_plot=-1):\n",
    "    # num_dots_to_plot == -1  => plot all\n",
    "\n",
    "    figsize_x = 20\n",
    "    figsize_y = 10\n",
    "    \n",
    "    if 'loss' in fields:\n",
    "        # summarize history for loss\n",
    "        plt.figure(figsize=(figsize_x, figsize_y))\n",
    "        plt.title('Функция потерь модели')\n",
    "        plt.plot(history['val_loss'][:num_dots_to_plot])\n",
    "        plt.plot(history['loss'][:num_dots_to_plot])\n",
    "        plt.ylabel('Функция потерь')\n",
    "        plt.xlabel('Номер эпохи')\n",
    "        plt.legend(['Валидация', 'Обучение'], loc='upper right')\n",
    "        if save:\n",
    "            plt.savefig(model_directory + 'model_loss.png')\n",
    "        plt.show()\n",
    "        \n",
    "    if 'accuracy' in fields:\n",
    "        # summarize history for accuracy\n",
    "        plt.figure(figsize=(figsize_x, figsize_y))\n",
    "        plt.title('Точность модели')\n",
    "        plt.plot(history['val_acc'][:num_dots_to_plot])\n",
    "        plt.plot(history['acc'][:num_dots_to_plot])\n",
    "        plt.ylabel('Точность')\n",
    "        plt.xlabel('Номер эпохи')\n",
    "        plt.legend(['Валидация', 'Обучение'], loc='lower right')\n",
    "        if save:\n",
    "            plt.savefig(model_directory + 'model_accuracy.png')\n",
    "        plt.show()\n",
    "        \n",
    "    if 'binary_accuracy' in fields:\n",
    "        # summarize history for binary accuracy\n",
    "        plt.figure(figsize=(figsize_x, figsize_y))\n",
    "        plt.title('Бинарная точность модели')\n",
    "        plt.plot(history['val_binary_accuracy'][:num_dots_to_plot])\n",
    "        plt.plot(history['binary_accuracy'][:num_dots_to_plot])\n",
    "        plt.ylabel('Бинарная точность')\n",
    "        plt.xlabel('Номер эпохи')\n",
    "        plt.legend(['Валидация', 'Обучение'], loc='lower right')\n",
    "        if save:\n",
    "            plt.savefig(model_directory + 'model_binary_accuracy.png')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RsJUBrPieZ2a"
   },
   "outputs": [],
   "source": [
    "# !git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34816, 5)\n",
      "(34816, 49)\n",
      "CPU times: user 737 ms, sys: 30.5 ms, total: 767 ms\n",
      "Wall time: 771 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = load_data(TEST_PATH)\n",
    "print(data.shape)\n",
    "make_features()\n",
    "print(data.shape)\n",
    "train_data, test_data, train_labels, test_labels, train_weight = stratificate_split_data(test_size=0.5)\n",
    "# train_data, test_data, train_labels, test_labels, train_weight = split_data(test_size=0.3)\n",
    "data.head()\n",
    "# del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11549,
     "status": "ok",
     "timestamp": 1523702485408,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "6QQ0swyyhrHK",
    "outputId": "c5969220-8397-4def-b1cc-72ca2a664ff9"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data = load_data(TRAIN_PATH)\n",
    "# # int_to_str()\n",
    "# print(data.shape)\n",
    "# make_features()\n",
    "# print(data.shape)\n",
    "# train_data, _, train_labels, _, train_weight = split_data(test_size=0.0001)\n",
    "\n",
    "# data = load_data(TEST_PATH)\n",
    "# # int_to_str()\n",
    "# print(data.shape)\n",
    "# make_features()\n",
    "# print(data.shape)\n",
    "# _, test_data, _, test_labels, _ = split_data(test_size=0.9999)\n",
    "# del(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()\n",
    "MCP = ModelCheckpoint(model_directory + 'model_epoch:{epoch:02d}_val_loss:{val_loss:.4f}.hdf5', \n",
    "                      monitor='val_loss', \n",
    "                      verbose=0, \n",
    "                      save_best_only=True, \n",
    "                      save_weights_only=False, \n",
    "                      mode='auto', \n",
    "                      period=10\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mul for N=16\n",
    "* 10 - 84%\n",
    "* 12 - 89%\n",
    "* 13 - 92%\n",
    "* 14 - 52%\n",
    "* 15 - 7х%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 741,
     "status": "ok",
     "timestamp": 1523701952025,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "9fktLgLrU1rL",
    "outputId": "aa6bca04-4ade-43ae-f306-cff058ffc24c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 208)               3536      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 208)               43472     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 208)               43472     \n",
      "_________________________________________________________________\n",
      "d3 (Dense)                   (None, 16)                3344      \n",
      "=================================================================\n",
      "Total params: 93,824\n",
      "Trainable params: 93,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from keras import models\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "inp = Input(shape=(N,))\n",
    "x = Dense(mul * N, activation='sigmoid', kernel_initializer = \"glorot_uniform\")(inp)\n",
    "x = Dense(mul * N, activation='sigmoid', kernel_initializer = \"glorot_uniform\")(x)\n",
    "x = Dense(mul * N, activation='sigmoid', kernel_initializer = \"glorot_uniform\")(x)\n",
    "# x = Dense(mul * N, activation='sigmoid', kernel_initializer = \"glorot_uniform\")(x)\n",
    "m = Dense(N, activation='sigmoid', name='d3')(x)\n",
    "\n",
    "model = Model(inp, m, 'm')\n",
    "model.compile(loss=exploss, optimizer='adam', metrics=['binary_accuracy', 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 171345,
     "status": "ok",
     "timestamp": 1523702134004,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "xKvAVKxUU1rN",
    "outputId": "5629fb29-33e0-4ded-e7be-ca6be77224d5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15667 samples, validate on 2765 samples\n",
      "Epoch 1/4000\n",
      "15667/15667 [==============================] - 0s 24us/step - loss: 0.6479 - binary_accuracy: 0.5159 - acc: 0.0990 - val_loss: 0.6420 - val_binary_accuracy: 0.5075 - val_acc: 0.0282\n",
      "Epoch 2/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.6278 - binary_accuracy: 0.6293 - acc: 0.0663 - val_loss: 0.6014 - val_binary_accuracy: 0.7425 - val_acc: 0.0235\n",
      "Epoch 3/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.5397 - binary_accuracy: 0.7644 - acc: 0.0973 - val_loss: 0.4736 - val_binary_accuracy: 0.7783 - val_acc: 0.0937\n",
      "Epoch 4/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.4121 - binary_accuracy: 0.8177 - acc: 0.1064 - val_loss: 0.3580 - val_binary_accuracy: 0.8566 - val_acc: 0.1089\n",
      "Epoch 5/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.3087 - binary_accuracy: 0.8854 - acc: 0.1016 - val_loss: 0.2714 - val_binary_accuracy: 0.9045 - val_acc: 0.0890\n",
      "Epoch 6/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.2381 - binary_accuracy: 0.9180 - acc: 0.0901 - val_loss: 0.2141 - val_binary_accuracy: 0.9284 - val_acc: 0.0828\n",
      "Epoch 7/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1890 - binary_accuracy: 0.9349 - acc: 0.0770 - val_loss: 0.1713 - val_binary_accuracy: 0.9382 - val_acc: 0.0807\n",
      "Epoch 8/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1583 - binary_accuracy: 0.9394 - acc: 0.0562 - val_loss: 0.1504 - val_binary_accuracy: 0.9396 - val_acc: 0.0474\n",
      "Epoch 9/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1432 - binary_accuracy: 0.9406 - acc: 0.0393 - val_loss: 0.1390 - val_binary_accuracy: 0.9404 - val_acc: 0.0488\n",
      "Epoch 10/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1337 - binary_accuracy: 0.9410 - acc: 0.0405 - val_loss: 0.1313 - val_binary_accuracy: 0.9407 - val_acc: 0.0514\n",
      "Epoch 11/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1268 - binary_accuracy: 0.9411 - acc: 0.0444 - val_loss: 0.1249 - val_binary_accuracy: 0.9408 - val_acc: 0.0546\n",
      "Epoch 12/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.1213 - binary_accuracy: 0.9411 - acc: 0.0491 - val_loss: 0.1201 - val_binary_accuracy: 0.9408 - val_acc: 0.0702\n",
      "Epoch 13/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1171 - binary_accuracy: 0.9411 - acc: 0.0570 - val_loss: 0.1164 - val_binary_accuracy: 0.9408 - val_acc: 0.0723\n",
      "Epoch 14/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1141 - binary_accuracy: 0.9411 - acc: 0.0658 - val_loss: 0.1138 - val_binary_accuracy: 0.9408 - val_acc: 0.0940\n",
      "Epoch 15/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1119 - binary_accuracy: 0.9411 - acc: 0.0804 - val_loss: 0.1120 - val_binary_accuracy: 0.9408 - val_acc: 0.1009\n",
      "Epoch 16/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1104 - binary_accuracy: 0.9411 - acc: 0.0921 - val_loss: 0.1107 - val_binary_accuracy: 0.9408 - val_acc: 0.1099\n",
      "Epoch 17/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1093 - binary_accuracy: 0.9411 - acc: 0.1049 - val_loss: 0.1097 - val_binary_accuracy: 0.9408 - val_acc: 0.1230\n",
      "Epoch 18/4000\n",
      "15667/15667 [==============================] - 0s 24us/step - loss: 0.1084 - binary_accuracy: 0.9411 - acc: 0.1130 - val_loss: 0.1089 - val_binary_accuracy: 0.9408 - val_acc: 0.1306\n",
      "Epoch 19/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1077 - binary_accuracy: 0.9411 - acc: 0.1121 - val_loss: 0.1082 - val_binary_accuracy: 0.9408 - val_acc: 0.1237\n",
      "Epoch 20/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1071 - binary_accuracy: 0.9411 - acc: 0.1148 - val_loss: 0.1077 - val_binary_accuracy: 0.9408 - val_acc: 0.1363\n",
      "Epoch 21/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1065 - binary_accuracy: 0.9411 - acc: 0.1152 - val_loss: 0.1072 - val_binary_accuracy: 0.9408 - val_acc: 0.1284\n",
      "Epoch 22/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1061 - binary_accuracy: 0.9411 - acc: 0.1182 - val_loss: 0.1067 - val_binary_accuracy: 0.9408 - val_acc: 0.1244\n",
      "Epoch 23/4000\n",
      "15667/15667 [==============================] - 0s 20us/step - loss: 0.1057 - binary_accuracy: 0.9411 - acc: 0.1155 - val_loss: 0.1063 - val_binary_accuracy: 0.9408 - val_acc: 0.1237\n",
      "Epoch 24/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1054 - binary_accuracy: 0.9411 - acc: 0.1180 - val_loss: 0.1060 - val_binary_accuracy: 0.9408 - val_acc: 0.1197\n",
      "Epoch 25/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1050 - binary_accuracy: 0.9411 - acc: 0.1151 - val_loss: 0.1057 - val_binary_accuracy: 0.9408 - val_acc: 0.1233\n",
      "Epoch 26/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1048 - binary_accuracy: 0.9411 - acc: 0.1183 - val_loss: 0.1054 - val_binary_accuracy: 0.9408 - val_acc: 0.1306\n",
      "Epoch 27/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1045 - binary_accuracy: 0.9411 - acc: 0.1179 - val_loss: 0.1052 - val_binary_accuracy: 0.9408 - val_acc: 0.1298\n",
      "Epoch 28/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1043 - binary_accuracy: 0.9411 - acc: 0.1187 - val_loss: 0.1050 - val_binary_accuracy: 0.9408 - val_acc: 0.1157\n",
      "Epoch 29/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1041 - binary_accuracy: 0.9411 - acc: 0.1177 - val_loss: 0.1048 - val_binary_accuracy: 0.9408 - val_acc: 0.1143\n",
      "Epoch 30/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1039 - binary_accuracy: 0.9411 - acc: 0.1174 - val_loss: 0.1046 - val_binary_accuracy: 0.9408 - val_acc: 0.1175\n",
      "Epoch 31/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1037 - binary_accuracy: 0.9411 - acc: 0.1184 - val_loss: 0.1044 - val_binary_accuracy: 0.9408 - val_acc: 0.1421\n",
      "Epoch 32/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1036 - binary_accuracy: 0.9411 - acc: 0.1187 - val_loss: 0.1043 - val_binary_accuracy: 0.9408 - val_acc: 0.1197\n",
      "Epoch 33/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1034 - binary_accuracy: 0.9411 - acc: 0.1162 - val_loss: 0.1041 - val_binary_accuracy: 0.9408 - val_acc: 0.1266\n",
      "Epoch 34/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1033 - binary_accuracy: 0.9411 - acc: 0.1180 - val_loss: 0.1040 - val_binary_accuracy: 0.9408 - val_acc: 0.1266\n",
      "Epoch 35/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1032 - binary_accuracy: 0.9411 - acc: 0.1174 - val_loss: 0.1039 - val_binary_accuracy: 0.9408 - val_acc: 0.1306\n",
      "Epoch 36/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1031 - binary_accuracy: 0.9411 - acc: 0.1205 - val_loss: 0.1038 - val_binary_accuracy: 0.9408 - val_acc: 0.1269\n",
      "Epoch 37/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1030 - binary_accuracy: 0.9411 - acc: 0.1199 - val_loss: 0.1037 - val_binary_accuracy: 0.9408 - val_acc: 0.1172\n",
      "Epoch 38/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1029 - binary_accuracy: 0.9411 - acc: 0.1179 - val_loss: 0.1036 - val_binary_accuracy: 0.9408 - val_acc: 0.1327\n",
      "Epoch 39/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1028 - binary_accuracy: 0.9411 - acc: 0.1199 - val_loss: 0.1035 - val_binary_accuracy: 0.9408 - val_acc: 0.1230\n",
      "Epoch 40/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1027 - binary_accuracy: 0.9411 - acc: 0.1187 - val_loss: 0.1034 - val_binary_accuracy: 0.9408 - val_acc: 0.1186\n",
      "Epoch 41/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1026 - binary_accuracy: 0.9411 - acc: 0.1203 - val_loss: 0.1033 - val_binary_accuracy: 0.9408 - val_acc: 0.1335\n",
      "Epoch 42/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1026 - binary_accuracy: 0.9411 - acc: 0.1169 - val_loss: 0.1033 - val_binary_accuracy: 0.9408 - val_acc: 0.1309\n",
      "Epoch 43/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1025 - binary_accuracy: 0.9411 - acc: 0.1164 - val_loss: 0.1032 - val_binary_accuracy: 0.9408 - val_acc: 0.1233\n",
      "Epoch 44/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1024 - binary_accuracy: 0.9411 - acc: 0.1194 - val_loss: 0.1031 - val_binary_accuracy: 0.9408 - val_acc: 0.1284\n",
      "Epoch 45/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1024 - binary_accuracy: 0.9411 - acc: 0.1199 - val_loss: 0.1031 - val_binary_accuracy: 0.9408 - val_acc: 0.1288\n",
      "Epoch 46/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1023 - binary_accuracy: 0.9411 - acc: 0.1205 - val_loss: 0.1030 - val_binary_accuracy: 0.9408 - val_acc: 0.1324\n",
      "Epoch 47/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1023 - binary_accuracy: 0.9411 - acc: 0.1198 - val_loss: 0.1029 - val_binary_accuracy: 0.9408 - val_acc: 0.1212\n",
      "Epoch 48/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1022 - binary_accuracy: 0.9411 - acc: 0.1201 - val_loss: 0.1029 - val_binary_accuracy: 0.9408 - val_acc: 0.1219\n",
      "Epoch 49/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1022 - binary_accuracy: 0.9411 - acc: 0.1181 - val_loss: 0.1028 - val_binary_accuracy: 0.9408 - val_acc: 0.1157\n",
      "Epoch 50/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1021 - binary_accuracy: 0.9411 - acc: 0.1183 - val_loss: 0.1028 - val_binary_accuracy: 0.9408 - val_acc: 0.1179\n",
      "Epoch 51/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1021 - binary_accuracy: 0.9411 - acc: 0.1192 - val_loss: 0.1028 - val_binary_accuracy: 0.9408 - val_acc: 0.1288\n",
      "Epoch 52/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1020 - binary_accuracy: 0.9411 - acc: 0.1201 - val_loss: 0.1027 - val_binary_accuracy: 0.9408 - val_acc: 0.1251\n",
      "Epoch 53/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1020 - binary_accuracy: 0.9411 - acc: 0.1179 - val_loss: 0.1027 - val_binary_accuracy: 0.9408 - val_acc: 0.1208\n",
      "Epoch 54/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1020 - binary_accuracy: 0.9411 - acc: 0.1194 - val_loss: 0.1026 - val_binary_accuracy: 0.9408 - val_acc: 0.1161\n",
      "Epoch 55/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1019 - binary_accuracy: 0.9411 - acc: 0.1205 - val_loss: 0.1026 - val_binary_accuracy: 0.9408 - val_acc: 0.1222\n",
      "Epoch 56/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1019 - binary_accuracy: 0.9411 - acc: 0.1180 - val_loss: 0.1026 - val_binary_accuracy: 0.9408 - val_acc: 0.1277\n",
      "Epoch 57/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1019 - binary_accuracy: 0.9411 - acc: 0.1210 - val_loss: 0.1025 - val_binary_accuracy: 0.9408 - val_acc: 0.1241\n",
      "Epoch 58/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1019 - binary_accuracy: 0.9411 - acc: 0.1193 - val_loss: 0.1025 - val_binary_accuracy: 0.9408 - val_acc: 0.1172\n",
      "Epoch 59/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1018 - binary_accuracy: 0.9411 - acc: 0.1186 - val_loss: 0.1025 - val_binary_accuracy: 0.9408 - val_acc: 0.1338\n",
      "Epoch 60/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1018 - binary_accuracy: 0.9411 - acc: 0.1217 - val_loss: 0.1025 - val_binary_accuracy: 0.9408 - val_acc: 0.1215\n",
      "Epoch 61/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1018 - binary_accuracy: 0.9411 - acc: 0.1180 - val_loss: 0.1024 - val_binary_accuracy: 0.9408 - val_acc: 0.1233\n",
      "Epoch 62/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1017 - binary_accuracy: 0.9411 - acc: 0.1206 - val_loss: 0.1024 - val_binary_accuracy: 0.9408 - val_acc: 0.1316\n",
      "Epoch 63/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1017 - binary_accuracy: 0.9411 - acc: 0.1233 - val_loss: 0.1024 - val_binary_accuracy: 0.9408 - val_acc: 0.1259\n",
      "Epoch 64/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1017 - binary_accuracy: 0.9411 - acc: 0.1209 - val_loss: 0.1024 - val_binary_accuracy: 0.9408 - val_acc: 0.1186\n",
      "Epoch 65/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1017 - binary_accuracy: 0.9411 - acc: 0.1189 - val_loss: 0.1023 - val_binary_accuracy: 0.9408 - val_acc: 0.1418\n",
      "Epoch 66/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1017 - binary_accuracy: 0.9411 - acc: 0.1194 - val_loss: 0.1023 - val_binary_accuracy: 0.9408 - val_acc: 0.1306\n",
      "Epoch 67/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1016 - binary_accuracy: 0.9411 - acc: 0.1187 - val_loss: 0.1023 - val_binary_accuracy: 0.9408 - val_acc: 0.1244\n",
      "Epoch 68/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1016 - binary_accuracy: 0.9411 - acc: 0.1190 - val_loss: 0.1023 - val_binary_accuracy: 0.9408 - val_acc: 0.1284\n",
      "Epoch 69/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1016 - binary_accuracy: 0.9411 - acc: 0.1217 - val_loss: 0.1023 - val_binary_accuracy: 0.9408 - val_acc: 0.1345\n",
      "Epoch 70/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1016 - binary_accuracy: 0.9411 - acc: 0.1218 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1172\n",
      "Epoch 71/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1016 - binary_accuracy: 0.9411 - acc: 0.1206 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1226\n",
      "Epoch 72/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1016 - binary_accuracy: 0.9411 - acc: 0.1211 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1201\n",
      "Epoch 73/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1218 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1284\n",
      "Epoch 74/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1201 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1212\n",
      "Epoch 75/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1212 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1212\n",
      "Epoch 76/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1175 - val_loss: 0.1022 - val_binary_accuracy: 0.9408 - val_acc: 0.1241\n",
      "Epoch 77/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1188 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1244\n",
      "Epoch 78/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1188 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1259\n",
      "Epoch 79/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1211 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1186\n",
      "Epoch 80/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1015 - binary_accuracy: 0.9411 - acc: 0.1201 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1222\n",
      "Epoch 81/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1175 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1378\n",
      "Epoch 82/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1209 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1251\n",
      "Epoch 83/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1193 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1203 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1136\n",
      "Epoch 85/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1189 - val_loss: 0.1021 - val_binary_accuracy: 0.9408 - val_acc: 0.1302\n",
      "Epoch 86/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1207 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1342\n",
      "Epoch 87/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1199 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1327\n",
      "Epoch 88/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1210 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1371\n",
      "Epoch 89/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1208 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1222\n",
      "Epoch 90/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1209 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1212\n",
      "Epoch 91/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1174 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1233\n",
      "Epoch 92/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1014 - binary_accuracy: 0.9411 - acc: 0.1176 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1306\n",
      "Epoch 93/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1199 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1190\n",
      "Epoch 94/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1197 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1125\n",
      "Epoch 95/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1182 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1259\n",
      "Epoch 96/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1181 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1363\n",
      "Epoch 97/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1212 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1128\n",
      "Epoch 98/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1176 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1313\n",
      "Epoch 99/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1182 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1222\n",
      "Epoch 100/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1208 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1450\n",
      "Epoch 101/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1184 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1309\n",
      "Epoch 102/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1174 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1284\n",
      "Epoch 103/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1221 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1266\n",
      "Epoch 104/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1189 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1378\n",
      "Epoch 105/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1199 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1284\n",
      "Epoch 106/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1202 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1146\n",
      "Epoch 107/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1171 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1233\n",
      "Epoch 108/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1151 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1230\n",
      "Epoch 109/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1162 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1306\n",
      "Epoch 110/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1193 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1157\n",
      "Epoch 111/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1070 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1494\n",
      "Epoch 112/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1108 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0951\n",
      "Epoch 113/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1012 - binary_accuracy: 0.9411 - acc: 0.1060 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1421\n",
      "Epoch 114/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1013 - binary_accuracy: 0.9411 - acc: 0.1014 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0825\n",
      "Epoch 115/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1012 - binary_accuracy: 0.9411 - acc: 0.1012 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1251\n",
      "Epoch 116/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1012 - binary_accuracy: 0.9412 - acc: 0.1118 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1038\n",
      "Epoch 117/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1012 - binary_accuracy: 0.9412 - acc: 0.1292 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0933\n",
      "Epoch 118/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.1012 - binary_accuracy: 0.9412 - acc: 0.1161 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0394\n",
      "Epoch 119/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1012 - binary_accuracy: 0.9412 - acc: 0.0981 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0987\n",
      "Epoch 120/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1011 - binary_accuracy: 0.9412 - acc: 0.1117 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0861\n",
      "Epoch 121/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.1011 - binary_accuracy: 0.9412 - acc: 0.1428 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.2517\n",
      "Epoch 122/4000\n",
      "15667/15667 [==============================] - 0s 20us/step - loss: 0.1011 - binary_accuracy: 0.9413 - acc: 0.1266 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1870\n",
      "Epoch 123/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1010 - binary_accuracy: 0.9413 - acc: 0.1305 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0828\n",
      "Epoch 124/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1010 - binary_accuracy: 0.9413 - acc: 0.1438 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0929\n",
      "Epoch 125/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1009 - binary_accuracy: 0.9413 - acc: 0.1208 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1009 - binary_accuracy: 0.9414 - acc: 0.1184 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0846\n",
      "Epoch 127/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1009 - binary_accuracy: 0.9414 - acc: 0.1287 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.3067\n",
      "Epoch 128/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1008 - binary_accuracy: 0.9414 - acc: 0.1358 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1049\n",
      "Epoch 129/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1008 - binary_accuracy: 0.9414 - acc: 0.1197 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0944\n",
      "Epoch 130/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1007 - binary_accuracy: 0.9414 - acc: 0.1084 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1653\n",
      "Epoch 131/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1007 - binary_accuracy: 0.9415 - acc: 0.1297 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.2405\n",
      "Epoch 132/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1007 - binary_accuracy: 0.9415 - acc: 0.1131 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1975\n",
      "Epoch 133/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1006 - binary_accuracy: 0.9415 - acc: 0.1233 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.2995\n",
      "Epoch 134/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1005 - binary_accuracy: 0.9416 - acc: 0.1415 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1089\n",
      "Epoch 135/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1005 - binary_accuracy: 0.9416 - acc: 0.1180 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.2014\n",
      "Epoch 136/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1005 - binary_accuracy: 0.9416 - acc: 0.1319 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1114\n",
      "Epoch 137/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1005 - binary_accuracy: 0.9416 - acc: 0.1173 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1602\n",
      "Epoch 138/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1005 - binary_accuracy: 0.9416 - acc: 0.1140 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1132\n",
      "Epoch 139/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1004 - binary_accuracy: 0.9416 - acc: 0.1145 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0785\n",
      "Epoch 140/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1003 - binary_accuracy: 0.9417 - acc: 0.1097 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0723\n",
      "Epoch 141/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1003 - binary_accuracy: 0.9417 - acc: 0.1106 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0984\n",
      "Epoch 142/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1002 - binary_accuracy: 0.9417 - acc: 0.1113 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0799\n",
      "Epoch 143/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1002 - binary_accuracy: 0.9418 - acc: 0.0982 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1175\n",
      "Epoch 144/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1002 - binary_accuracy: 0.9418 - acc: 0.1055 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0908\n",
      "Epoch 145/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1002 - binary_accuracy: 0.9418 - acc: 0.1155 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1114\n",
      "Epoch 146/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1002 - binary_accuracy: 0.9418 - acc: 0.1121 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1157\n",
      "Epoch 147/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1001 - binary_accuracy: 0.9418 - acc: 0.1084 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0749\n",
      "Epoch 148/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1001 - binary_accuracy: 0.9418 - acc: 0.1141 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1049\n",
      "Epoch 149/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1001 - binary_accuracy: 0.9418 - acc: 0.1043 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1024\n",
      "Epoch 150/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1001 - binary_accuracy: 0.9418 - acc: 0.1043 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1071\n",
      "Epoch 151/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.1000 - binary_accuracy: 0.9418 - acc: 0.1016 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1490\n",
      "Epoch 152/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1000 - binary_accuracy: 0.9419 - acc: 0.1035 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1107\n",
      "Epoch 153/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.1000 - binary_accuracy: 0.9419 - acc: 0.1096 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0778\n",
      "Epoch 154/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1000 - binary_accuracy: 0.9419 - acc: 0.1151 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1523\n",
      "Epoch 155/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.1000 - binary_accuracy: 0.9419 - acc: 0.1036 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0669\n",
      "Epoch 156/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0999 - binary_accuracy: 0.9419 - acc: 0.1031 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0958\n",
      "Epoch 157/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0998 - binary_accuracy: 0.9420 - acc: 0.0942 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1342\n",
      "Epoch 158/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0997 - binary_accuracy: 0.9420 - acc: 0.1176 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1125\n",
      "Epoch 159/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0997 - binary_accuracy: 0.9420 - acc: 0.1108 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0911\n",
      "Epoch 160/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0997 - binary_accuracy: 0.9420 - acc: 0.1272 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1060\n",
      "Epoch 161/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0997 - binary_accuracy: 0.9421 - acc: 0.1064 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1038\n",
      "Epoch 162/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0996 - binary_accuracy: 0.9421 - acc: 0.1320 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.1146\n",
      "Epoch 163/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0996 - binary_accuracy: 0.9421 - acc: 0.1223 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1505\n",
      "Epoch 164/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0995 - binary_accuracy: 0.9421 - acc: 0.1255 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1146\n",
      "Epoch 165/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0995 - binary_accuracy: 0.9422 - acc: 0.1350 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1125\n",
      "Epoch 166/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0994 - binary_accuracy: 0.9422 - acc: 0.1464 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0940\n",
      "Epoch 167/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0994 - binary_accuracy: 0.9422 - acc: 0.1373 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1371\n",
      "Epoch 168/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0993 - binary_accuracy: 0.9422 - acc: 0.1328 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.0897\n",
      "Epoch 169/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0993 - binary_accuracy: 0.9423 - acc: 0.1231 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1812\n",
      "Epoch 170/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0993 - binary_accuracy: 0.9423 - acc: 0.1410 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1776\n",
      "Epoch 171/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0992 - binary_accuracy: 0.9423 - acc: 0.1511 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.2756\n",
      "Epoch 172/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0992 - binary_accuracy: 0.9423 - acc: 0.1501 - val_loss: 0.1020 - val_binary_accuracy: 0.9408 - val_acc: 0.0948\n",
      "Epoch 173/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0991 - binary_accuracy: 0.9424 - acc: 0.1486 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1222\n",
      "Epoch 174/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0991 - binary_accuracy: 0.9424 - acc: 0.1207 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1038\n",
      "Epoch 175/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0990 - binary_accuracy: 0.9424 - acc: 0.1308 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1967\n",
      "Epoch 176/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0991 - binary_accuracy: 0.9424 - acc: 0.1333 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1241\n",
      "Epoch 177/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0990 - binary_accuracy: 0.9425 - acc: 0.1162 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1038\n",
      "Epoch 178/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0989 - binary_accuracy: 0.9425 - acc: 0.1355 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1552\n",
      "Epoch 179/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0989 - binary_accuracy: 0.9425 - acc: 0.1367 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1125\n",
      "Epoch 180/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0988 - binary_accuracy: 0.9425 - acc: 0.1379 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1967\n",
      "Epoch 181/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0988 - binary_accuracy: 0.9426 - acc: 0.1396 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1063\n",
      "Epoch 182/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0988 - binary_accuracy: 0.9426 - acc: 0.1250 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1042\n",
      "Epoch 183/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0987 - binary_accuracy: 0.9426 - acc: 0.1352 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1009\n",
      "Epoch 184/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0987 - binary_accuracy: 0.9426 - acc: 0.1540 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1085\n",
      "Epoch 185/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0986 - binary_accuracy: 0.9427 - acc: 0.1338 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1548\n",
      "Epoch 186/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0986 - binary_accuracy: 0.9427 - acc: 0.1418 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1045\n",
      "Epoch 187/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0984 - binary_accuracy: 0.9428 - acc: 0.1509 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1230\n",
      "Epoch 188/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0984 - binary_accuracy: 0.9428 - acc: 0.1414 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1407\n",
      "Epoch 189/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0984 - binary_accuracy: 0.9428 - acc: 0.1441 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1378\n",
      "Epoch 190/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0983 - binary_accuracy: 0.9429 - acc: 0.1311 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1946\n",
      "Epoch 191/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0983 - binary_accuracy: 0.9429 - acc: 0.1501 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1758\n",
      "Epoch 192/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0982 - binary_accuracy: 0.9429 - acc: 0.1522 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1298\n",
      "Epoch 193/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0982 - binary_accuracy: 0.9429 - acc: 0.1496 - val_loss: 0.1019 - val_binary_accuracy: 0.9408 - val_acc: 0.1335\n",
      "Epoch 194/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0981 - binary_accuracy: 0.9430 - acc: 0.1450 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1396\n",
      "Epoch 195/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0981 - binary_accuracy: 0.9430 - acc: 0.1450 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.0919\n",
      "Epoch 196/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0980 - binary_accuracy: 0.9430 - acc: 0.1439 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.2083\n",
      "Epoch 197/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0979 - binary_accuracy: 0.9431 - acc: 0.1251 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1186\n",
      "Epoch 198/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0979 - binary_accuracy: 0.9431 - acc: 0.1192 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.0991\n",
      "Epoch 199/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0978 - binary_accuracy: 0.9431 - acc: 0.1160 - val_loss: 0.1018 - val_binary_accuracy: 0.9409 - val_acc: 0.1454\n",
      "Epoch 200/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0978 - binary_accuracy: 0.9432 - acc: 0.1265 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1747\n",
      "Epoch 201/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0977 - binary_accuracy: 0.9432 - acc: 0.1317 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1099\n",
      "Epoch 202/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0977 - binary_accuracy: 0.9432 - acc: 0.1241 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.2018\n",
      "Epoch 203/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0976 - binary_accuracy: 0.9433 - acc: 0.1325 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1107\n",
      "Epoch 204/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0976 - binary_accuracy: 0.9433 - acc: 0.1368 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.0825\n",
      "Epoch 205/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0975 - binary_accuracy: 0.9433 - acc: 0.1132 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.0915\n",
      "Epoch 206/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0974 - binary_accuracy: 0.9434 - acc: 0.1254 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1201\n",
      "Epoch 207/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0974 - binary_accuracy: 0.9434 - acc: 0.1035 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1241\n",
      "Epoch 208/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0974 - binary_accuracy: 0.9434 - acc: 0.1162 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0973 - binary_accuracy: 0.9435 - acc: 0.1079 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1031\n",
      "Epoch 210/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0972 - binary_accuracy: 0.9435 - acc: 0.1218 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.0995\n",
      "Epoch 211/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0972 - binary_accuracy: 0.9435 - acc: 0.1104 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.0955\n",
      "Epoch 212/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0972 - binary_accuracy: 0.9435 - acc: 0.1056 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1356\n",
      "Epoch 213/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0971 - binary_accuracy: 0.9435 - acc: 0.1185 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1844\n",
      "Epoch 214/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0971 - binary_accuracy: 0.9436 - acc: 0.1275 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1382\n",
      "Epoch 215/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0971 - binary_accuracy: 0.9436 - acc: 0.1213 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1056\n",
      "Epoch 216/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0970 - binary_accuracy: 0.9436 - acc: 0.1238 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1443\n",
      "Epoch 217/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0970 - binary_accuracy: 0.9436 - acc: 0.1300 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1071\n",
      "Epoch 218/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0969 - binary_accuracy: 0.9437 - acc: 0.1314 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1711\n",
      "Epoch 219/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0969 - binary_accuracy: 0.9437 - acc: 0.1310 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1635\n",
      "Epoch 220/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0968 - binary_accuracy: 0.9437 - acc: 0.1259 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1986\n",
      "Epoch 221/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0968 - binary_accuracy: 0.9437 - acc: 0.1392 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1143\n",
      "Epoch 222/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0968 - binary_accuracy: 0.9437 - acc: 0.1291 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.1928\n",
      "Epoch 223/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0967 - binary_accuracy: 0.9438 - acc: 0.1561 - val_loss: 0.1018 - val_binary_accuracy: 0.9409 - val_acc: 0.0911\n",
      "Epoch 224/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0967 - binary_accuracy: 0.9438 - acc: 0.1497 - val_loss: 0.1018 - val_binary_accuracy: 0.9408 - val_acc: 0.2438\n",
      "Epoch 225/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0967 - binary_accuracy: 0.9438 - acc: 0.1400 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1251\n",
      "Epoch 226/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0966 - binary_accuracy: 0.9439 - acc: 0.1325 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1407\n",
      "Epoch 227/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0965 - binary_accuracy: 0.9439 - acc: 0.1309 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1400\n",
      "Epoch 228/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0965 - binary_accuracy: 0.9439 - acc: 0.1455 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1613\n",
      "Epoch 229/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0964 - binary_accuracy: 0.9440 - acc: 0.1457 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.0973\n",
      "Epoch 230/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0964 - binary_accuracy: 0.9440 - acc: 0.1501 - val_loss: 0.1016 - val_binary_accuracy: 0.9410 - val_acc: 0.1190\n",
      "Epoch 231/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0963 - binary_accuracy: 0.9440 - acc: 0.1409 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1439\n",
      "Epoch 232/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0963 - binary_accuracy: 0.9440 - acc: 0.1367 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1009\n",
      "Epoch 233/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0962 - binary_accuracy: 0.9441 - acc: 0.1511 - val_loss: 0.1016 - val_binary_accuracy: 0.9410 - val_acc: 0.1425\n",
      "Epoch 234/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0962 - binary_accuracy: 0.9441 - acc: 0.1439 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1562\n",
      "Epoch 235/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0962 - binary_accuracy: 0.9441 - acc: 0.1575 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1458\n",
      "Epoch 236/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0961 - binary_accuracy: 0.9441 - acc: 0.1545 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1530\n",
      "Epoch 237/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0961 - binary_accuracy: 0.9441 - acc: 0.1391 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.1808\n",
      "Epoch 238/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0961 - binary_accuracy: 0.9441 - acc: 0.1420 - val_loss: 0.1017 - val_binary_accuracy: 0.9408 - val_acc: 0.2000\n",
      "Epoch 239/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0961 - binary_accuracy: 0.9442 - acc: 0.1502 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1410\n",
      "Epoch 240/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0960 - binary_accuracy: 0.9442 - acc: 0.1538 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1403\n",
      "Epoch 241/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0960 - binary_accuracy: 0.9442 - acc: 0.1583 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1931\n",
      "Epoch 242/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0959 - binary_accuracy: 0.9442 - acc: 0.1552 - val_loss: 0.1016 - val_binary_accuracy: 0.9410 - val_acc: 0.1595\n",
      "Epoch 243/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0959 - binary_accuracy: 0.9443 - acc: 0.1531 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1439\n",
      "Epoch 244/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0958 - binary_accuracy: 0.9443 - acc: 0.1583 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1530\n",
      "Epoch 245/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0958 - binary_accuracy: 0.9443 - acc: 0.1467 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1530\n",
      "Epoch 246/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0958 - binary_accuracy: 0.9443 - acc: 0.1557 - val_loss: 0.1015 - val_binary_accuracy: 0.9410 - val_acc: 0.1125\n",
      "Epoch 247/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0958 - binary_accuracy: 0.9443 - acc: 0.1411 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1830\n",
      "Epoch 248/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0957 - binary_accuracy: 0.9444 - acc: 0.1692 - val_loss: 0.1016 - val_binary_accuracy: 0.9410 - val_acc: 0.1382\n",
      "Epoch 249/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0957 - binary_accuracy: 0.9444 - acc: 0.1498 - val_loss: 0.1016 - val_binary_accuracy: 0.9410 - val_acc: 0.1349\n",
      "Epoch 250/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0956 - binary_accuracy: 0.9444 - acc: 0.1637 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1081\n",
      "Epoch 251/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0956 - binary_accuracy: 0.9444 - acc: 0.1496 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1859\n",
      "Epoch 252/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0956 - binary_accuracy: 0.9444 - acc: 0.1741 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1490\n",
      "Epoch 253/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0955 - binary_accuracy: 0.9445 - acc: 0.1692 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1541\n",
      "Epoch 254/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0955 - binary_accuracy: 0.9445 - acc: 0.1815 - val_loss: 0.1015 - val_binary_accuracy: 0.9409 - val_acc: 0.1533\n",
      "Epoch 255/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0955 - binary_accuracy: 0.9445 - acc: 0.1904 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1421\n",
      "Epoch 256/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0955 - binary_accuracy: 0.9445 - acc: 0.1904 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1212\n",
      "Epoch 257/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0954 - binary_accuracy: 0.9445 - acc: 0.1788 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.1996\n",
      "Epoch 258/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0954 - binary_accuracy: 0.9446 - acc: 0.1988 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1186\n",
      "Epoch 259/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0953 - binary_accuracy: 0.9446 - acc: 0.1724 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1410\n",
      "Epoch 260/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0953 - binary_accuracy: 0.9447 - acc: 0.1704 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1942\n",
      "Epoch 261/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0952 - binary_accuracy: 0.9447 - acc: 0.1672 - val_loss: 0.1015 - val_binary_accuracy: 0.9409 - val_acc: 0.1421\n",
      "Epoch 262/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0951 - binary_accuracy: 0.9447 - acc: 0.1735 - val_loss: 0.1015 - val_binary_accuracy: 0.9410 - val_acc: 0.1403\n",
      "Epoch 263/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0951 - binary_accuracy: 0.9447 - acc: 0.1686 - val_loss: 0.1016 - val_binary_accuracy: 0.9409 - val_acc: 0.1222\n",
      "Epoch 264/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0951 - binary_accuracy: 0.9447 - acc: 0.1731 - val_loss: 0.1015 - val_binary_accuracy: 0.9409 - val_acc: 0.1707\n",
      "Epoch 265/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0950 - binary_accuracy: 0.9448 - acc: 0.1840 - val_loss: 0.1017 - val_binary_accuracy: 0.9409 - val_acc: 0.2156\n",
      "Epoch 266/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0950 - binary_accuracy: 0.9448 - acc: 0.2039 - val_loss: 0.1015 - val_binary_accuracy: 0.9410 - val_acc: 0.1986\n",
      "Epoch 267/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0949 - binary_accuracy: 0.9449 - acc: 0.1952 - val_loss: 0.1015 - val_binary_accuracy: 0.9410 - val_acc: 0.1953\n",
      "Epoch 268/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0948 - binary_accuracy: 0.9449 - acc: 0.2088 - val_loss: 0.1015 - val_binary_accuracy: 0.9410 - val_acc: 0.1168\n",
      "Epoch 269/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0947 - binary_accuracy: 0.9450 - acc: 0.1949 - val_loss: 0.1014 - val_binary_accuracy: 0.9410 - val_acc: 0.1816\n",
      "Epoch 270/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0946 - binary_accuracy: 0.9450 - acc: 0.2034 - val_loss: 0.1014 - val_binary_accuracy: 0.9410 - val_acc: 0.2235\n",
      "Epoch 271/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0946 - binary_accuracy: 0.9450 - acc: 0.2238 - val_loss: 0.1013 - val_binary_accuracy: 0.9411 - val_acc: 0.1685\n",
      "Epoch 272/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0945 - binary_accuracy: 0.9451 - acc: 0.2237 - val_loss: 0.1013 - val_binary_accuracy: 0.9411 - val_acc: 0.2076\n",
      "Epoch 273/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0945 - binary_accuracy: 0.9451 - acc: 0.2228 - val_loss: 0.1013 - val_binary_accuracy: 0.9411 - val_acc: 0.2087\n",
      "Epoch 274/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0944 - binary_accuracy: 0.9451 - acc: 0.2257 - val_loss: 0.1013 - val_binary_accuracy: 0.9411 - val_acc: 0.2752\n",
      "Epoch 275/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0943 - binary_accuracy: 0.9452 - acc: 0.2337 - val_loss: 0.1013 - val_binary_accuracy: 0.9411 - val_acc: 0.2347\n",
      "Epoch 276/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0943 - binary_accuracy: 0.9452 - acc: 0.2472 - val_loss: 0.1013 - val_binary_accuracy: 0.9410 - val_acc: 0.2590\n",
      "Epoch 277/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0942 - binary_accuracy: 0.9453 - acc: 0.2530 - val_loss: 0.1013 - val_binary_accuracy: 0.9410 - val_acc: 0.2336\n",
      "Epoch 278/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0941 - binary_accuracy: 0.9453 - acc: 0.2440 - val_loss: 0.1014 - val_binary_accuracy: 0.9410 - val_acc: 0.2387\n",
      "Epoch 279/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0940 - binary_accuracy: 0.9454 - acc: 0.2488 - val_loss: 0.1014 - val_binary_accuracy: 0.9410 - val_acc: 0.2980\n",
      "Epoch 280/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0939 - binary_accuracy: 0.9454 - acc: 0.2575 - val_loss: 0.1012 - val_binary_accuracy: 0.9411 - val_acc: 0.2047\n",
      "Epoch 281/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0938 - binary_accuracy: 0.9455 - acc: 0.2469 - val_loss: 0.1013 - val_binary_accuracy: 0.9411 - val_acc: 0.2618\n",
      "Epoch 282/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0937 - binary_accuracy: 0.9456 - acc: 0.2446 - val_loss: 0.1010 - val_binary_accuracy: 0.9413 - val_acc: 0.2192\n",
      "Epoch 283/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0936 - binary_accuracy: 0.9456 - acc: 0.2609 - val_loss: 0.1011 - val_binary_accuracy: 0.9412 - val_acc: 0.1790\n",
      "Epoch 284/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0936 - binary_accuracy: 0.9456 - acc: 0.2455 - val_loss: 0.1010 - val_binary_accuracy: 0.9413 - val_acc: 0.2040\n",
      "Epoch 285/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0935 - binary_accuracy: 0.9457 - acc: 0.2415 - val_loss: 0.1010 - val_binary_accuracy: 0.9413 - val_acc: 0.2514\n",
      "Epoch 286/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0935 - binary_accuracy: 0.9457 - acc: 0.2431 - val_loss: 0.1010 - val_binary_accuracy: 0.9413 - val_acc: 0.2083\n",
      "Epoch 287/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0934 - binary_accuracy: 0.9458 - acc: 0.2320 - val_loss: 0.1010 - val_binary_accuracy: 0.9413 - val_acc: 0.2452\n",
      "Epoch 288/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0933 - binary_accuracy: 0.9458 - acc: 0.2335 - val_loss: 0.1010 - val_binary_accuracy: 0.9412 - val_acc: 0.2221\n",
      "Epoch 289/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0932 - binary_accuracy: 0.9458 - acc: 0.2557 - val_loss: 0.1009 - val_binary_accuracy: 0.9412 - val_acc: 0.2022\n",
      "Epoch 290/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0932 - binary_accuracy: 0.9459 - acc: 0.2354 - val_loss: 0.1009 - val_binary_accuracy: 0.9413 - val_acc: 0.2825\n",
      "Epoch 291/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0931 - binary_accuracy: 0.9459 - acc: 0.2582 - val_loss: 0.1008 - val_binary_accuracy: 0.9414 - val_acc: 0.1794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0930 - binary_accuracy: 0.9460 - acc: 0.2251 - val_loss: 0.1010 - val_binary_accuracy: 0.9413 - val_acc: 0.3371\n",
      "Epoch 293/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0930 - binary_accuracy: 0.9460 - acc: 0.2602 - val_loss: 0.1008 - val_binary_accuracy: 0.9413 - val_acc: 0.2391\n",
      "Epoch 294/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0929 - binary_accuracy: 0.9461 - acc: 0.2544 - val_loss: 0.1008 - val_binary_accuracy: 0.9414 - val_acc: 0.2166\n",
      "Epoch 295/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0928 - binary_accuracy: 0.9461 - acc: 0.2398 - val_loss: 0.1008 - val_binary_accuracy: 0.9413 - val_acc: 0.2257\n",
      "Epoch 296/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0928 - binary_accuracy: 0.9461 - acc: 0.2535 - val_loss: 0.1007 - val_binary_accuracy: 0.9414 - val_acc: 0.2354\n",
      "Epoch 297/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0927 - binary_accuracy: 0.9462 - acc: 0.2451 - val_loss: 0.1007 - val_binary_accuracy: 0.9415 - val_acc: 0.2116\n",
      "Epoch 298/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0926 - binary_accuracy: 0.9462 - acc: 0.2557 - val_loss: 0.1007 - val_binary_accuracy: 0.9414 - val_acc: 0.3013\n",
      "Epoch 299/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0925 - binary_accuracy: 0.9462 - acc: 0.2633 - val_loss: 0.1006 - val_binary_accuracy: 0.9415 - val_acc: 0.2119\n",
      "Epoch 300/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0925 - binary_accuracy: 0.9463 - acc: 0.2562 - val_loss: 0.1005 - val_binary_accuracy: 0.9415 - val_acc: 0.2590\n",
      "Epoch 301/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0924 - binary_accuracy: 0.9463 - acc: 0.2575 - val_loss: 0.1004 - val_binary_accuracy: 0.9415 - val_acc: 0.2521\n",
      "Epoch 302/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0924 - binary_accuracy: 0.9463 - acc: 0.2666 - val_loss: 0.1005 - val_binary_accuracy: 0.9415 - val_acc: 0.2655\n",
      "Epoch 303/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0923 - binary_accuracy: 0.9464 - acc: 0.2614 - val_loss: 0.1004 - val_binary_accuracy: 0.9416 - val_acc: 0.2987\n",
      "Epoch 304/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0922 - binary_accuracy: 0.9464 - acc: 0.2728 - val_loss: 0.1003 - val_binary_accuracy: 0.9416 - val_acc: 0.2195\n",
      "Epoch 305/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0922 - binary_accuracy: 0.9465 - acc: 0.2537 - val_loss: 0.1004 - val_binary_accuracy: 0.9416 - val_acc: 0.2452\n",
      "Epoch 306/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0921 - binary_accuracy: 0.9465 - acc: 0.2637 - val_loss: 0.1004 - val_binary_accuracy: 0.9416 - val_acc: 0.2651\n",
      "Epoch 307/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0920 - binary_accuracy: 0.9466 - acc: 0.2602 - val_loss: 0.1004 - val_binary_accuracy: 0.9416 - val_acc: 0.2933\n",
      "Epoch 308/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0920 - binary_accuracy: 0.9466 - acc: 0.2510 - val_loss: 0.1004 - val_binary_accuracy: 0.9416 - val_acc: 0.2278\n",
      "Epoch 309/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0918 - binary_accuracy: 0.9467 - acc: 0.2437 - val_loss: 0.1003 - val_binary_accuracy: 0.9417 - val_acc: 0.2550\n",
      "Epoch 310/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0918 - binary_accuracy: 0.9467 - acc: 0.2458 - val_loss: 0.1002 - val_binary_accuracy: 0.9417 - val_acc: 0.2452\n",
      "Epoch 311/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0916 - binary_accuracy: 0.9468 - acc: 0.2593 - val_loss: 0.1002 - val_binary_accuracy: 0.9417 - val_acc: 0.2047\n",
      "Epoch 312/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0915 - binary_accuracy: 0.9468 - acc: 0.2554 - val_loss: 0.1003 - val_binary_accuracy: 0.9417 - val_acc: 0.2282\n",
      "Epoch 313/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0914 - binary_accuracy: 0.9469 - acc: 0.2764 - val_loss: 0.1002 - val_binary_accuracy: 0.9418 - val_acc: 0.2090\n",
      "Epoch 314/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0913 - binary_accuracy: 0.9470 - acc: 0.2642 - val_loss: 0.1003 - val_binary_accuracy: 0.9416 - val_acc: 0.3385\n",
      "Epoch 315/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0912 - binary_accuracy: 0.9470 - acc: 0.2838 - val_loss: 0.1001 - val_binary_accuracy: 0.9418 - val_acc: 0.2821\n",
      "Epoch 316/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0912 - binary_accuracy: 0.9471 - acc: 0.2768 - val_loss: 0.1002 - val_binary_accuracy: 0.9417 - val_acc: 0.2532\n",
      "Epoch 317/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0911 - binary_accuracy: 0.9471 - acc: 0.2874 - val_loss: 0.1002 - val_binary_accuracy: 0.9417 - val_acc: 0.2720\n",
      "Epoch 318/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0910 - binary_accuracy: 0.9471 - acc: 0.2950 - val_loss: 0.1002 - val_binary_accuracy: 0.9417 - val_acc: 0.2481\n",
      "Epoch 319/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0909 - binary_accuracy: 0.9472 - acc: 0.2981 - val_loss: 0.1000 - val_binary_accuracy: 0.9418 - val_acc: 0.3027\n",
      "Epoch 320/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0908 - binary_accuracy: 0.9473 - acc: 0.3090 - val_loss: 0.1003 - val_binary_accuracy: 0.9417 - val_acc: 0.2517\n",
      "Epoch 321/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0906 - binary_accuracy: 0.9474 - acc: 0.2934 - val_loss: 0.1000 - val_binary_accuracy: 0.9417 - val_acc: 0.2727\n",
      "Epoch 322/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0906 - binary_accuracy: 0.9474 - acc: 0.3092 - val_loss: 0.0999 - val_binary_accuracy: 0.9418 - val_acc: 0.2369\n",
      "Epoch 323/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0905 - binary_accuracy: 0.9475 - acc: 0.2968 - val_loss: 0.0998 - val_binary_accuracy: 0.9419 - val_acc: 0.2622\n",
      "Epoch 324/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0904 - binary_accuracy: 0.9476 - acc: 0.2906 - val_loss: 0.1000 - val_binary_accuracy: 0.9419 - val_acc: 0.2297\n",
      "Epoch 325/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0902 - binary_accuracy: 0.9476 - acc: 0.2837 - val_loss: 0.0998 - val_binary_accuracy: 0.9421 - val_acc: 0.2644\n",
      "Epoch 326/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0901 - binary_accuracy: 0.9477 - acc: 0.2830 - val_loss: 0.0999 - val_binary_accuracy: 0.9419 - val_acc: 0.3454\n",
      "Epoch 327/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0900 - binary_accuracy: 0.9478 - acc: 0.2992 - val_loss: 0.0998 - val_binary_accuracy: 0.9420 - val_acc: 0.2495\n",
      "Epoch 328/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0899 - binary_accuracy: 0.9478 - acc: 0.2898 - val_loss: 0.0996 - val_binary_accuracy: 0.9421 - val_acc: 0.2922\n",
      "Epoch 329/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0898 - binary_accuracy: 0.9479 - acc: 0.2981 - val_loss: 0.0995 - val_binary_accuracy: 0.9422 - val_acc: 0.2937\n",
      "Epoch 330/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0897 - binary_accuracy: 0.9479 - acc: 0.2985 - val_loss: 0.0995 - val_binary_accuracy: 0.9422 - val_acc: 0.2933\n",
      "Epoch 331/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0896 - binary_accuracy: 0.9480 - acc: 0.3095 - val_loss: 0.0993 - val_binary_accuracy: 0.9423 - val_acc: 0.2995\n",
      "Epoch 332/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0895 - binary_accuracy: 0.9481 - acc: 0.3029 - val_loss: 0.0993 - val_binary_accuracy: 0.9422 - val_acc: 0.2984\n",
      "Epoch 333/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0893 - binary_accuracy: 0.9482 - acc: 0.2967 - val_loss: 0.0994 - val_binary_accuracy: 0.9422 - val_acc: 0.3154\n",
      "Epoch 334/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0892 - binary_accuracy: 0.9482 - acc: 0.2946 - val_loss: 0.0993 - val_binary_accuracy: 0.9424 - val_acc: 0.3067\n",
      "Epoch 335/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0891 - binary_accuracy: 0.9483 - acc: 0.3172 - val_loss: 0.0992 - val_binary_accuracy: 0.9423 - val_acc: 0.2821\n",
      "Epoch 336/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0889 - binary_accuracy: 0.9484 - acc: 0.3029 - val_loss: 0.0992 - val_binary_accuracy: 0.9425 - val_acc: 0.3222\n",
      "Epoch 337/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0888 - binary_accuracy: 0.9485 - acc: 0.3108 - val_loss: 0.0991 - val_binary_accuracy: 0.9424 - val_acc: 0.2495\n",
      "Epoch 338/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0888 - binary_accuracy: 0.9486 - acc: 0.3046 - val_loss: 0.0990 - val_binary_accuracy: 0.9424 - val_acc: 0.3573\n",
      "Epoch 339/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0886 - binary_accuracy: 0.9486 - acc: 0.3164 - val_loss: 0.0990 - val_binary_accuracy: 0.9425 - val_acc: 0.2803\n",
      "Epoch 340/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0884 - binary_accuracy: 0.9487 - acc: 0.2976 - val_loss: 0.0990 - val_binary_accuracy: 0.9424 - val_acc: 0.3056\n",
      "Epoch 341/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0884 - binary_accuracy: 0.9488 - acc: 0.3163 - val_loss: 0.0988 - val_binary_accuracy: 0.9426 - val_acc: 0.3483\n",
      "Epoch 342/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0882 - binary_accuracy: 0.9488 - acc: 0.3110 - val_loss: 0.0988 - val_binary_accuracy: 0.9427 - val_acc: 0.3244\n",
      "Epoch 343/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0881 - binary_accuracy: 0.9489 - acc: 0.3094 - val_loss: 0.0988 - val_binary_accuracy: 0.9426 - val_acc: 0.3215\n",
      "Epoch 344/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0880 - binary_accuracy: 0.9489 - acc: 0.3122 - val_loss: 0.0988 - val_binary_accuracy: 0.9426 - val_acc: 0.2955\n",
      "Epoch 345/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0879 - binary_accuracy: 0.9490 - acc: 0.3155 - val_loss: 0.0986 - val_binary_accuracy: 0.9428 - val_acc: 0.3204\n",
      "Epoch 346/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0877 - binary_accuracy: 0.9491 - acc: 0.3066 - val_loss: 0.0985 - val_binary_accuracy: 0.9426 - val_acc: 0.3197\n",
      "Epoch 347/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0876 - binary_accuracy: 0.9492 - acc: 0.2982 - val_loss: 0.0985 - val_binary_accuracy: 0.9427 - val_acc: 0.3020\n",
      "Epoch 348/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0874 - binary_accuracy: 0.9493 - acc: 0.3094 - val_loss: 0.0985 - val_binary_accuracy: 0.9427 - val_acc: 0.3241\n",
      "Epoch 349/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0873 - binary_accuracy: 0.9494 - acc: 0.2989 - val_loss: 0.0984 - val_binary_accuracy: 0.9429 - val_acc: 0.2908\n",
      "Epoch 350/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0872 - binary_accuracy: 0.9495 - acc: 0.3029 - val_loss: 0.0984 - val_binary_accuracy: 0.9428 - val_acc: 0.3309\n",
      "Epoch 351/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0872 - binary_accuracy: 0.9495 - acc: 0.3012 - val_loss: 0.0983 - val_binary_accuracy: 0.9429 - val_acc: 0.2937\n",
      "Epoch 352/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0870 - binary_accuracy: 0.9496 - acc: 0.3071 - val_loss: 0.0982 - val_binary_accuracy: 0.9429 - val_acc: 0.2857\n",
      "Epoch 353/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0868 - binary_accuracy: 0.9497 - acc: 0.3092 - val_loss: 0.0982 - val_binary_accuracy: 0.9431 - val_acc: 0.3132\n",
      "Epoch 354/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0866 - binary_accuracy: 0.9498 - acc: 0.3065 - val_loss: 0.0983 - val_binary_accuracy: 0.9430 - val_acc: 0.2492\n",
      "Epoch 355/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0864 - binary_accuracy: 0.9499 - acc: 0.3009 - val_loss: 0.0979 - val_binary_accuracy: 0.9430 - val_acc: 0.3020\n",
      "Epoch 356/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0862 - binary_accuracy: 0.9500 - acc: 0.3059 - val_loss: 0.0979 - val_binary_accuracy: 0.9430 - val_acc: 0.3132\n",
      "Epoch 357/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0861 - binary_accuracy: 0.9501 - acc: 0.2984 - val_loss: 0.0978 - val_binary_accuracy: 0.9431 - val_acc: 0.2886\n",
      "Epoch 358/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0860 - binary_accuracy: 0.9502 - acc: 0.3069 - val_loss: 0.0980 - val_binary_accuracy: 0.9430 - val_acc: 0.3052\n",
      "Epoch 359/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0857 - binary_accuracy: 0.9504 - acc: 0.3047 - val_loss: 0.0977 - val_binary_accuracy: 0.9432 - val_acc: 0.3494\n",
      "Epoch 360/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0854 - binary_accuracy: 0.9505 - acc: 0.3010 - val_loss: 0.0976 - val_binary_accuracy: 0.9431 - val_acc: 0.2875\n",
      "Epoch 361/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0852 - binary_accuracy: 0.9507 - acc: 0.2951 - val_loss: 0.0972 - val_binary_accuracy: 0.9435 - val_acc: 0.3154\n",
      "Epoch 362/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0851 - binary_accuracy: 0.9508 - acc: 0.3154 - val_loss: 0.0971 - val_binary_accuracy: 0.9436 - val_acc: 0.2774\n",
      "Epoch 363/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0848 - binary_accuracy: 0.9509 - acc: 0.3029 - val_loss: 0.0972 - val_binary_accuracy: 0.9435 - val_acc: 0.2976\n",
      "Epoch 364/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0847 - binary_accuracy: 0.9510 - acc: 0.2978 - val_loss: 0.0969 - val_binary_accuracy: 0.9437 - val_acc: 0.2929\n",
      "Epoch 365/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0844 - binary_accuracy: 0.9511 - acc: 0.2988 - val_loss: 0.0968 - val_binary_accuracy: 0.9436 - val_acc: 0.3128\n",
      "Epoch 366/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0842 - binary_accuracy: 0.9513 - acc: 0.3031 - val_loss: 0.0968 - val_binary_accuracy: 0.9438 - val_acc: 0.2799\n",
      "Epoch 367/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0840 - binary_accuracy: 0.9514 - acc: 0.2992 - val_loss: 0.0967 - val_binary_accuracy: 0.9436 - val_acc: 0.3136\n",
      "Epoch 368/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0836 - binary_accuracy: 0.9516 - acc: 0.2980 - val_loss: 0.0965 - val_binary_accuracy: 0.9439 - val_acc: 0.2517\n",
      "Epoch 369/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0835 - binary_accuracy: 0.9517 - acc: 0.2969 - val_loss: 0.0963 - val_binary_accuracy: 0.9440 - val_acc: 0.2600\n",
      "Epoch 370/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0832 - binary_accuracy: 0.9519 - acc: 0.2932 - val_loss: 0.0962 - val_binary_accuracy: 0.9442 - val_acc: 0.2799\n",
      "Epoch 371/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0829 - binary_accuracy: 0.9520 - acc: 0.2931 - val_loss: 0.0962 - val_binary_accuracy: 0.9440 - val_acc: 0.3118\n",
      "Epoch 372/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0828 - binary_accuracy: 0.9521 - acc: 0.2918 - val_loss: 0.0960 - val_binary_accuracy: 0.9442 - val_acc: 0.2608\n",
      "Epoch 373/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0826 - binary_accuracy: 0.9523 - acc: 0.2885 - val_loss: 0.0959 - val_binary_accuracy: 0.9442 - val_acc: 0.3118\n",
      "Epoch 374/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0823 - binary_accuracy: 0.9524 - acc: 0.2860 - val_loss: 0.0959 - val_binary_accuracy: 0.9444 - val_acc: 0.3139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0821 - binary_accuracy: 0.9525 - acc: 0.2944 - val_loss: 0.0955 - val_binary_accuracy: 0.9446 - val_acc: 0.2926\n",
      "Epoch 376/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0819 - binary_accuracy: 0.9526 - acc: 0.2893 - val_loss: 0.0955 - val_binary_accuracy: 0.9445 - val_acc: 0.2749\n",
      "Epoch 377/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0817 - binary_accuracy: 0.9528 - acc: 0.2867 - val_loss: 0.0952 - val_binary_accuracy: 0.9448 - val_acc: 0.2937\n",
      "Epoch 378/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0815 - binary_accuracy: 0.9529 - acc: 0.2921 - val_loss: 0.0952 - val_binary_accuracy: 0.9446 - val_acc: 0.2850\n",
      "Epoch 379/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0813 - binary_accuracy: 0.9531 - acc: 0.2836 - val_loss: 0.0951 - val_binary_accuracy: 0.9446 - val_acc: 0.2550\n",
      "Epoch 380/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0811 - binary_accuracy: 0.9532 - acc: 0.2894 - val_loss: 0.0949 - val_binary_accuracy: 0.9449 - val_acc: 0.2694\n",
      "Epoch 381/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0808 - binary_accuracy: 0.9533 - acc: 0.2801 - val_loss: 0.0948 - val_binary_accuracy: 0.9449 - val_acc: 0.2669\n",
      "Epoch 382/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0806 - binary_accuracy: 0.9534 - acc: 0.2790 - val_loss: 0.0945 - val_binary_accuracy: 0.9451 - val_acc: 0.2948\n",
      "Epoch 383/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0804 - binary_accuracy: 0.9536 - acc: 0.2804 - val_loss: 0.0941 - val_binary_accuracy: 0.9451 - val_acc: 0.2637\n",
      "Epoch 384/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0801 - binary_accuracy: 0.9538 - acc: 0.2844 - val_loss: 0.0941 - val_binary_accuracy: 0.9452 - val_acc: 0.2579\n",
      "Epoch 385/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0799 - binary_accuracy: 0.9539 - acc: 0.2852 - val_loss: 0.0940 - val_binary_accuracy: 0.9454 - val_acc: 0.2857\n",
      "Epoch 386/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0797 - binary_accuracy: 0.9540 - acc: 0.2840 - val_loss: 0.0941 - val_binary_accuracy: 0.9453 - val_acc: 0.2727\n",
      "Epoch 387/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0795 - binary_accuracy: 0.9541 - acc: 0.2858 - val_loss: 0.0939 - val_binary_accuracy: 0.9454 - val_acc: 0.2778\n",
      "Epoch 388/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0793 - binary_accuracy: 0.9542 - acc: 0.2793 - val_loss: 0.0937 - val_binary_accuracy: 0.9455 - val_acc: 0.2846\n",
      "Epoch 389/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0791 - binary_accuracy: 0.9544 - acc: 0.2805 - val_loss: 0.0936 - val_binary_accuracy: 0.9456 - val_acc: 0.2778\n",
      "Epoch 390/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0789 - binary_accuracy: 0.9545 - acc: 0.2815 - val_loss: 0.0936 - val_binary_accuracy: 0.9457 - val_acc: 0.2517\n",
      "Epoch 391/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0786 - binary_accuracy: 0.9546 - acc: 0.2801 - val_loss: 0.0934 - val_binary_accuracy: 0.9459 - val_acc: 0.2600\n",
      "Epoch 392/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0783 - binary_accuracy: 0.9548 - acc: 0.2835 - val_loss: 0.0934 - val_binary_accuracy: 0.9456 - val_acc: 0.2495\n",
      "Epoch 393/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0781 - binary_accuracy: 0.9549 - acc: 0.2788 - val_loss: 0.0932 - val_binary_accuracy: 0.9460 - val_acc: 0.2391\n",
      "Epoch 394/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0778 - binary_accuracy: 0.9551 - acc: 0.2778 - val_loss: 0.0929 - val_binary_accuracy: 0.9460 - val_acc: 0.2879\n",
      "Epoch 395/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0776 - binary_accuracy: 0.9552 - acc: 0.2840 - val_loss: 0.0928 - val_binary_accuracy: 0.9461 - val_acc: 0.2550\n",
      "Epoch 396/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0773 - binary_accuracy: 0.9554 - acc: 0.2884 - val_loss: 0.0926 - val_binary_accuracy: 0.9462 - val_acc: 0.2383\n",
      "Epoch 397/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0771 - binary_accuracy: 0.9556 - acc: 0.2846 - val_loss: 0.0923 - val_binary_accuracy: 0.9465 - val_acc: 0.2380\n",
      "Epoch 398/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0767 - binary_accuracy: 0.9558 - acc: 0.2916 - val_loss: 0.0925 - val_binary_accuracy: 0.9463 - val_acc: 0.2615\n",
      "Epoch 399/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0764 - binary_accuracy: 0.9560 - acc: 0.2912 - val_loss: 0.0920 - val_binary_accuracy: 0.9465 - val_acc: 0.2611\n",
      "Epoch 400/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0762 - binary_accuracy: 0.9561 - acc: 0.2899 - val_loss: 0.0919 - val_binary_accuracy: 0.9465 - val_acc: 0.2665\n",
      "Epoch 401/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0759 - binary_accuracy: 0.9563 - acc: 0.2924 - val_loss: 0.0917 - val_binary_accuracy: 0.9467 - val_acc: 0.2604\n",
      "Epoch 402/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0757 - binary_accuracy: 0.9564 - acc: 0.2915 - val_loss: 0.0914 - val_binary_accuracy: 0.9469 - val_acc: 0.2542\n",
      "Epoch 403/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0754 - binary_accuracy: 0.9566 - acc: 0.2911 - val_loss: 0.0915 - val_binary_accuracy: 0.9468 - val_acc: 0.2788\n",
      "Epoch 404/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0750 - binary_accuracy: 0.9568 - acc: 0.2984 - val_loss: 0.0913 - val_binary_accuracy: 0.9467 - val_acc: 0.2369\n",
      "Epoch 405/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0749 - binary_accuracy: 0.9569 - acc: 0.2956 - val_loss: 0.0908 - val_binary_accuracy: 0.9472 - val_acc: 0.2622\n",
      "Epoch 406/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0745 - binary_accuracy: 0.9571 - acc: 0.2985 - val_loss: 0.0904 - val_binary_accuracy: 0.9475 - val_acc: 0.2817\n",
      "Epoch 407/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0743 - binary_accuracy: 0.9573 - acc: 0.2999 - val_loss: 0.0903 - val_binary_accuracy: 0.9476 - val_acc: 0.2684\n",
      "Epoch 408/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0740 - binary_accuracy: 0.9574 - acc: 0.3003 - val_loss: 0.0898 - val_binary_accuracy: 0.9480 - val_acc: 0.2705\n",
      "Epoch 409/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0736 - binary_accuracy: 0.9576 - acc: 0.3000 - val_loss: 0.0896 - val_binary_accuracy: 0.9479 - val_acc: 0.2727\n",
      "Epoch 410/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0734 - binary_accuracy: 0.9577 - acc: 0.2985 - val_loss: 0.0898 - val_binary_accuracy: 0.9477 - val_acc: 0.2937\n",
      "Epoch 411/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0732 - binary_accuracy: 0.9579 - acc: 0.2911 - val_loss: 0.0892 - val_binary_accuracy: 0.9481 - val_acc: 0.2716\n",
      "Epoch 412/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0729 - binary_accuracy: 0.9581 - acc: 0.2930 - val_loss: 0.0889 - val_binary_accuracy: 0.9482 - val_acc: 0.2843\n",
      "Epoch 413/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0725 - binary_accuracy: 0.9582 - acc: 0.2906 - val_loss: 0.0888 - val_binary_accuracy: 0.9483 - val_acc: 0.2427\n",
      "Epoch 414/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0722 - binary_accuracy: 0.9585 - acc: 0.2889 - val_loss: 0.0885 - val_binary_accuracy: 0.9483 - val_acc: 0.2893\n",
      "Epoch 415/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0720 - binary_accuracy: 0.9586 - acc: 0.2967 - val_loss: 0.0881 - val_binary_accuracy: 0.9488 - val_acc: 0.2597\n",
      "Epoch 416/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0718 - binary_accuracy: 0.9587 - acc: 0.2795 - val_loss: 0.0878 - val_binary_accuracy: 0.9489 - val_acc: 0.2517\n",
      "Epoch 417/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0713 - binary_accuracy: 0.9589 - acc: 0.2796 - val_loss: 0.0877 - val_binary_accuracy: 0.9488 - val_acc: 0.2423\n",
      "Epoch 418/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0712 - binary_accuracy: 0.9590 - acc: 0.2885 - val_loss: 0.0873 - val_binary_accuracy: 0.9493 - val_acc: 0.2676\n",
      "Epoch 419/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0707 - binary_accuracy: 0.9593 - acc: 0.2879 - val_loss: 0.0871 - val_binary_accuracy: 0.9490 - val_acc: 0.2741\n",
      "Epoch 420/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0704 - binary_accuracy: 0.9595 - acc: 0.2855 - val_loss: 0.0869 - val_binary_accuracy: 0.9491 - val_acc: 0.2434\n",
      "Epoch 421/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0700 - binary_accuracy: 0.9598 - acc: 0.2787 - val_loss: 0.0864 - val_binary_accuracy: 0.9495 - val_acc: 0.2546\n",
      "Epoch 422/4000\n",
      "15667/15667 [==============================] - 0s 20us/step - loss: 0.0697 - binary_accuracy: 0.9600 - acc: 0.2787 - val_loss: 0.0859 - val_binary_accuracy: 0.9498 - val_acc: 0.2445\n",
      "Epoch 423/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0693 - binary_accuracy: 0.9602 - acc: 0.2796 - val_loss: 0.0860 - val_binary_accuracy: 0.9498 - val_acc: 0.2814\n",
      "Epoch 424/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0691 - binary_accuracy: 0.9604 - acc: 0.2796 - val_loss: 0.0860 - val_binary_accuracy: 0.9499 - val_acc: 0.2510\n",
      "Epoch 425/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0688 - binary_accuracy: 0.9605 - acc: 0.2801 - val_loss: 0.0855 - val_binary_accuracy: 0.9499 - val_acc: 0.2774\n",
      "Epoch 426/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0684 - binary_accuracy: 0.9607 - acc: 0.2792 - val_loss: 0.0849 - val_binary_accuracy: 0.9505 - val_acc: 0.2524\n",
      "Epoch 427/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0681 - binary_accuracy: 0.9610 - acc: 0.2747 - val_loss: 0.0847 - val_binary_accuracy: 0.9507 - val_acc: 0.2412\n",
      "Epoch 428/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0677 - binary_accuracy: 0.9612 - acc: 0.2778 - val_loss: 0.0845 - val_binary_accuracy: 0.9505 - val_acc: 0.2770\n",
      "Epoch 429/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0674 - binary_accuracy: 0.9613 - acc: 0.2798 - val_loss: 0.0842 - val_binary_accuracy: 0.9509 - val_acc: 0.2514\n",
      "Epoch 430/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0672 - binary_accuracy: 0.9615 - acc: 0.2724 - val_loss: 0.0838 - val_binary_accuracy: 0.9511 - val_acc: 0.2347\n",
      "Epoch 431/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0669 - binary_accuracy: 0.9617 - acc: 0.2782 - val_loss: 0.0838 - val_binary_accuracy: 0.9511 - val_acc: 0.2593\n",
      "Epoch 432/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0666 - binary_accuracy: 0.9618 - acc: 0.2727 - val_loss: 0.0833 - val_binary_accuracy: 0.9514 - val_acc: 0.2495\n",
      "Epoch 433/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0664 - binary_accuracy: 0.9620 - acc: 0.2704 - val_loss: 0.0832 - val_binary_accuracy: 0.9515 - val_acc: 0.2524\n",
      "Epoch 434/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0661 - binary_accuracy: 0.9621 - acc: 0.2676 - val_loss: 0.0828 - val_binary_accuracy: 0.9518 - val_acc: 0.2434\n",
      "Epoch 435/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0658 - binary_accuracy: 0.9623 - acc: 0.2706 - val_loss: 0.0826 - val_binary_accuracy: 0.9520 - val_acc: 0.2474\n",
      "Epoch 436/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0655 - binary_accuracy: 0.9625 - acc: 0.2678 - val_loss: 0.0823 - val_binary_accuracy: 0.9521 - val_acc: 0.2373\n",
      "Epoch 437/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0652 - binary_accuracy: 0.9626 - acc: 0.2581 - val_loss: 0.0821 - val_binary_accuracy: 0.9521 - val_acc: 0.2282\n",
      "Epoch 438/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0650 - binary_accuracy: 0.9628 - acc: 0.2563 - val_loss: 0.0817 - val_binary_accuracy: 0.9526 - val_acc: 0.2278\n",
      "Epoch 439/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0647 - binary_accuracy: 0.9630 - acc: 0.2498 - val_loss: 0.0815 - val_binary_accuracy: 0.9527 - val_acc: 0.2373\n",
      "Epoch 440/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0644 - binary_accuracy: 0.9631 - acc: 0.2519 - val_loss: 0.0812 - val_binary_accuracy: 0.9528 - val_acc: 0.2177\n",
      "Epoch 441/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0640 - binary_accuracy: 0.9634 - acc: 0.2410 - val_loss: 0.0810 - val_binary_accuracy: 0.9529 - val_acc: 0.2351\n",
      "Epoch 442/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0638 - binary_accuracy: 0.9635 - acc: 0.2485 - val_loss: 0.0808 - val_binary_accuracy: 0.9530 - val_acc: 0.2166\n",
      "Epoch 443/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0635 - binary_accuracy: 0.9637 - acc: 0.2413 - val_loss: 0.0805 - val_binary_accuracy: 0.9532 - val_acc: 0.1863\n",
      "Epoch 444/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0632 - binary_accuracy: 0.9638 - acc: 0.2360 - val_loss: 0.0804 - val_binary_accuracy: 0.9531 - val_acc: 0.1931\n",
      "Epoch 445/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0629 - binary_accuracy: 0.9640 - acc: 0.2358 - val_loss: 0.0800 - val_binary_accuracy: 0.9537 - val_acc: 0.2134\n",
      "Epoch 446/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0626 - binary_accuracy: 0.9642 - acc: 0.2353 - val_loss: 0.0796 - val_binary_accuracy: 0.9539 - val_acc: 0.2098\n",
      "Epoch 447/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0622 - binary_accuracy: 0.9644 - acc: 0.2347 - val_loss: 0.0795 - val_binary_accuracy: 0.9538 - val_acc: 0.2174\n",
      "Epoch 448/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0620 - binary_accuracy: 0.9646 - acc: 0.2387 - val_loss: 0.0794 - val_binary_accuracy: 0.9538 - val_acc: 0.2188\n",
      "Epoch 449/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0618 - binary_accuracy: 0.9647 - acc: 0.2389 - val_loss: 0.0791 - val_binary_accuracy: 0.9540 - val_acc: 0.1971\n",
      "Epoch 450/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0615 - binary_accuracy: 0.9648 - acc: 0.2385 - val_loss: 0.0789 - val_binary_accuracy: 0.9539 - val_acc: 0.2300\n",
      "Epoch 451/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0612 - binary_accuracy: 0.9651 - acc: 0.2355 - val_loss: 0.0786 - val_binary_accuracy: 0.9543 - val_acc: 0.2072\n",
      "Epoch 452/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0610 - binary_accuracy: 0.9651 - acc: 0.2307 - val_loss: 0.0787 - val_binary_accuracy: 0.9545 - val_acc: 0.2470\n",
      "Epoch 453/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0608 - binary_accuracy: 0.9654 - acc: 0.2362 - val_loss: 0.0782 - val_binary_accuracy: 0.9546 - val_acc: 0.1964\n",
      "Epoch 454/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0605 - binary_accuracy: 0.9654 - acc: 0.2364 - val_loss: 0.0779 - val_binary_accuracy: 0.9546 - val_acc: 0.1808\n",
      "Epoch 455/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0603 - binary_accuracy: 0.9656 - acc: 0.2308 - val_loss: 0.0777 - val_binary_accuracy: 0.9549 - val_acc: 0.2123\n",
      "Epoch 456/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0601 - binary_accuracy: 0.9657 - acc: 0.2344 - val_loss: 0.0775 - val_binary_accuracy: 0.9550 - val_acc: 0.1996\n",
      "Epoch 457/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0599 - binary_accuracy: 0.9658 - acc: 0.2373 - val_loss: 0.0771 - val_binary_accuracy: 0.9554 - val_acc: 0.2069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0596 - binary_accuracy: 0.9659 - acc: 0.2346 - val_loss: 0.0771 - val_binary_accuracy: 0.9554 - val_acc: 0.2033\n",
      "Epoch 459/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0594 - binary_accuracy: 0.9661 - acc: 0.2364 - val_loss: 0.0767 - val_binary_accuracy: 0.9556 - val_acc: 0.2040\n",
      "Epoch 460/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0591 - binary_accuracy: 0.9662 - acc: 0.2358 - val_loss: 0.0766 - val_binary_accuracy: 0.9557 - val_acc: 0.2007\n",
      "Epoch 461/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0589 - binary_accuracy: 0.9664 - acc: 0.2263 - val_loss: 0.0766 - val_binary_accuracy: 0.9556 - val_acc: 0.1982\n",
      "Epoch 462/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0587 - binary_accuracy: 0.9665 - acc: 0.2370 - val_loss: 0.0762 - val_binary_accuracy: 0.9560 - val_acc: 0.2094\n",
      "Epoch 463/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0585 - binary_accuracy: 0.9666 - acc: 0.2363 - val_loss: 0.0760 - val_binary_accuracy: 0.9560 - val_acc: 0.2253\n",
      "Epoch 464/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0583 - binary_accuracy: 0.9668 - acc: 0.2392 - val_loss: 0.0757 - val_binary_accuracy: 0.9562 - val_acc: 0.1917\n",
      "Epoch 465/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0581 - binary_accuracy: 0.9669 - acc: 0.2339 - val_loss: 0.0756 - val_binary_accuracy: 0.9561 - val_acc: 0.1928\n",
      "Epoch 466/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0579 - binary_accuracy: 0.9670 - acc: 0.2401 - val_loss: 0.0754 - val_binary_accuracy: 0.9564 - val_acc: 0.1982\n",
      "Epoch 467/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0576 - binary_accuracy: 0.9671 - acc: 0.2387 - val_loss: 0.0753 - val_binary_accuracy: 0.9564 - val_acc: 0.2022\n",
      "Epoch 468/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0574 - binary_accuracy: 0.9673 - acc: 0.2418 - val_loss: 0.0752 - val_binary_accuracy: 0.9563 - val_acc: 0.2051\n",
      "Epoch 469/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0572 - binary_accuracy: 0.9674 - acc: 0.2468 - val_loss: 0.0750 - val_binary_accuracy: 0.9566 - val_acc: 0.2087\n",
      "Epoch 470/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0570 - binary_accuracy: 0.9675 - acc: 0.2471 - val_loss: 0.0747 - val_binary_accuracy: 0.9568 - val_acc: 0.1834\n",
      "Epoch 471/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0567 - binary_accuracy: 0.9677 - acc: 0.2410 - val_loss: 0.0749 - val_binary_accuracy: 0.9569 - val_acc: 0.2011\n",
      "Epoch 472/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0566 - binary_accuracy: 0.9678 - acc: 0.2390 - val_loss: 0.0746 - val_binary_accuracy: 0.9569 - val_acc: 0.2080\n",
      "Epoch 473/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0563 - binary_accuracy: 0.9679 - acc: 0.2424 - val_loss: 0.0743 - val_binary_accuracy: 0.9568 - val_acc: 0.2058\n",
      "Epoch 474/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0560 - binary_accuracy: 0.9681 - acc: 0.2444 - val_loss: 0.0741 - val_binary_accuracy: 0.9571 - val_acc: 0.2159\n",
      "Epoch 475/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0560 - binary_accuracy: 0.9681 - acc: 0.2436 - val_loss: 0.0741 - val_binary_accuracy: 0.9571 - val_acc: 0.2033\n",
      "Epoch 476/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0557 - binary_accuracy: 0.9683 - acc: 0.2371 - val_loss: 0.0740 - val_binary_accuracy: 0.9571 - val_acc: 0.2007\n",
      "Epoch 477/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0555 - binary_accuracy: 0.9684 - acc: 0.2441 - val_loss: 0.0740 - val_binary_accuracy: 0.9573 - val_acc: 0.2231\n",
      "Epoch 478/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0552 - binary_accuracy: 0.9685 - acc: 0.2367 - val_loss: 0.0735 - val_binary_accuracy: 0.9574 - val_acc: 0.2336\n",
      "Epoch 479/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0552 - binary_accuracy: 0.9685 - acc: 0.2433 - val_loss: 0.0739 - val_binary_accuracy: 0.9573 - val_acc: 0.2250\n",
      "Epoch 480/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0550 - binary_accuracy: 0.9687 - acc: 0.2380 - val_loss: 0.0732 - val_binary_accuracy: 0.9577 - val_acc: 0.1960\n",
      "Epoch 481/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0547 - binary_accuracy: 0.9688 - acc: 0.2429 - val_loss: 0.0732 - val_binary_accuracy: 0.9578 - val_acc: 0.2217\n",
      "Epoch 482/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0545 - binary_accuracy: 0.9690 - acc: 0.2473 - val_loss: 0.0730 - val_binary_accuracy: 0.9578 - val_acc: 0.2351\n",
      "Epoch 483/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0543 - binary_accuracy: 0.9691 - acc: 0.2450 - val_loss: 0.0727 - val_binary_accuracy: 0.9580 - val_acc: 0.2152\n",
      "Epoch 484/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0541 - binary_accuracy: 0.9692 - acc: 0.2426 - val_loss: 0.0728 - val_binary_accuracy: 0.9578 - val_acc: 0.2369\n",
      "Epoch 485/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0539 - binary_accuracy: 0.9693 - acc: 0.2464 - val_loss: 0.0724 - val_binary_accuracy: 0.9580 - val_acc: 0.2224\n",
      "Epoch 486/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0539 - binary_accuracy: 0.9694 - acc: 0.2399 - val_loss: 0.0725 - val_binary_accuracy: 0.9580 - val_acc: 0.2235\n",
      "Epoch 487/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0536 - binary_accuracy: 0.9695 - acc: 0.2477 - val_loss: 0.0722 - val_binary_accuracy: 0.9579 - val_acc: 0.2210\n",
      "Epoch 488/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0535 - binary_accuracy: 0.9695 - acc: 0.2441 - val_loss: 0.0722 - val_binary_accuracy: 0.9580 - val_acc: 0.2680\n",
      "Epoch 489/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0534 - binary_accuracy: 0.9696 - acc: 0.2484 - val_loss: 0.0717 - val_binary_accuracy: 0.9583 - val_acc: 0.2253\n",
      "Epoch 490/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0532 - binary_accuracy: 0.9697 - acc: 0.2448 - val_loss: 0.0716 - val_binary_accuracy: 0.9585 - val_acc: 0.2130\n",
      "Epoch 491/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0532 - binary_accuracy: 0.9697 - acc: 0.2454 - val_loss: 0.0715 - val_binary_accuracy: 0.9586 - val_acc: 0.2210\n",
      "Epoch 492/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0529 - binary_accuracy: 0.9698 - acc: 0.2480 - val_loss: 0.0711 - val_binary_accuracy: 0.9588 - val_acc: 0.2159\n",
      "Epoch 493/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0528 - binary_accuracy: 0.9699 - acc: 0.2493 - val_loss: 0.0711 - val_binary_accuracy: 0.9588 - val_acc: 0.2297\n",
      "Epoch 494/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0527 - binary_accuracy: 0.9700 - acc: 0.2453 - val_loss: 0.0711 - val_binary_accuracy: 0.9587 - val_acc: 0.2268\n",
      "Epoch 495/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0525 - binary_accuracy: 0.9701 - acc: 0.2514 - val_loss: 0.0707 - val_binary_accuracy: 0.9590 - val_acc: 0.2401\n",
      "Epoch 496/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0523 - binary_accuracy: 0.9702 - acc: 0.2570 - val_loss: 0.0707 - val_binary_accuracy: 0.9590 - val_acc: 0.2253\n",
      "Epoch 497/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0521 - binary_accuracy: 0.9703 - acc: 0.2575 - val_loss: 0.0705 - val_binary_accuracy: 0.9588 - val_acc: 0.2521\n",
      "Epoch 498/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0520 - binary_accuracy: 0.9703 - acc: 0.2616 - val_loss: 0.0704 - val_binary_accuracy: 0.9592 - val_acc: 0.2467\n",
      "Epoch 499/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0519 - binary_accuracy: 0.9705 - acc: 0.2594 - val_loss: 0.0707 - val_binary_accuracy: 0.9590 - val_acc: 0.2394\n",
      "Epoch 500/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0517 - binary_accuracy: 0.9705 - acc: 0.2626 - val_loss: 0.0700 - val_binary_accuracy: 0.9596 - val_acc: 0.2235\n",
      "Epoch 501/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0515 - binary_accuracy: 0.9707 - acc: 0.2625 - val_loss: 0.0699 - val_binary_accuracy: 0.9596 - val_acc: 0.2286\n",
      "Epoch 502/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0513 - binary_accuracy: 0.9707 - acc: 0.2621 - val_loss: 0.0702 - val_binary_accuracy: 0.9595 - val_acc: 0.2676\n",
      "Epoch 503/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0512 - binary_accuracy: 0.9709 - acc: 0.2636 - val_loss: 0.0697 - val_binary_accuracy: 0.9597 - val_acc: 0.2177\n",
      "Epoch 504/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0511 - binary_accuracy: 0.9709 - acc: 0.2620 - val_loss: 0.0694 - val_binary_accuracy: 0.9599 - val_acc: 0.2250\n",
      "Epoch 505/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0509 - binary_accuracy: 0.9710 - acc: 0.2613 - val_loss: 0.0694 - val_binary_accuracy: 0.9600 - val_acc: 0.2441\n",
      "Epoch 506/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0508 - binary_accuracy: 0.9711 - acc: 0.2673 - val_loss: 0.0692 - val_binary_accuracy: 0.9600 - val_acc: 0.2141\n",
      "Epoch 507/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0506 - binary_accuracy: 0.9711 - acc: 0.2651 - val_loss: 0.0687 - val_binary_accuracy: 0.9606 - val_acc: 0.2420\n",
      "Epoch 508/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0505 - binary_accuracy: 0.9712 - acc: 0.2715 - val_loss: 0.0688 - val_binary_accuracy: 0.9602 - val_acc: 0.2517\n",
      "Epoch 509/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0504 - binary_accuracy: 0.9713 - acc: 0.2692 - val_loss: 0.0687 - val_binary_accuracy: 0.9605 - val_acc: 0.2477\n",
      "Epoch 510/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0503 - binary_accuracy: 0.9714 - acc: 0.2772 - val_loss: 0.0685 - val_binary_accuracy: 0.9606 - val_acc: 0.2488\n",
      "Epoch 511/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0501 - binary_accuracy: 0.9714 - acc: 0.2745 - val_loss: 0.0683 - val_binary_accuracy: 0.9606 - val_acc: 0.2459\n",
      "Epoch 512/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0500 - binary_accuracy: 0.9715 - acc: 0.2777 - val_loss: 0.0687 - val_binary_accuracy: 0.9602 - val_acc: 0.2445\n",
      "Epoch 513/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0498 - binary_accuracy: 0.9716 - acc: 0.2810 - val_loss: 0.0682 - val_binary_accuracy: 0.9606 - val_acc: 0.2901\n",
      "Epoch 514/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0497 - binary_accuracy: 0.9716 - acc: 0.2802 - val_loss: 0.0681 - val_binary_accuracy: 0.9606 - val_acc: 0.2633\n",
      "Epoch 515/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0496 - binary_accuracy: 0.9717 - acc: 0.2759 - val_loss: 0.0678 - val_binary_accuracy: 0.9609 - val_acc: 0.2420\n",
      "Epoch 516/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0495 - binary_accuracy: 0.9718 - acc: 0.2824 - val_loss: 0.0678 - val_binary_accuracy: 0.9610 - val_acc: 0.2459\n",
      "Epoch 517/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0495 - binary_accuracy: 0.9718 - acc: 0.2833 - val_loss: 0.0677 - val_binary_accuracy: 0.9609 - val_acc: 0.2271\n",
      "Epoch 518/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0494 - binary_accuracy: 0.9718 - acc: 0.2849 - val_loss: 0.0678 - val_binary_accuracy: 0.9608 - val_acc: 0.2705\n",
      "Epoch 519/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0493 - binary_accuracy: 0.9719 - acc: 0.2890 - val_loss: 0.0675 - val_binary_accuracy: 0.9612 - val_acc: 0.2669\n",
      "Epoch 520/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0491 - binary_accuracy: 0.9720 - acc: 0.2867 - val_loss: 0.0674 - val_binary_accuracy: 0.9614 - val_acc: 0.2716\n",
      "Epoch 521/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0490 - binary_accuracy: 0.9720 - acc: 0.2955 - val_loss: 0.0673 - val_binary_accuracy: 0.9611 - val_acc: 0.2702\n",
      "Epoch 522/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0489 - binary_accuracy: 0.9721 - acc: 0.2948 - val_loss: 0.0672 - val_binary_accuracy: 0.9611 - val_acc: 0.2608\n",
      "Epoch 523/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0488 - binary_accuracy: 0.9721 - acc: 0.2948 - val_loss: 0.0671 - val_binary_accuracy: 0.9611 - val_acc: 0.2600\n",
      "Epoch 524/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0487 - binary_accuracy: 0.9722 - acc: 0.2972 - val_loss: 0.0671 - val_binary_accuracy: 0.9611 - val_acc: 0.2647\n",
      "Epoch 525/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0486 - binary_accuracy: 0.9723 - acc: 0.2987 - val_loss: 0.0670 - val_binary_accuracy: 0.9616 - val_acc: 0.2702\n",
      "Epoch 526/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0485 - binary_accuracy: 0.9723 - acc: 0.3010 - val_loss: 0.0669 - val_binary_accuracy: 0.9612 - val_acc: 0.2741\n",
      "Epoch 527/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0484 - binary_accuracy: 0.9724 - acc: 0.3018 - val_loss: 0.0666 - val_binary_accuracy: 0.9617 - val_acc: 0.2600\n",
      "Epoch 528/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0482 - binary_accuracy: 0.9724 - acc: 0.3018 - val_loss: 0.0668 - val_binary_accuracy: 0.9616 - val_acc: 0.2788\n",
      "Epoch 529/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0481 - binary_accuracy: 0.9725 - acc: 0.3040 - val_loss: 0.0665 - val_binary_accuracy: 0.9616 - val_acc: 0.2694\n",
      "Epoch 530/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0480 - binary_accuracy: 0.9726 - acc: 0.3147 - val_loss: 0.0666 - val_binary_accuracy: 0.9615 - val_acc: 0.2778\n",
      "Epoch 531/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0479 - binary_accuracy: 0.9726 - acc: 0.3114 - val_loss: 0.0662 - val_binary_accuracy: 0.9618 - val_acc: 0.2647\n",
      "Epoch 532/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0478 - binary_accuracy: 0.9727 - acc: 0.3080 - val_loss: 0.0663 - val_binary_accuracy: 0.9616 - val_acc: 0.2922\n",
      "Epoch 533/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0477 - binary_accuracy: 0.9727 - acc: 0.3140 - val_loss: 0.0660 - val_binary_accuracy: 0.9619 - val_acc: 0.2846\n",
      "Epoch 534/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0476 - binary_accuracy: 0.9728 - acc: 0.3146 - val_loss: 0.0662 - val_binary_accuracy: 0.9617 - val_acc: 0.2720\n",
      "Epoch 535/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0475 - binary_accuracy: 0.9729 - acc: 0.3108 - val_loss: 0.0659 - val_binary_accuracy: 0.9620 - val_acc: 0.2788\n",
      "Epoch 536/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0474 - binary_accuracy: 0.9729 - acc: 0.3151 - val_loss: 0.0657 - val_binary_accuracy: 0.9623 - val_acc: 0.2897\n",
      "Epoch 537/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0473 - binary_accuracy: 0.9730 - acc: 0.3165 - val_loss: 0.0658 - val_binary_accuracy: 0.9622 - val_acc: 0.2962\n",
      "Epoch 538/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0472 - binary_accuracy: 0.9730 - acc: 0.3168 - val_loss: 0.0657 - val_binary_accuracy: 0.9620 - val_acc: 0.2817\n",
      "Epoch 539/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0471 - binary_accuracy: 0.9731 - acc: 0.3112 - val_loss: 0.0658 - val_binary_accuracy: 0.9623 - val_acc: 0.2951\n",
      "Epoch 540/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0469 - binary_accuracy: 0.9732 - acc: 0.3157 - val_loss: 0.0653 - val_binary_accuracy: 0.9623 - val_acc: 0.2901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 541/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0469 - binary_accuracy: 0.9732 - acc: 0.3168 - val_loss: 0.0653 - val_binary_accuracy: 0.9624 - val_acc: 0.2984\n",
      "Epoch 542/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0468 - binary_accuracy: 0.9732 - acc: 0.3186 - val_loss: 0.0652 - val_binary_accuracy: 0.9623 - val_acc: 0.2879\n",
      "Epoch 543/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0466 - binary_accuracy: 0.9733 - acc: 0.3094 - val_loss: 0.0648 - val_binary_accuracy: 0.9627 - val_acc: 0.2948\n",
      "Epoch 544/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0465 - binary_accuracy: 0.9734 - acc: 0.3153 - val_loss: 0.0647 - val_binary_accuracy: 0.9629 - val_acc: 0.2803\n",
      "Epoch 545/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0465 - binary_accuracy: 0.9734 - acc: 0.3211 - val_loss: 0.0650 - val_binary_accuracy: 0.9625 - val_acc: 0.2944\n",
      "Epoch 546/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0463 - binary_accuracy: 0.9735 - acc: 0.3189 - val_loss: 0.0648 - val_binary_accuracy: 0.9625 - val_acc: 0.2911\n",
      "Epoch 547/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0463 - binary_accuracy: 0.9735 - acc: 0.3188 - val_loss: 0.0648 - val_binary_accuracy: 0.9628 - val_acc: 0.2857\n",
      "Epoch 548/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0461 - binary_accuracy: 0.9736 - acc: 0.3158 - val_loss: 0.0644 - val_binary_accuracy: 0.9630 - val_acc: 0.2644\n",
      "Epoch 549/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0460 - binary_accuracy: 0.9737 - acc: 0.3134 - val_loss: 0.0645 - val_binary_accuracy: 0.9628 - val_acc: 0.2980\n",
      "Epoch 550/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0459 - binary_accuracy: 0.9738 - acc: 0.3092 - val_loss: 0.0644 - val_binary_accuracy: 0.9630 - val_acc: 0.2698\n",
      "Epoch 551/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0458 - binary_accuracy: 0.9738 - acc: 0.3204 - val_loss: 0.0643 - val_binary_accuracy: 0.9630 - val_acc: 0.2510\n",
      "Epoch 552/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0457 - binary_accuracy: 0.9739 - acc: 0.3165 - val_loss: 0.0642 - val_binary_accuracy: 0.9632 - val_acc: 0.2759\n",
      "Epoch 553/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0456 - binary_accuracy: 0.9739 - acc: 0.3168 - val_loss: 0.0645 - val_binary_accuracy: 0.9627 - val_acc: 0.2897\n",
      "Epoch 554/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0456 - binary_accuracy: 0.9739 - acc: 0.3163 - val_loss: 0.0639 - val_binary_accuracy: 0.9631 - val_acc: 0.2864\n",
      "Epoch 555/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0454 - binary_accuracy: 0.9740 - acc: 0.3156 - val_loss: 0.0639 - val_binary_accuracy: 0.9631 - val_acc: 0.2741\n",
      "Epoch 556/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0454 - binary_accuracy: 0.9740 - acc: 0.3190 - val_loss: 0.0638 - val_binary_accuracy: 0.9634 - val_acc: 0.2712\n",
      "Epoch 557/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0453 - binary_accuracy: 0.9740 - acc: 0.3163 - val_loss: 0.0639 - val_binary_accuracy: 0.9631 - val_acc: 0.2665\n",
      "Epoch 558/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0452 - binary_accuracy: 0.9740 - acc: 0.3229 - val_loss: 0.0637 - val_binary_accuracy: 0.9632 - val_acc: 0.2669\n",
      "Epoch 559/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0452 - binary_accuracy: 0.9741 - acc: 0.3221 - val_loss: 0.0636 - val_binary_accuracy: 0.9633 - val_acc: 0.2825\n",
      "Epoch 560/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0452 - binary_accuracy: 0.9741 - acc: 0.3232 - val_loss: 0.0637 - val_binary_accuracy: 0.9634 - val_acc: 0.2933\n",
      "Epoch 561/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0451 - binary_accuracy: 0.9741 - acc: 0.3295 - val_loss: 0.0637 - val_binary_accuracy: 0.9632 - val_acc: 0.3103\n",
      "Epoch 562/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0451 - binary_accuracy: 0.9741 - acc: 0.3295 - val_loss: 0.0636 - val_binary_accuracy: 0.9632 - val_acc: 0.2893\n",
      "Epoch 563/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0450 - binary_accuracy: 0.9742 - acc: 0.3338 - val_loss: 0.0638 - val_binary_accuracy: 0.9630 - val_acc: 0.3103\n",
      "Epoch 564/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0449 - binary_accuracy: 0.9742 - acc: 0.3343 - val_loss: 0.0636 - val_binary_accuracy: 0.9634 - val_acc: 0.3016\n",
      "Epoch 565/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0449 - binary_accuracy: 0.9742 - acc: 0.3382 - val_loss: 0.0635 - val_binary_accuracy: 0.9634 - val_acc: 0.2976\n",
      "Epoch 566/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0448 - binary_accuracy: 0.9742 - acc: 0.3383 - val_loss: 0.0635 - val_binary_accuracy: 0.9632 - val_acc: 0.3020\n",
      "Epoch 567/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0448 - binary_accuracy: 0.9743 - acc: 0.3381 - val_loss: 0.0634 - val_binary_accuracy: 0.9634 - val_acc: 0.2973\n",
      "Epoch 568/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0447 - binary_accuracy: 0.9743 - acc: 0.3403 - val_loss: 0.0635 - val_binary_accuracy: 0.9630 - val_acc: 0.3262\n",
      "Epoch 569/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0447 - binary_accuracy: 0.9743 - acc: 0.3456 - val_loss: 0.0635 - val_binary_accuracy: 0.9632 - val_acc: 0.2843\n",
      "Epoch 570/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0446 - binary_accuracy: 0.9743 - acc: 0.3392 - val_loss: 0.0632 - val_binary_accuracy: 0.9634 - val_acc: 0.3002\n",
      "Epoch 571/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0446 - binary_accuracy: 0.9744 - acc: 0.3448 - val_loss: 0.0632 - val_binary_accuracy: 0.9633 - val_acc: 0.2854\n",
      "Epoch 572/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0445 - binary_accuracy: 0.9744 - acc: 0.3402 - val_loss: 0.0630 - val_binary_accuracy: 0.9635 - val_acc: 0.2940\n",
      "Epoch 573/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0444 - binary_accuracy: 0.9744 - acc: 0.3392 - val_loss: 0.0631 - val_binary_accuracy: 0.9635 - val_acc: 0.3074\n",
      "Epoch 574/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0444 - binary_accuracy: 0.9745 - acc: 0.3422 - val_loss: 0.0632 - val_binary_accuracy: 0.9634 - val_acc: 0.3099\n",
      "Epoch 575/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0444 - binary_accuracy: 0.9745 - acc: 0.3403 - val_loss: 0.0631 - val_binary_accuracy: 0.9634 - val_acc: 0.3172\n",
      "Epoch 576/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0443 - binary_accuracy: 0.9745 - acc: 0.3472 - val_loss: 0.0628 - val_binary_accuracy: 0.9637 - val_acc: 0.2919\n",
      "Epoch 577/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0443 - binary_accuracy: 0.9745 - acc: 0.3486 - val_loss: 0.0628 - val_binary_accuracy: 0.9635 - val_acc: 0.2966\n",
      "Epoch 578/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0442 - binary_accuracy: 0.9745 - acc: 0.3486 - val_loss: 0.0629 - val_binary_accuracy: 0.9635 - val_acc: 0.3049\n",
      "Epoch 579/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0442 - binary_accuracy: 0.9746 - acc: 0.3408 - val_loss: 0.0630 - val_binary_accuracy: 0.9634 - val_acc: 0.2893\n",
      "Epoch 580/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0441 - binary_accuracy: 0.9746 - acc: 0.3446 - val_loss: 0.0628 - val_binary_accuracy: 0.9636 - val_acc: 0.3212\n",
      "Epoch 581/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0441 - binary_accuracy: 0.9746 - acc: 0.3458 - val_loss: 0.0631 - val_binary_accuracy: 0.9634 - val_acc: 0.3099\n",
      "Epoch 582/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0440 - binary_accuracy: 0.9746 - acc: 0.3412 - val_loss: 0.0628 - val_binary_accuracy: 0.9633 - val_acc: 0.3114\n",
      "Epoch 583/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0440 - binary_accuracy: 0.9747 - acc: 0.3523 - val_loss: 0.0629 - val_binary_accuracy: 0.9634 - val_acc: 0.3179\n",
      "Epoch 584/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0439 - binary_accuracy: 0.9747 - acc: 0.3559 - val_loss: 0.0629 - val_binary_accuracy: 0.9636 - val_acc: 0.3288\n",
      "Epoch 585/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0439 - binary_accuracy: 0.9747 - acc: 0.3529 - val_loss: 0.0626 - val_binary_accuracy: 0.9638 - val_acc: 0.3201\n",
      "Epoch 586/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0438 - binary_accuracy: 0.9748 - acc: 0.3522 - val_loss: 0.0624 - val_binary_accuracy: 0.9639 - val_acc: 0.3078\n",
      "Epoch 587/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0437 - binary_accuracy: 0.9748 - acc: 0.3599 - val_loss: 0.0628 - val_binary_accuracy: 0.9635 - val_acc: 0.3360\n",
      "Epoch 588/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0437 - binary_accuracy: 0.9748 - acc: 0.3598 - val_loss: 0.0626 - val_binary_accuracy: 0.9636 - val_acc: 0.3110\n",
      "Epoch 589/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0437 - binary_accuracy: 0.9748 - acc: 0.3634 - val_loss: 0.0625 - val_binary_accuracy: 0.9636 - val_acc: 0.3602\n",
      "Epoch 590/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0436 - binary_accuracy: 0.9749 - acc: 0.3569 - val_loss: 0.0624 - val_binary_accuracy: 0.9638 - val_acc: 0.3400\n",
      "Epoch 591/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0435 - binary_accuracy: 0.9749 - acc: 0.3634 - val_loss: 0.0622 - val_binary_accuracy: 0.9638 - val_acc: 0.3331\n",
      "Epoch 592/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0435 - binary_accuracy: 0.9749 - acc: 0.3639 - val_loss: 0.0621 - val_binary_accuracy: 0.9641 - val_acc: 0.3284\n",
      "Epoch 593/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0435 - binary_accuracy: 0.9749 - acc: 0.3691 - val_loss: 0.0622 - val_binary_accuracy: 0.9642 - val_acc: 0.3541\n",
      "Epoch 594/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0435 - binary_accuracy: 0.9749 - acc: 0.3674 - val_loss: 0.0623 - val_binary_accuracy: 0.9640 - val_acc: 0.3327\n",
      "Epoch 595/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0434 - binary_accuracy: 0.9750 - acc: 0.3665 - val_loss: 0.0621 - val_binary_accuracy: 0.9640 - val_acc: 0.3197\n",
      "Epoch 596/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0434 - binary_accuracy: 0.9750 - acc: 0.3678 - val_loss: 0.0617 - val_binary_accuracy: 0.9644 - val_acc: 0.3269\n",
      "Epoch 597/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0433 - binary_accuracy: 0.9750 - acc: 0.3744 - val_loss: 0.0622 - val_binary_accuracy: 0.9642 - val_acc: 0.3400\n",
      "Epoch 598/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0432 - binary_accuracy: 0.9750 - acc: 0.3721 - val_loss: 0.0617 - val_binary_accuracy: 0.9644 - val_acc: 0.3288\n",
      "Epoch 599/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0432 - binary_accuracy: 0.9751 - acc: 0.3650 - val_loss: 0.0621 - val_binary_accuracy: 0.9642 - val_acc: 0.3277\n",
      "Epoch 600/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0431 - binary_accuracy: 0.9751 - acc: 0.3715 - val_loss: 0.0618 - val_binary_accuracy: 0.9644 - val_acc: 0.3327\n",
      "Epoch 601/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0431 - binary_accuracy: 0.9752 - acc: 0.3678 - val_loss: 0.0618 - val_binary_accuracy: 0.9643 - val_acc: 0.3179\n",
      "Epoch 602/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0430 - binary_accuracy: 0.9752 - acc: 0.3745 - val_loss: 0.0617 - val_binary_accuracy: 0.9644 - val_acc: 0.3367\n",
      "Epoch 603/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0430 - binary_accuracy: 0.9752 - acc: 0.3818 - val_loss: 0.0616 - val_binary_accuracy: 0.9643 - val_acc: 0.3146\n",
      "Epoch 604/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0430 - binary_accuracy: 0.9752 - acc: 0.3818 - val_loss: 0.0618 - val_binary_accuracy: 0.9642 - val_acc: 0.3555\n",
      "Epoch 605/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0429 - binary_accuracy: 0.9753 - acc: 0.3849 - val_loss: 0.0616 - val_binary_accuracy: 0.9645 - val_acc: 0.3248\n",
      "Epoch 606/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0428 - binary_accuracy: 0.9753 - acc: 0.3825 - val_loss: 0.0617 - val_binary_accuracy: 0.9642 - val_acc: 0.3685\n",
      "Epoch 607/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0428 - binary_accuracy: 0.9753 - acc: 0.3827 - val_loss: 0.0615 - val_binary_accuracy: 0.9645 - val_acc: 0.3302\n",
      "Epoch 608/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0427 - binary_accuracy: 0.9753 - acc: 0.3911 - val_loss: 0.0620 - val_binary_accuracy: 0.9640 - val_acc: 0.3646\n",
      "Epoch 609/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0427 - binary_accuracy: 0.9753 - acc: 0.3854 - val_loss: 0.0616 - val_binary_accuracy: 0.9643 - val_acc: 0.3599\n",
      "Epoch 610/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0426 - binary_accuracy: 0.9754 - acc: 0.3807 - val_loss: 0.0615 - val_binary_accuracy: 0.9643 - val_acc: 0.3512\n",
      "Epoch 611/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0426 - binary_accuracy: 0.9754 - acc: 0.3952 - val_loss: 0.0614 - val_binary_accuracy: 0.9645 - val_acc: 0.3385\n",
      "Epoch 612/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0427 - binary_accuracy: 0.9754 - acc: 0.3830 - val_loss: 0.0617 - val_binary_accuracy: 0.9643 - val_acc: 0.3537\n",
      "Epoch 613/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0426 - binary_accuracy: 0.9754 - acc: 0.3891 - val_loss: 0.0611 - val_binary_accuracy: 0.9647 - val_acc: 0.3429\n",
      "Epoch 614/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0425 - binary_accuracy: 0.9754 - acc: 0.3862 - val_loss: 0.0610 - val_binary_accuracy: 0.9647 - val_acc: 0.3494\n",
      "Epoch 615/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0425 - binary_accuracy: 0.9754 - acc: 0.3905 - val_loss: 0.0608 - val_binary_accuracy: 0.9649 - val_acc: 0.3667\n",
      "Epoch 616/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0424 - binary_accuracy: 0.9755 - acc: 0.3920 - val_loss: 0.0611 - val_binary_accuracy: 0.9647 - val_acc: 0.3378\n",
      "Epoch 617/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0424 - binary_accuracy: 0.9755 - acc: 0.3929 - val_loss: 0.0607 - val_binary_accuracy: 0.9648 - val_acc: 0.3548\n",
      "Epoch 618/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0424 - binary_accuracy: 0.9755 - acc: 0.3929 - val_loss: 0.0612 - val_binary_accuracy: 0.9645 - val_acc: 0.3707\n",
      "Epoch 619/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0424 - binary_accuracy: 0.9755 - acc: 0.3925 - val_loss: 0.0610 - val_binary_accuracy: 0.9646 - val_acc: 0.3772\n",
      "Epoch 620/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0424 - binary_accuracy: 0.9755 - acc: 0.3901 - val_loss: 0.0608 - val_binary_accuracy: 0.9648 - val_acc: 0.3306\n",
      "Epoch 621/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0423 - binary_accuracy: 0.9756 - acc: 0.3996 - val_loss: 0.0612 - val_binary_accuracy: 0.9646 - val_acc: 0.3606\n",
      "Epoch 622/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0422 - binary_accuracy: 0.9756 - acc: 0.3945 - val_loss: 0.0612 - val_binary_accuracy: 0.9645 - val_acc: 0.3696\n",
      "Epoch 623/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0422 - binary_accuracy: 0.9756 - acc: 0.4021 - val_loss: 0.0608 - val_binary_accuracy: 0.9648 - val_acc: 0.3765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0422 - binary_accuracy: 0.9756 - acc: 0.4079 - val_loss: 0.0606 - val_binary_accuracy: 0.9648 - val_acc: 0.3754\n",
      "Epoch 625/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0421 - binary_accuracy: 0.9756 - acc: 0.4058 - val_loss: 0.0608 - val_binary_accuracy: 0.9648 - val_acc: 0.3580\n",
      "Epoch 626/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0421 - binary_accuracy: 0.9756 - acc: 0.4070 - val_loss: 0.0609 - val_binary_accuracy: 0.9646 - val_acc: 0.3848\n",
      "Epoch 627/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0421 - binary_accuracy: 0.9757 - acc: 0.4137 - val_loss: 0.0610 - val_binary_accuracy: 0.9646 - val_acc: 0.4029\n",
      "Epoch 628/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0421 - binary_accuracy: 0.9757 - acc: 0.4159 - val_loss: 0.0605 - val_binary_accuracy: 0.9649 - val_acc: 0.3826\n",
      "Epoch 629/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0420 - binary_accuracy: 0.9757 - acc: 0.4137 - val_loss: 0.0606 - val_binary_accuracy: 0.9649 - val_acc: 0.3859\n",
      "Epoch 630/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0420 - binary_accuracy: 0.9757 - acc: 0.4200 - val_loss: 0.0608 - val_binary_accuracy: 0.9647 - val_acc: 0.3559\n",
      "Epoch 631/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0420 - binary_accuracy: 0.9757 - acc: 0.4129 - val_loss: 0.0606 - val_binary_accuracy: 0.9648 - val_acc: 0.3816\n",
      "Epoch 632/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0419 - binary_accuracy: 0.9758 - acc: 0.4156 - val_loss: 0.0604 - val_binary_accuracy: 0.9651 - val_acc: 0.3859\n",
      "Epoch 633/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0418 - binary_accuracy: 0.9758 - acc: 0.4203 - val_loss: 0.0601 - val_binary_accuracy: 0.9652 - val_acc: 0.3823\n",
      "Epoch 634/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0418 - binary_accuracy: 0.9758 - acc: 0.4227 - val_loss: 0.0601 - val_binary_accuracy: 0.9651 - val_acc: 0.4177\n",
      "Epoch 635/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0418 - binary_accuracy: 0.9758 - acc: 0.4306 - val_loss: 0.0602 - val_binary_accuracy: 0.9652 - val_acc: 0.3848\n",
      "Epoch 636/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0418 - binary_accuracy: 0.9758 - acc: 0.4302 - val_loss: 0.0603 - val_binary_accuracy: 0.9652 - val_acc: 0.4213\n",
      "Epoch 637/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0417 - binary_accuracy: 0.9758 - acc: 0.4402 - val_loss: 0.0606 - val_binary_accuracy: 0.9648 - val_acc: 0.3863\n",
      "Epoch 638/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0418 - binary_accuracy: 0.9759 - acc: 0.4330 - val_loss: 0.0608 - val_binary_accuracy: 0.9647 - val_acc: 0.4043\n",
      "Epoch 639/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0417 - binary_accuracy: 0.9759 - acc: 0.4400 - val_loss: 0.0603 - val_binary_accuracy: 0.9650 - val_acc: 0.4412\n",
      "Epoch 640/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0417 - binary_accuracy: 0.9759 - acc: 0.4337 - val_loss: 0.0599 - val_binary_accuracy: 0.9653 - val_acc: 0.3779\n",
      "Epoch 641/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0416 - binary_accuracy: 0.9759 - acc: 0.4307 - val_loss: 0.0601 - val_binary_accuracy: 0.9650 - val_acc: 0.4235\n",
      "Epoch 642/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0416 - binary_accuracy: 0.9759 - acc: 0.4365 - val_loss: 0.0602 - val_binary_accuracy: 0.9650 - val_acc: 0.3931\n",
      "Epoch 643/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0418 - binary_accuracy: 0.9759 - acc: 0.4388 - val_loss: 0.0602 - val_binary_accuracy: 0.9652 - val_acc: 0.3971\n",
      "Epoch 644/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0416 - binary_accuracy: 0.9759 - acc: 0.4386 - val_loss: 0.0599 - val_binary_accuracy: 0.9651 - val_acc: 0.4076\n",
      "Epoch 645/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0415 - binary_accuracy: 0.9760 - acc: 0.4363 - val_loss: 0.0597 - val_binary_accuracy: 0.9653 - val_acc: 0.4300\n",
      "Epoch 646/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0415 - binary_accuracy: 0.9760 - acc: 0.4476 - val_loss: 0.0598 - val_binary_accuracy: 0.9653 - val_acc: 0.4336\n",
      "Epoch 647/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0414 - binary_accuracy: 0.9760 - acc: 0.4474 - val_loss: 0.0599 - val_binary_accuracy: 0.9653 - val_acc: 0.4163\n",
      "Epoch 648/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0414 - binary_accuracy: 0.9761 - acc: 0.4527 - val_loss: 0.0596 - val_binary_accuracy: 0.9655 - val_acc: 0.4325\n",
      "Epoch 649/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0413 - binary_accuracy: 0.9761 - acc: 0.4489 - val_loss: 0.0601 - val_binary_accuracy: 0.9650 - val_acc: 0.4065\n",
      "Epoch 650/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0413 - binary_accuracy: 0.9761 - acc: 0.4580 - val_loss: 0.0598 - val_binary_accuracy: 0.9654 - val_acc: 0.4340\n",
      "Epoch 651/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0412 - binary_accuracy: 0.9761 - acc: 0.4552 - val_loss: 0.0594 - val_binary_accuracy: 0.9655 - val_acc: 0.4373\n",
      "Epoch 652/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0412 - binary_accuracy: 0.9762 - acc: 0.4550 - val_loss: 0.0600 - val_binary_accuracy: 0.9653 - val_acc: 0.4315\n",
      "Epoch 653/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0411 - binary_accuracy: 0.9762 - acc: 0.4645 - val_loss: 0.0594 - val_binary_accuracy: 0.9656 - val_acc: 0.4535\n",
      "Epoch 654/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0411 - binary_accuracy: 0.9762 - acc: 0.4647 - val_loss: 0.0594 - val_binary_accuracy: 0.9657 - val_acc: 0.4347\n",
      "Epoch 655/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0411 - binary_accuracy: 0.9762 - acc: 0.4641 - val_loss: 0.0596 - val_binary_accuracy: 0.9655 - val_acc: 0.4441\n",
      "Epoch 656/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0410 - binary_accuracy: 0.9763 - acc: 0.4609 - val_loss: 0.0594 - val_binary_accuracy: 0.9656 - val_acc: 0.4108\n",
      "Epoch 657/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0410 - binary_accuracy: 0.9763 - acc: 0.4624 - val_loss: 0.0598 - val_binary_accuracy: 0.9654 - val_acc: 0.4499\n",
      "Epoch 658/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0409 - binary_accuracy: 0.9763 - acc: 0.4628 - val_loss: 0.0595 - val_binary_accuracy: 0.9656 - val_acc: 0.4365\n",
      "Epoch 659/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0409 - binary_accuracy: 0.9763 - acc: 0.4659 - val_loss: 0.0591 - val_binary_accuracy: 0.9660 - val_acc: 0.4405\n",
      "Epoch 660/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0410 - binary_accuracy: 0.9763 - acc: 0.4681 - val_loss: 0.0597 - val_binary_accuracy: 0.9653 - val_acc: 0.4401\n",
      "Epoch 661/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0411 - binary_accuracy: 0.9763 - acc: 0.4704 - val_loss: 0.0596 - val_binary_accuracy: 0.9654 - val_acc: 0.4539\n",
      "Epoch 662/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0409 - binary_accuracy: 0.9764 - acc: 0.4614 - val_loss: 0.0592 - val_binary_accuracy: 0.9656 - val_acc: 0.4716\n",
      "Epoch 663/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0408 - binary_accuracy: 0.9764 - acc: 0.4636 - val_loss: 0.0592 - val_binary_accuracy: 0.9656 - val_acc: 0.4336\n",
      "Epoch 664/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0407 - binary_accuracy: 0.9764 - acc: 0.4628 - val_loss: 0.0590 - val_binary_accuracy: 0.9657 - val_acc: 0.4137\n",
      "Epoch 665/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0407 - binary_accuracy: 0.9764 - acc: 0.4589 - val_loss: 0.0587 - val_binary_accuracy: 0.9660 - val_acc: 0.4336\n",
      "Epoch 666/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0407 - binary_accuracy: 0.9764 - acc: 0.4674 - val_loss: 0.0589 - val_binary_accuracy: 0.9657 - val_acc: 0.4448\n",
      "Epoch 667/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0406 - binary_accuracy: 0.9765 - acc: 0.4752 - val_loss: 0.0590 - val_binary_accuracy: 0.9659 - val_acc: 0.4416\n",
      "Epoch 668/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0406 - binary_accuracy: 0.9765 - acc: 0.4749 - val_loss: 0.0590 - val_binary_accuracy: 0.9657 - val_acc: 0.4626\n",
      "Epoch 669/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0406 - binary_accuracy: 0.9765 - acc: 0.4735 - val_loss: 0.0590 - val_binary_accuracy: 0.9657 - val_acc: 0.4524\n",
      "Epoch 670/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0405 - binary_accuracy: 0.9765 - acc: 0.4731 - val_loss: 0.0587 - val_binary_accuracy: 0.9660 - val_acc: 0.4246\n",
      "Epoch 671/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0405 - binary_accuracy: 0.9765 - acc: 0.4718 - val_loss: 0.0589 - val_binary_accuracy: 0.9658 - val_acc: 0.4463\n",
      "Epoch 672/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0405 - binary_accuracy: 0.9765 - acc: 0.4764 - val_loss: 0.0589 - val_binary_accuracy: 0.9658 - val_acc: 0.4637\n",
      "Epoch 673/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0405 - binary_accuracy: 0.9765 - acc: 0.4738 - val_loss: 0.0589 - val_binary_accuracy: 0.9658 - val_acc: 0.4521\n",
      "Epoch 674/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0405 - binary_accuracy: 0.9765 - acc: 0.4819 - val_loss: 0.0588 - val_binary_accuracy: 0.9658 - val_acc: 0.4600\n",
      "Epoch 675/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0404 - binary_accuracy: 0.9766 - acc: 0.4817 - val_loss: 0.0588 - val_binary_accuracy: 0.9658 - val_acc: 0.4720\n",
      "Epoch 676/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0404 - binary_accuracy: 0.9766 - acc: 0.4842 - val_loss: 0.0586 - val_binary_accuracy: 0.9659 - val_acc: 0.4420\n",
      "Epoch 677/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0404 - binary_accuracy: 0.9766 - acc: 0.4773 - val_loss: 0.0589 - val_binary_accuracy: 0.9658 - val_acc: 0.4492\n",
      "Epoch 678/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0404 - binary_accuracy: 0.9766 - acc: 0.4746 - val_loss: 0.0587 - val_binary_accuracy: 0.9657 - val_acc: 0.4278\n",
      "Epoch 679/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0403 - binary_accuracy: 0.9766 - acc: 0.4693 - val_loss: 0.0585 - val_binary_accuracy: 0.9660 - val_acc: 0.4597\n",
      "Epoch 680/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0403 - binary_accuracy: 0.9766 - acc: 0.4896 - val_loss: 0.0584 - val_binary_accuracy: 0.9661 - val_acc: 0.4716\n",
      "Epoch 681/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0403 - binary_accuracy: 0.9766 - acc: 0.4921 - val_loss: 0.0586 - val_binary_accuracy: 0.9659 - val_acc: 0.4611\n",
      "Epoch 682/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0403 - binary_accuracy: 0.9766 - acc: 0.4904 - val_loss: 0.0584 - val_binary_accuracy: 0.9659 - val_acc: 0.4731\n",
      "Epoch 683/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9766 - acc: 0.4993 - val_loss: 0.0585 - val_binary_accuracy: 0.9661 - val_acc: 0.4745\n",
      "Epoch 684/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.4966 - val_loss: 0.0586 - val_binary_accuracy: 0.9659 - val_acc: 0.4676\n",
      "Epoch 685/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.4996 - val_loss: 0.0584 - val_binary_accuracy: 0.9661 - val_acc: 0.4680\n",
      "Epoch 686/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5027 - val_loss: 0.0582 - val_binary_accuracy: 0.9661 - val_acc: 0.4741\n",
      "Epoch 687/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5039 - val_loss: 0.0586 - val_binary_accuracy: 0.9659 - val_acc: 0.4857\n",
      "Epoch 688/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5090 - val_loss: 0.0585 - val_binary_accuracy: 0.9661 - val_acc: 0.4590\n",
      "Epoch 689/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5019 - val_loss: 0.0583 - val_binary_accuracy: 0.9663 - val_acc: 0.4716\n",
      "Epoch 690/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5055 - val_loss: 0.0582 - val_binary_accuracy: 0.9663 - val_acc: 0.4770\n",
      "Epoch 691/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0401 - binary_accuracy: 0.9767 - acc: 0.5078 - val_loss: 0.0582 - val_binary_accuracy: 0.9662 - val_acc: 0.4814\n",
      "Epoch 692/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9767 - acc: 0.5101 - val_loss: 0.0587 - val_binary_accuracy: 0.9660 - val_acc: 0.4810\n",
      "Epoch 693/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0401 - binary_accuracy: 0.9767 - acc: 0.5050 - val_loss: 0.0583 - val_binary_accuracy: 0.9660 - val_acc: 0.4995\n",
      "Epoch 694/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9767 - acc: 0.5075 - val_loss: 0.0581 - val_binary_accuracy: 0.9662 - val_acc: 0.4767\n",
      "Epoch 695/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9767 - acc: 0.5184 - val_loss: 0.0581 - val_binary_accuracy: 0.9661 - val_acc: 0.4814\n",
      "Epoch 696/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9767 - acc: 0.5067 - val_loss: 0.0583 - val_binary_accuracy: 0.9660 - val_acc: 0.4911\n",
      "Epoch 697/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9768 - acc: 0.5064 - val_loss: 0.0586 - val_binary_accuracy: 0.9658 - val_acc: 0.4705\n",
      "Epoch 698/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9768 - acc: 0.5004 - val_loss: 0.0589 - val_binary_accuracy: 0.9658 - val_acc: 0.4488\n",
      "Epoch 699/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5025 - val_loss: 0.0601 - val_binary_accuracy: 0.9650 - val_acc: 0.4864\n",
      "Epoch 700/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0405 - binary_accuracy: 0.9766 - acc: 0.4851 - val_loss: 0.0604 - val_binary_accuracy: 0.9647 - val_acc: 0.4712\n",
      "Epoch 701/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0404 - binary_accuracy: 0.9767 - acc: 0.4917 - val_loss: 0.0590 - val_binary_accuracy: 0.9658 - val_acc: 0.4712\n",
      "Epoch 702/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9768 - acc: 0.4921 - val_loss: 0.0579 - val_binary_accuracy: 0.9663 - val_acc: 0.4788\n",
      "Epoch 703/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0400 - binary_accuracy: 0.9768 - acc: 0.4966 - val_loss: 0.0576 - val_binary_accuracy: 0.9665 - val_acc: 0.4655\n",
      "Epoch 704/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0400 - binary_accuracy: 0.9768 - acc: 0.4982 - val_loss: 0.0575 - val_binary_accuracy: 0.9667 - val_acc: 0.4727\n",
      "Epoch 705/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0399 - binary_accuracy: 0.9768 - acc: 0.5036 - val_loss: 0.0576 - val_binary_accuracy: 0.9664 - val_acc: 0.4796\n",
      "Epoch 706/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0399 - binary_accuracy: 0.9768 - acc: 0.5049 - val_loss: 0.0577 - val_binary_accuracy: 0.9665 - val_acc: 0.4803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0399 - binary_accuracy: 0.9768 - acc: 0.5134 - val_loss: 0.0577 - val_binary_accuracy: 0.9665 - val_acc: 0.4456\n",
      "Epoch 708/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0399 - binary_accuracy: 0.9768 - acc: 0.5180 - val_loss: 0.0573 - val_binary_accuracy: 0.9669 - val_acc: 0.4835\n",
      "Epoch 709/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0399 - binary_accuracy: 0.9769 - acc: 0.5168 - val_loss: 0.0574 - val_binary_accuracy: 0.9666 - val_acc: 0.4759\n",
      "Epoch 710/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0399 - binary_accuracy: 0.9769 - acc: 0.5151 - val_loss: 0.0574 - val_binary_accuracy: 0.9665 - val_acc: 0.4767\n",
      "Epoch 711/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5173 - val_loss: 0.0574 - val_binary_accuracy: 0.9668 - val_acc: 0.4759\n",
      "Epoch 712/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5176 - val_loss: 0.0574 - val_binary_accuracy: 0.9667 - val_acc: 0.4846\n",
      "Epoch 713/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5218 - val_loss: 0.0573 - val_binary_accuracy: 0.9667 - val_acc: 0.4897\n",
      "Epoch 714/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5221 - val_loss: 0.0573 - val_binary_accuracy: 0.9666 - val_acc: 0.4861\n",
      "Epoch 715/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5260 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.4890\n",
      "Epoch 716/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5258 - val_loss: 0.0574 - val_binary_accuracy: 0.9666 - val_acc: 0.5089\n",
      "Epoch 717/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5235 - val_loss: 0.0573 - val_binary_accuracy: 0.9667 - val_acc: 0.5038\n",
      "Epoch 718/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5306 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.4980\n",
      "Epoch 719/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5332 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.4951\n",
      "Epoch 720/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5321 - val_loss: 0.0573 - val_binary_accuracy: 0.9667 - val_acc: 0.5074\n",
      "Epoch 721/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5344 - val_loss: 0.0573 - val_binary_accuracy: 0.9667 - val_acc: 0.5042\n",
      "Epoch 722/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5357 - val_loss: 0.0574 - val_binary_accuracy: 0.9667 - val_acc: 0.4995\n",
      "Epoch 723/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5358 - val_loss: 0.0571 - val_binary_accuracy: 0.9669 - val_acc: 0.4966\n",
      "Epoch 724/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5400 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5118\n",
      "Epoch 725/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5406 - val_loss: 0.0578 - val_binary_accuracy: 0.9666 - val_acc: 0.5186\n",
      "Epoch 726/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0402 - binary_accuracy: 0.9767 - acc: 0.5446 - val_loss: 0.0590 - val_binary_accuracy: 0.9656 - val_acc: 0.5251\n",
      "Epoch 727/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0409 - binary_accuracy: 0.9764 - acc: 0.5291 - val_loss: 0.0587 - val_binary_accuracy: 0.9659 - val_acc: 0.4720\n",
      "Epoch 728/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0401 - binary_accuracy: 0.9768 - acc: 0.5182 - val_loss: 0.0577 - val_binary_accuracy: 0.9665 - val_acc: 0.4745\n",
      "Epoch 729/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0398 - binary_accuracy: 0.9769 - acc: 0.5217 - val_loss: 0.0573 - val_binary_accuracy: 0.9669 - val_acc: 0.4901\n",
      "Epoch 730/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0397 - binary_accuracy: 0.9769 - acc: 0.5214 - val_loss: 0.0575 - val_binary_accuracy: 0.9666 - val_acc: 0.4951\n",
      "Epoch 731/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0397 - binary_accuracy: 0.9769 - acc: 0.5259 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.4908\n",
      "Epoch 732/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0397 - binary_accuracy: 0.9770 - acc: 0.5335 - val_loss: 0.0571 - val_binary_accuracy: 0.9669 - val_acc: 0.5096\n",
      "Epoch 733/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0397 - binary_accuracy: 0.9770 - acc: 0.5336 - val_loss: 0.0570 - val_binary_accuracy: 0.9671 - val_acc: 0.4767\n",
      "Epoch 734/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5234 - val_loss: 0.0571 - val_binary_accuracy: 0.9668 - val_acc: 0.4976\n",
      "Epoch 735/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5344 - val_loss: 0.0571 - val_binary_accuracy: 0.9669 - val_acc: 0.5020\n",
      "Epoch 736/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5336 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5150\n",
      "Epoch 737/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5349 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.5118\n",
      "Epoch 738/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5335 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.5074\n",
      "Epoch 739/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5344 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.5237\n",
      "Epoch 740/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5475 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5175\n",
      "Epoch 741/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5409 - val_loss: 0.0572 - val_binary_accuracy: 0.9669 - val_acc: 0.5121\n",
      "Epoch 742/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5476 - val_loss: 0.0574 - val_binary_accuracy: 0.9667 - val_acc: 0.5052\n",
      "Epoch 743/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5469 - val_loss: 0.0573 - val_binary_accuracy: 0.9667 - val_acc: 0.5259\n",
      "Epoch 744/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9770 - acc: 0.5474 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5244\n",
      "Epoch 745/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5498 - val_loss: 0.0574 - val_binary_accuracy: 0.9667 - val_acc: 0.5327\n",
      "Epoch 746/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9770 - acc: 0.5513 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.5291\n",
      "Epoch 747/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9770 - acc: 0.5531 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5345\n",
      "Epoch 748/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9770 - acc: 0.5537 - val_loss: 0.0572 - val_binary_accuracy: 0.9666 - val_acc: 0.5363\n",
      "Epoch 749/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9770 - acc: 0.5571 - val_loss: 0.0576 - val_binary_accuracy: 0.9665 - val_acc: 0.5255\n",
      "Epoch 750/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9770 - acc: 0.5644 - val_loss: 0.0573 - val_binary_accuracy: 0.9667 - val_acc: 0.5414\n",
      "Epoch 751/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0395 - binary_accuracy: 0.9771 - acc: 0.5510 - val_loss: 0.0574 - val_binary_accuracy: 0.9665 - val_acc: 0.5342\n",
      "Epoch 752/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0395 - binary_accuracy: 0.9771 - acc: 0.5631 - val_loss: 0.0578 - val_binary_accuracy: 0.9664 - val_acc: 0.5016\n",
      "Epoch 753/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0396 - binary_accuracy: 0.9770 - acc: 0.5494 - val_loss: 0.0590 - val_binary_accuracy: 0.9656 - val_acc: 0.4177\n",
      "Epoch 754/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0399 - binary_accuracy: 0.9769 - acc: 0.5415 - val_loss: 0.0587 - val_binary_accuracy: 0.9659 - val_acc: 0.5150\n",
      "Epoch 755/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0397 - binary_accuracy: 0.9770 - acc: 0.5420 - val_loss: 0.0577 - val_binary_accuracy: 0.9665 - val_acc: 0.5288\n",
      "Epoch 756/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0394 - binary_accuracy: 0.9771 - acc: 0.5359 - val_loss: 0.0575 - val_binary_accuracy: 0.9667 - val_acc: 0.5179\n",
      "Epoch 757/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0393 - binary_accuracy: 0.9772 - acc: 0.5502 - val_loss: 0.0579 - val_binary_accuracy: 0.9664 - val_acc: 0.5092\n",
      "Epoch 758/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0395 - binary_accuracy: 0.9772 - acc: 0.5453 - val_loss: 0.0576 - val_binary_accuracy: 0.9666 - val_acc: 0.4976\n",
      "Epoch 759/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0392 - binary_accuracy: 0.9772 - acc: 0.5408 - val_loss: 0.0573 - val_binary_accuracy: 0.9666 - val_acc: 0.5302\n",
      "Epoch 760/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0391 - binary_accuracy: 0.9773 - acc: 0.5433 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5277\n",
      "Epoch 761/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0391 - binary_accuracy: 0.9773 - acc: 0.5494 - val_loss: 0.0572 - val_binary_accuracy: 0.9668 - val_acc: 0.5356\n",
      "Epoch 762/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0391 - binary_accuracy: 0.9773 - acc: 0.5557 - val_loss: 0.0571 - val_binary_accuracy: 0.9669 - val_acc: 0.5273\n",
      "Epoch 763/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0391 - binary_accuracy: 0.9773 - acc: 0.5573 - val_loss: 0.0572 - val_binary_accuracy: 0.9666 - val_acc: 0.5454\n",
      "Epoch 764/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9773 - acc: 0.5547 - val_loss: 0.0571 - val_binary_accuracy: 0.9668 - val_acc: 0.5335\n",
      "Epoch 765/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9773 - acc: 0.5566 - val_loss: 0.0571 - val_binary_accuracy: 0.9669 - val_acc: 0.5320\n",
      "Epoch 766/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0390 - binary_accuracy: 0.9773 - acc: 0.5568 - val_loss: 0.0570 - val_binary_accuracy: 0.9668 - val_acc: 0.5371\n",
      "Epoch 767/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9773 - acc: 0.5603 - val_loss: 0.0569 - val_binary_accuracy: 0.9670 - val_acc: 0.5414\n",
      "Epoch 768/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9773 - acc: 0.5639 - val_loss: 0.0572 - val_binary_accuracy: 0.9666 - val_acc: 0.5356\n",
      "Epoch 769/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0390 - binary_accuracy: 0.9774 - acc: 0.5719 - val_loss: 0.0569 - val_binary_accuracy: 0.9669 - val_acc: 0.5439\n",
      "Epoch 770/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9774 - acc: 0.5630 - val_loss: 0.0569 - val_binary_accuracy: 0.9670 - val_acc: 0.5732\n",
      "Epoch 771/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9774 - acc: 0.5716 - val_loss: 0.0569 - val_binary_accuracy: 0.9668 - val_acc: 0.5548\n",
      "Epoch 772/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0389 - binary_accuracy: 0.9774 - acc: 0.5634 - val_loss: 0.0575 - val_binary_accuracy: 0.9666 - val_acc: 0.5327\n",
      "Epoch 773/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0389 - binary_accuracy: 0.9774 - acc: 0.5676 - val_loss: 0.0573 - val_binary_accuracy: 0.9665 - val_acc: 0.5027\n",
      "Epoch 774/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0389 - binary_accuracy: 0.9774 - acc: 0.5656 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.5298\n",
      "Epoch 775/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0389 - binary_accuracy: 0.9774 - acc: 0.5675 - val_loss: 0.0569 - val_binary_accuracy: 0.9669 - val_acc: 0.5324\n",
      "Epoch 776/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0389 - binary_accuracy: 0.9774 - acc: 0.5651 - val_loss: 0.0568 - val_binary_accuracy: 0.9670 - val_acc: 0.5577\n",
      "Epoch 777/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9774 - acc: 0.5713 - val_loss: 0.0572 - val_binary_accuracy: 0.9667 - val_acc: 0.5707\n",
      "Epoch 778/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0389 - binary_accuracy: 0.9774 - acc: 0.5707 - val_loss: 0.0570 - val_binary_accuracy: 0.9669 - val_acc: 0.5320\n",
      "Epoch 779/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9774 - acc: 0.5701 - val_loss: 0.0568 - val_binary_accuracy: 0.9670 - val_acc: 0.5396\n",
      "Epoch 780/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9774 - acc: 0.5713 - val_loss: 0.0568 - val_binary_accuracy: 0.9669 - val_acc: 0.5631\n",
      "Epoch 781/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9774 - acc: 0.5761 - val_loss: 0.0568 - val_binary_accuracy: 0.9671 - val_acc: 0.5537\n",
      "Epoch 782/4000\n",
      "15667/15667 [==============================] - 0s 20us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5734 - val_loss: 0.0566 - val_binary_accuracy: 0.9672 - val_acc: 0.5523\n",
      "Epoch 783/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5825 - val_loss: 0.0570 - val_binary_accuracy: 0.9668 - val_acc: 0.5924\n",
      "Epoch 784/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5829 - val_loss: 0.0568 - val_binary_accuracy: 0.9667 - val_acc: 0.5624\n",
      "Epoch 785/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5798 - val_loss: 0.0566 - val_binary_accuracy: 0.9670 - val_acc: 0.5461\n",
      "Epoch 786/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5813 - val_loss: 0.0564 - val_binary_accuracy: 0.9672 - val_acc: 0.5526\n",
      "Epoch 787/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5807 - val_loss: 0.0568 - val_binary_accuracy: 0.9668 - val_acc: 0.5548\n",
      "Epoch 788/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5803 - val_loss: 0.0565 - val_binary_accuracy: 0.9670 - val_acc: 0.5722\n",
      "Epoch 789/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5842 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 790/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5823 - val_loss: 0.0567 - val_binary_accuracy: 0.9670 - val_acc: 0.5982\n",
      "Epoch 791/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0388 - binary_accuracy: 0.9775 - acc: 0.5791 - val_loss: 0.0567 - val_binary_accuracy: 0.9671 - val_acc: 0.5750\n",
      "Epoch 792/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5735 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5642\n",
      "Epoch 793/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5836 - val_loss: 0.0566 - val_binary_accuracy: 0.9670 - val_acc: 0.5591\n",
      "Epoch 794/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5833 - val_loss: 0.0569 - val_binary_accuracy: 0.9669 - val_acc: 0.5649\n",
      "Epoch 795/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5847 - val_loss: 0.0567 - val_binary_accuracy: 0.9670 - val_acc: 0.5544\n",
      "Epoch 796/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5872 - val_loss: 0.0568 - val_binary_accuracy: 0.9669 - val_acc: 0.5696\n",
      "Epoch 797/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5852 - val_loss: 0.0567 - val_binary_accuracy: 0.9670 - val_acc: 0.5714\n",
      "Epoch 798/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5908 - val_loss: 0.0568 - val_binary_accuracy: 0.9669 - val_acc: 0.5725\n",
      "Epoch 799/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5843 - val_loss: 0.0574 - val_binary_accuracy: 0.9664 - val_acc: 0.5718\n",
      "Epoch 800/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5900 - val_loss: 0.0568 - val_binary_accuracy: 0.9669 - val_acc: 0.5866\n",
      "Epoch 801/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9775 - acc: 0.5863 - val_loss: 0.0568 - val_binary_accuracy: 0.9670 - val_acc: 0.5823\n",
      "Epoch 802/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9774 - acc: 0.5842 - val_loss: 0.0585 - val_binary_accuracy: 0.9658 - val_acc: 0.6174\n",
      "Epoch 803/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0395 - binary_accuracy: 0.9772 - acc: 0.5886 - val_loss: 0.0581 - val_binary_accuracy: 0.9659 - val_acc: 0.5892\n",
      "Epoch 804/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0390 - binary_accuracy: 0.9774 - acc: 0.5794 - val_loss: 0.0575 - val_binary_accuracy: 0.9663 - val_acc: 0.5548\n",
      "Epoch 805/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0387 - binary_accuracy: 0.9776 - acc: 0.5641 - val_loss: 0.0571 - val_binary_accuracy: 0.9666 - val_acc: 0.5544\n",
      "Epoch 806/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0386 - binary_accuracy: 0.9776 - acc: 0.5789 - val_loss: 0.0566 - val_binary_accuracy: 0.9670 - val_acc: 0.5729\n",
      "Epoch 807/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0386 - binary_accuracy: 0.9776 - acc: 0.5787 - val_loss: 0.0566 - val_binary_accuracy: 0.9672 - val_acc: 0.5678\n",
      "Epoch 808/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0386 - binary_accuracy: 0.9776 - acc: 0.5840 - val_loss: 0.0565 - val_binary_accuracy: 0.9672 - val_acc: 0.5678\n",
      "Epoch 809/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0386 - binary_accuracy: 0.9776 - acc: 0.5844 - val_loss: 0.0565 - val_binary_accuracy: 0.9672 - val_acc: 0.5747\n",
      "Epoch 810/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5868 - val_loss: 0.0564 - val_binary_accuracy: 0.9672 - val_acc: 0.5750\n",
      "Epoch 811/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5878 - val_loss: 0.0563 - val_binary_accuracy: 0.9672 - val_acc: 0.5693\n",
      "Epoch 812/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5884 - val_loss: 0.0563 - val_binary_accuracy: 0.9672 - val_acc: 0.5747\n",
      "Epoch 813/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5873 - val_loss: 0.0564 - val_binary_accuracy: 0.9671 - val_acc: 0.5653\n",
      "Epoch 814/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5917 - val_loss: 0.0564 - val_binary_accuracy: 0.9672 - val_acc: 0.5722\n",
      "Epoch 815/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5900 - val_loss: 0.0565 - val_binary_accuracy: 0.9670 - val_acc: 0.5841\n",
      "Epoch 816/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5931 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.5693\n",
      "Epoch 817/4000\n",
      "15667/15667 [==============================] - 0s 20us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5942 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.5805\n",
      "Epoch 818/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5957 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.5855\n",
      "Epoch 819/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.6008 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.5761\n",
      "Epoch 820/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5984 - val_loss: 0.0563 - val_binary_accuracy: 0.9670 - val_acc: 0.5866\n",
      "Epoch 821/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.6011 - val_loss: 0.0567 - val_binary_accuracy: 0.9668 - val_acc: 0.5975\n",
      "Epoch 822/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5995 - val_loss: 0.0565 - val_binary_accuracy: 0.9670 - val_acc: 0.5982\n",
      "Epoch 823/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.5974 - val_loss: 0.0566 - val_binary_accuracy: 0.9670 - val_acc: 0.6033\n",
      "Epoch 824/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9776 - acc: 0.6059 - val_loss: 0.0563 - val_binary_accuracy: 0.9672 - val_acc: 0.5881\n",
      "Epoch 825/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9776 - acc: 0.6057 - val_loss: 0.0562 - val_binary_accuracy: 0.9673 - val_acc: 0.5895\n",
      "Epoch 826/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0384 - binary_accuracy: 0.9776 - acc: 0.6051 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5844\n",
      "Epoch 827/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9776 - acc: 0.6050 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5758\n",
      "Epoch 828/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0384 - binary_accuracy: 0.9776 - acc: 0.6041 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.5924\n",
      "Epoch 829/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.6053 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.5957\n",
      "Epoch 830/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.6082 - val_loss: 0.0563 - val_binary_accuracy: 0.9672 - val_acc: 0.6018\n",
      "Epoch 831/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9777 - acc: 0.6099 - val_loss: 0.0570 - val_binary_accuracy: 0.9666 - val_acc: 0.6239\n",
      "Epoch 832/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.6022 - val_loss: 0.0567 - val_binary_accuracy: 0.9670 - val_acc: 0.5779\n",
      "Epoch 833/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.6134 - val_loss: 0.0570 - val_binary_accuracy: 0.9668 - val_acc: 0.5812\n",
      "Epoch 834/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9777 - acc: 0.6044 - val_loss: 0.0577 - val_binary_accuracy: 0.9664 - val_acc: 0.5201\n",
      "Epoch 835/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0389 - binary_accuracy: 0.9775 - acc: 0.5888 - val_loss: 0.0574 - val_binary_accuracy: 0.9668 - val_acc: 0.5794\n",
      "Epoch 836/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0386 - binary_accuracy: 0.9777 - acc: 0.5834 - val_loss: 0.0571 - val_binary_accuracy: 0.9667 - val_acc: 0.5624\n",
      "Epoch 837/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.5744 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5324\n",
      "Epoch 838/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.5844 - val_loss: 0.0567 - val_binary_accuracy: 0.9670 - val_acc: 0.5552\n",
      "Epoch 839/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0383 - binary_accuracy: 0.9777 - acc: 0.5882 - val_loss: 0.0569 - val_binary_accuracy: 0.9668 - val_acc: 0.5758\n",
      "Epoch 840/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0383 - binary_accuracy: 0.9777 - acc: 0.5801 - val_loss: 0.0571 - val_binary_accuracy: 0.9666 - val_acc: 0.5678\n",
      "Epoch 841/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0383 - binary_accuracy: 0.9778 - acc: 0.5881 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5834\n",
      "Epoch 842/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0383 - binary_accuracy: 0.9778 - acc: 0.5945 - val_loss: 0.0566 - val_binary_accuracy: 0.9672 - val_acc: 0.5855\n",
      "Epoch 843/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0383 - binary_accuracy: 0.9778 - acc: 0.6020 - val_loss: 0.0562 - val_binary_accuracy: 0.9673 - val_acc: 0.5834\n",
      "Epoch 844/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.5999 - val_loss: 0.0568 - val_binary_accuracy: 0.9669 - val_acc: 0.5844\n",
      "Epoch 845/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.5998 - val_loss: 0.0564 - val_binary_accuracy: 0.9672 - val_acc: 0.5870\n",
      "Epoch 846/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.6061 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.5844\n",
      "Epoch 847/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.6027 - val_loss: 0.0564 - val_binary_accuracy: 0.9671 - val_acc: 0.5975\n",
      "Epoch 848/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.6069 - val_loss: 0.0565 - val_binary_accuracy: 0.9670 - val_acc: 0.5819\n",
      "Epoch 849/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.5973 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.5750\n",
      "Epoch 850/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.5960 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5826\n",
      "Epoch 851/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9778 - acc: 0.6006 - val_loss: 0.0569 - val_binary_accuracy: 0.9669 - val_acc: 0.6083\n",
      "Epoch 852/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0385 - binary_accuracy: 0.9777 - acc: 0.5849 - val_loss: 0.0573 - val_binary_accuracy: 0.9668 - val_acc: 0.5928\n",
      "Epoch 853/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0383 - binary_accuracy: 0.9778 - acc: 0.5963 - val_loss: 0.0568 - val_binary_accuracy: 0.9670 - val_acc: 0.5508\n",
      "Epoch 854/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0382 - binary_accuracy: 0.9779 - acc: 0.5893 - val_loss: 0.0563 - val_binary_accuracy: 0.9673 - val_acc: 0.5830\n",
      "Epoch 855/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.6019 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.5902\n",
      "Epoch 856/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.5966 - val_loss: 0.0562 - val_binary_accuracy: 0.9671 - val_acc: 0.5729\n",
      "Epoch 857/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.5965 - val_loss: 0.0562 - val_binary_accuracy: 0.9673 - val_acc: 0.5732\n",
      "Epoch 858/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.6038 - val_loss: 0.0561 - val_binary_accuracy: 0.9673 - val_acc: 0.5949\n",
      "Epoch 859/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.6004 - val_loss: 0.0561 - val_binary_accuracy: 0.9673 - val_acc: 0.5696\n",
      "Epoch 860/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.6070 - val_loss: 0.0562 - val_binary_accuracy: 0.9673 - val_acc: 0.5526\n",
      "Epoch 861/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.5977 - val_loss: 0.0561 - val_binary_accuracy: 0.9672 - val_acc: 0.5823\n",
      "Epoch 862/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6070 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.6127\n",
      "Epoch 863/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6106 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5967\n",
      "Epoch 864/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6045 - val_loss: 0.0562 - val_binary_accuracy: 0.9670 - val_acc: 0.5975\n",
      "Epoch 865/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6140 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.5779\n",
      "Epoch 866/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6072 - val_loss: 0.0561 - val_binary_accuracy: 0.9673 - val_acc: 0.5870\n",
      "Epoch 867/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6101 - val_loss: 0.0562 - val_binary_accuracy: 0.9671 - val_acc: 0.5996\n",
      "Epoch 868/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6131 - val_loss: 0.0568 - val_binary_accuracy: 0.9668 - val_acc: 0.5859\n",
      "Epoch 869/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.6069 - val_loss: 0.0571 - val_binary_accuracy: 0.9665 - val_acc: 0.5797\n",
      "Epoch 870/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0384 - binary_accuracy: 0.9777 - acc: 0.6034 - val_loss: 0.0578 - val_binary_accuracy: 0.9662 - val_acc: 0.5942\n",
      "Epoch 871/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0383 - binary_accuracy: 0.9779 - acc: 0.5824 - val_loss: 0.0568 - val_binary_accuracy: 0.9669 - val_acc: 0.5993\n",
      "Epoch 872/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0380 - binary_accuracy: 0.9779 - acc: 0.6009 - val_loss: 0.0563 - val_binary_accuracy: 0.9672 - val_acc: 0.5505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0381 - binary_accuracy: 0.9779 - acc: 0.5988 - val_loss: 0.0564 - val_binary_accuracy: 0.9672 - val_acc: 0.5772\n",
      "Epoch 874/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0380 - binary_accuracy: 0.9780 - acc: 0.6043 - val_loss: 0.0564 - val_binary_accuracy: 0.9672 - val_acc: 0.5732\n",
      "Epoch 875/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0379 - binary_accuracy: 0.9780 - acc: 0.5993 - val_loss: 0.0560 - val_binary_accuracy: 0.9674 - val_acc: 0.5946\n",
      "Epoch 876/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0379 - binary_accuracy: 0.9780 - acc: 0.6117 - val_loss: 0.0561 - val_binary_accuracy: 0.9673 - val_acc: 0.5964\n",
      "Epoch 877/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0379 - binary_accuracy: 0.9780 - acc: 0.6111 - val_loss: 0.0562 - val_binary_accuracy: 0.9675 - val_acc: 0.5627\n",
      "Epoch 878/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0379 - binary_accuracy: 0.9780 - acc: 0.5889 - val_loss: 0.0560 - val_binary_accuracy: 0.9675 - val_acc: 0.5548\n",
      "Epoch 879/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0378 - binary_accuracy: 0.9780 - acc: 0.5904 - val_loss: 0.0562 - val_binary_accuracy: 0.9673 - val_acc: 0.5577\n",
      "Epoch 880/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0378 - binary_accuracy: 0.9780 - acc: 0.6048 - val_loss: 0.0561 - val_binary_accuracy: 0.9672 - val_acc: 0.5884\n",
      "Epoch 881/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0378 - binary_accuracy: 0.9781 - acc: 0.6075 - val_loss: 0.0563 - val_binary_accuracy: 0.9673 - val_acc: 0.5906\n",
      "Epoch 882/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0377 - binary_accuracy: 0.9781 - acc: 0.6057 - val_loss: 0.0560 - val_binary_accuracy: 0.9675 - val_acc: 0.5949\n",
      "Epoch 883/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0377 - binary_accuracy: 0.9781 - acc: 0.6149 - val_loss: 0.0561 - val_binary_accuracy: 0.9674 - val_acc: 0.6166\n",
      "Epoch 884/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0377 - binary_accuracy: 0.9781 - acc: 0.6115 - val_loss: 0.0557 - val_binary_accuracy: 0.9676 - val_acc: 0.5729\n",
      "Epoch 885/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0377 - binary_accuracy: 0.9781 - acc: 0.6083 - val_loss: 0.0559 - val_binary_accuracy: 0.9674 - val_acc: 0.5884\n",
      "Epoch 886/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0376 - binary_accuracy: 0.9781 - acc: 0.6195 - val_loss: 0.0559 - val_binary_accuracy: 0.9673 - val_acc: 0.5986\n",
      "Epoch 887/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0376 - binary_accuracy: 0.9782 - acc: 0.6152 - val_loss: 0.0559 - val_binary_accuracy: 0.9674 - val_acc: 0.5772\n",
      "Epoch 888/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0376 - binary_accuracy: 0.9782 - acc: 0.6129 - val_loss: 0.0558 - val_binary_accuracy: 0.9674 - val_acc: 0.5899\n",
      "Epoch 889/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0376 - binary_accuracy: 0.9782 - acc: 0.6156 - val_loss: 0.0560 - val_binary_accuracy: 0.9672 - val_acc: 0.5920\n",
      "Epoch 890/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0376 - binary_accuracy: 0.9782 - acc: 0.6139 - val_loss: 0.0558 - val_binary_accuracy: 0.9676 - val_acc: 0.5848\n",
      "Epoch 891/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0376 - binary_accuracy: 0.9782 - acc: 0.6118 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.6083\n",
      "Epoch 892/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0376 - binary_accuracy: 0.9782 - acc: 0.6145 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5653\n",
      "Epoch 893/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0375 - binary_accuracy: 0.9782 - acc: 0.6157 - val_loss: 0.0562 - val_binary_accuracy: 0.9671 - val_acc: 0.5848\n",
      "Epoch 894/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0375 - binary_accuracy: 0.9783 - acc: 0.6169 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.6166\n",
      "Epoch 895/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0374 - binary_accuracy: 0.9783 - acc: 0.6227 - val_loss: 0.0559 - val_binary_accuracy: 0.9673 - val_acc: 0.5863\n",
      "Epoch 896/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0374 - binary_accuracy: 0.9783 - acc: 0.6096 - val_loss: 0.0561 - val_binary_accuracy: 0.9672 - val_acc: 0.5964\n",
      "Epoch 897/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0375 - binary_accuracy: 0.9783 - acc: 0.6126 - val_loss: 0.0561 - val_binary_accuracy: 0.9673 - val_acc: 0.5971\n",
      "Epoch 898/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0374 - binary_accuracy: 0.9783 - acc: 0.6092 - val_loss: 0.0565 - val_binary_accuracy: 0.9672 - val_acc: 0.5949\n",
      "Epoch 899/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0373 - binary_accuracy: 0.9783 - acc: 0.6094 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5812\n",
      "Epoch 900/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0373 - binary_accuracy: 0.9784 - acc: 0.6151 - val_loss: 0.0563 - val_binary_accuracy: 0.9671 - val_acc: 0.5805\n",
      "Epoch 901/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0372 - binary_accuracy: 0.9784 - acc: 0.6190 - val_loss: 0.0559 - val_binary_accuracy: 0.9672 - val_acc: 0.5830\n",
      "Epoch 902/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0372 - binary_accuracy: 0.9784 - acc: 0.6128 - val_loss: 0.0562 - val_binary_accuracy: 0.9670 - val_acc: 0.5617\n",
      "Epoch 903/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0371 - binary_accuracy: 0.9785 - acc: 0.6062 - val_loss: 0.0557 - val_binary_accuracy: 0.9674 - val_acc: 0.5834\n",
      "Epoch 904/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0371 - binary_accuracy: 0.9785 - acc: 0.6112 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5418\n",
      "Epoch 905/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0371 - binary_accuracy: 0.9785 - acc: 0.5993 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.6123\n",
      "Epoch 906/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0371 - binary_accuracy: 0.9785 - acc: 0.6075 - val_loss: 0.0558 - val_binary_accuracy: 0.9675 - val_acc: 0.5797\n",
      "Epoch 907/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0370 - binary_accuracy: 0.9785 - acc: 0.6031 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5852\n",
      "Epoch 908/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0369 - binary_accuracy: 0.9785 - acc: 0.6282 - val_loss: 0.0562 - val_binary_accuracy: 0.9671 - val_acc: 0.5873\n",
      "Epoch 909/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0370 - binary_accuracy: 0.9786 - acc: 0.6193 - val_loss: 0.0560 - val_binary_accuracy: 0.9673 - val_acc: 0.5993\n",
      "Epoch 910/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0369 - binary_accuracy: 0.9786 - acc: 0.6132 - val_loss: 0.0560 - val_binary_accuracy: 0.9675 - val_acc: 0.6123\n",
      "Epoch 911/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0369 - binary_accuracy: 0.9786 - acc: 0.6276 - val_loss: 0.0565 - val_binary_accuracy: 0.9671 - val_acc: 0.5497\n",
      "Epoch 912/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0369 - binary_accuracy: 0.9786 - acc: 0.6195 - val_loss: 0.0556 - val_binary_accuracy: 0.9675 - val_acc: 0.5573\n",
      "Epoch 913/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0367 - binary_accuracy: 0.9787 - acc: 0.6097 - val_loss: 0.0552 - val_binary_accuracy: 0.9678 - val_acc: 0.5711\n",
      "Epoch 914/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0367 - binary_accuracy: 0.9787 - acc: 0.6033 - val_loss: 0.0554 - val_binary_accuracy: 0.9678 - val_acc: 0.5884\n",
      "Epoch 915/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0367 - binary_accuracy: 0.9787 - acc: 0.6121 - val_loss: 0.0551 - val_binary_accuracy: 0.9679 - val_acc: 0.5790\n",
      "Epoch 916/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0366 - binary_accuracy: 0.9787 - acc: 0.6122 - val_loss: 0.0549 - val_binary_accuracy: 0.9681 - val_acc: 0.5819\n",
      "Epoch 917/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0366 - binary_accuracy: 0.9787 - acc: 0.6142 - val_loss: 0.0551 - val_binary_accuracy: 0.9679 - val_acc: 0.5910\n",
      "Epoch 918/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0366 - binary_accuracy: 0.9787 - acc: 0.6203 - val_loss: 0.0551 - val_binary_accuracy: 0.9678 - val_acc: 0.5758\n",
      "Epoch 919/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0366 - binary_accuracy: 0.9788 - acc: 0.6175 - val_loss: 0.0550 - val_binary_accuracy: 0.9679 - val_acc: 0.6022\n",
      "Epoch 920/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0366 - binary_accuracy: 0.9788 - acc: 0.6279 - val_loss: 0.0551 - val_binary_accuracy: 0.9678 - val_acc: 0.5989\n",
      "Epoch 921/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6242 - val_loss: 0.0553 - val_binary_accuracy: 0.9677 - val_acc: 0.5881\n",
      "Epoch 922/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6274 - val_loss: 0.0548 - val_binary_accuracy: 0.9681 - val_acc: 0.5863\n",
      "Epoch 923/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6294 - val_loss: 0.0548 - val_binary_accuracy: 0.9683 - val_acc: 0.5939\n",
      "Epoch 924/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6290 - val_loss: 0.0549 - val_binary_accuracy: 0.9680 - val_acc: 0.6040\n",
      "Epoch 925/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6294 - val_loss: 0.0548 - val_binary_accuracy: 0.9682 - val_acc: 0.5931\n",
      "Epoch 926/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6222 - val_loss: 0.0547 - val_binary_accuracy: 0.9681 - val_acc: 0.6108\n",
      "Epoch 927/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6337 - val_loss: 0.0548 - val_binary_accuracy: 0.9679 - val_acc: 0.6061\n",
      "Epoch 928/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6326 - val_loss: 0.0547 - val_binary_accuracy: 0.9682 - val_acc: 0.5884\n",
      "Epoch 929/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6295 - val_loss: 0.0548 - val_binary_accuracy: 0.9680 - val_acc: 0.6025\n",
      "Epoch 930/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6339 - val_loss: 0.0547 - val_binary_accuracy: 0.9682 - val_acc: 0.6018\n",
      "Epoch 931/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6346 - val_loss: 0.0550 - val_binary_accuracy: 0.9680 - val_acc: 0.5989\n",
      "Epoch 932/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6397 - val_loss: 0.0550 - val_binary_accuracy: 0.9678 - val_acc: 0.6018\n",
      "Epoch 933/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6352 - val_loss: 0.0556 - val_binary_accuracy: 0.9676 - val_acc: 0.6130\n",
      "Epoch 934/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6430 - val_loss: 0.0551 - val_binary_accuracy: 0.9678 - val_acc: 0.6033\n",
      "Epoch 935/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6359 - val_loss: 0.0548 - val_binary_accuracy: 0.9682 - val_acc: 0.6159\n",
      "Epoch 936/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6382 - val_loss: 0.0549 - val_binary_accuracy: 0.9680 - val_acc: 0.5993\n",
      "Epoch 937/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6326 - val_loss: 0.0547 - val_binary_accuracy: 0.9682 - val_acc: 0.6101\n",
      "Epoch 938/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6374 - val_loss: 0.0554 - val_binary_accuracy: 0.9677 - val_acc: 0.6271\n",
      "Epoch 939/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6431 - val_loss: 0.0548 - val_binary_accuracy: 0.9680 - val_acc: 0.6061\n",
      "Epoch 940/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9788 - acc: 0.6413 - val_loss: 0.0550 - val_binary_accuracy: 0.9678 - val_acc: 0.6116\n",
      "Epoch 941/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9789 - acc: 0.6491 - val_loss: 0.0555 - val_binary_accuracy: 0.9676 - val_acc: 0.6072\n",
      "Epoch 942/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9789 - acc: 0.6459 - val_loss: 0.0550 - val_binary_accuracy: 0.9679 - val_acc: 0.6242\n",
      "Epoch 943/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9789 - acc: 0.6514 - val_loss: 0.0547 - val_binary_accuracy: 0.9681 - val_acc: 0.6152\n",
      "Epoch 944/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6483 - val_loss: 0.0548 - val_binary_accuracy: 0.9680 - val_acc: 0.6123\n",
      "Epoch 945/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9789 - acc: 0.6478 - val_loss: 0.0548 - val_binary_accuracy: 0.9679 - val_acc: 0.6137\n",
      "Epoch 946/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6500 - val_loss: 0.0547 - val_binary_accuracy: 0.9680 - val_acc: 0.6195\n",
      "Epoch 947/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6544 - val_loss: 0.0552 - val_binary_accuracy: 0.9677 - val_acc: 0.6228\n",
      "Epoch 948/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0365 - binary_accuracy: 0.9788 - acc: 0.6547 - val_loss: 0.0566 - val_binary_accuracy: 0.9668 - val_acc: 0.6832\n",
      "Epoch 949/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0370 - binary_accuracy: 0.9785 - acc: 0.6270 - val_loss: 0.0578 - val_binary_accuracy: 0.9662 - val_acc: 0.6351\n",
      "Epoch 950/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0367 - binary_accuracy: 0.9787 - acc: 0.6443 - val_loss: 0.0557 - val_binary_accuracy: 0.9675 - val_acc: 0.5620\n",
      "Epoch 951/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0365 - binary_accuracy: 0.9789 - acc: 0.6284 - val_loss: 0.0549 - val_binary_accuracy: 0.9681 - val_acc: 0.5685\n",
      "Epoch 952/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0364 - binary_accuracy: 0.9789 - acc: 0.6332 - val_loss: 0.0548 - val_binary_accuracy: 0.9681 - val_acc: 0.6065\n",
      "Epoch 953/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6283 - val_loss: 0.0550 - val_binary_accuracy: 0.9679 - val_acc: 0.5787\n",
      "Epoch 954/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6353 - val_loss: 0.0548 - val_binary_accuracy: 0.9679 - val_acc: 0.6069\n",
      "Epoch 955/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6425 - val_loss: 0.0548 - val_binary_accuracy: 0.9679 - val_acc: 0.6123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 956/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9789 - acc: 0.6392 - val_loss: 0.0546 - val_binary_accuracy: 0.9682 - val_acc: 0.6058\n",
      "Epoch 957/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9789 - acc: 0.6359 - val_loss: 0.0545 - val_binary_accuracy: 0.9681 - val_acc: 0.6014\n",
      "Epoch 958/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9789 - acc: 0.6399 - val_loss: 0.0545 - val_binary_accuracy: 0.9681 - val_acc: 0.6083\n",
      "Epoch 959/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9790 - acc: 0.6428 - val_loss: 0.0543 - val_binary_accuracy: 0.9682 - val_acc: 0.6101\n",
      "Epoch 960/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9790 - acc: 0.6445 - val_loss: 0.0543 - val_binary_accuracy: 0.9684 - val_acc: 0.6188\n",
      "Epoch 961/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0362 - binary_accuracy: 0.9790 - acc: 0.6320 - val_loss: 0.0547 - val_binary_accuracy: 0.9682 - val_acc: 0.5790\n",
      "Epoch 962/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0363 - binary_accuracy: 0.9789 - acc: 0.6290 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.6069\n",
      "Epoch 963/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0364 - binary_accuracy: 0.9789 - acc: 0.6428 - val_loss: 0.0554 - val_binary_accuracy: 0.9676 - val_acc: 0.6018\n",
      "Epoch 964/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9790 - acc: 0.6300 - val_loss: 0.0549 - val_binary_accuracy: 0.9679 - val_acc: 0.6184\n",
      "Epoch 965/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0361 - binary_accuracy: 0.9790 - acc: 0.6355 - val_loss: 0.0545 - val_binary_accuracy: 0.9683 - val_acc: 0.6011\n",
      "Epoch 966/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0361 - binary_accuracy: 0.9790 - acc: 0.6336 - val_loss: 0.0548 - val_binary_accuracy: 0.9678 - val_acc: 0.6112\n",
      "Epoch 967/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0361 - binary_accuracy: 0.9790 - acc: 0.6463 - val_loss: 0.0548 - val_binary_accuracy: 0.9680 - val_acc: 0.6152\n",
      "Epoch 968/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0361 - binary_accuracy: 0.9790 - acc: 0.6387 - val_loss: 0.0547 - val_binary_accuracy: 0.9680 - val_acc: 0.6119\n",
      "Epoch 969/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0360 - binary_accuracy: 0.9791 - acc: 0.6414 - val_loss: 0.0547 - val_binary_accuracy: 0.9680 - val_acc: 0.6275\n",
      "Epoch 970/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0360 - binary_accuracy: 0.9791 - acc: 0.6508 - val_loss: 0.0551 - val_binary_accuracy: 0.9678 - val_acc: 0.6253\n",
      "Epoch 971/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0360 - binary_accuracy: 0.9791 - acc: 0.6495 - val_loss: 0.0546 - val_binary_accuracy: 0.9680 - val_acc: 0.6184\n",
      "Epoch 972/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0360 - binary_accuracy: 0.9791 - acc: 0.6526 - val_loss: 0.0548 - val_binary_accuracy: 0.9680 - val_acc: 0.6137\n",
      "Epoch 973/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0360 - binary_accuracy: 0.9791 - acc: 0.6505 - val_loss: 0.0546 - val_binary_accuracy: 0.9682 - val_acc: 0.6286\n",
      "Epoch 974/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0359 - binary_accuracy: 0.9791 - acc: 0.6570 - val_loss: 0.0547 - val_binary_accuracy: 0.9681 - val_acc: 0.6278\n",
      "Epoch 975/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0359 - binary_accuracy: 0.9791 - acc: 0.6562 - val_loss: 0.0545 - val_binary_accuracy: 0.9682 - val_acc: 0.6159\n",
      "Epoch 976/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0359 - binary_accuracy: 0.9791 - acc: 0.6591 - val_loss: 0.0547 - val_binary_accuracy: 0.9681 - val_acc: 0.6278\n",
      "Epoch 977/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0359 - binary_accuracy: 0.9791 - acc: 0.6637 - val_loss: 0.0562 - val_binary_accuracy: 0.9672 - val_acc: 0.5873\n",
      "Epoch 978/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0362 - binary_accuracy: 0.9791 - acc: 0.6405 - val_loss: 0.0563 - val_binary_accuracy: 0.9670 - val_acc: 0.6239\n",
      "Epoch 979/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0360 - binary_accuracy: 0.9791 - acc: 0.6424 - val_loss: 0.0557 - val_binary_accuracy: 0.9674 - val_acc: 0.6246\n",
      "Epoch 980/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0358 - binary_accuracy: 0.9792 - acc: 0.6423 - val_loss: 0.0550 - val_binary_accuracy: 0.9681 - val_acc: 0.6177\n",
      "Epoch 981/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0357 - binary_accuracy: 0.9793 - acc: 0.6383 - val_loss: 0.0544 - val_binary_accuracy: 0.9685 - val_acc: 0.6014\n",
      "Epoch 982/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0356 - binary_accuracy: 0.9793 - acc: 0.6415 - val_loss: 0.0545 - val_binary_accuracy: 0.9684 - val_acc: 0.6195\n",
      "Epoch 983/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0356 - binary_accuracy: 0.9793 - acc: 0.6462 - val_loss: 0.0543 - val_binary_accuracy: 0.9684 - val_acc: 0.6250\n",
      "Epoch 984/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0356 - binary_accuracy: 0.9793 - acc: 0.6493 - val_loss: 0.0544 - val_binary_accuracy: 0.9682 - val_acc: 0.6275\n",
      "Epoch 985/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0355 - binary_accuracy: 0.9794 - acc: 0.6588 - val_loss: 0.0545 - val_binary_accuracy: 0.9679 - val_acc: 0.6239\n",
      "Epoch 986/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0355 - binary_accuracy: 0.9794 - acc: 0.6552 - val_loss: 0.0546 - val_binary_accuracy: 0.9679 - val_acc: 0.6333\n",
      "Epoch 987/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0355 - binary_accuracy: 0.9794 - acc: 0.6532 - val_loss: 0.0547 - val_binary_accuracy: 0.9681 - val_acc: 0.6336\n",
      "Epoch 988/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0355 - binary_accuracy: 0.9794 - acc: 0.6510 - val_loss: 0.0546 - val_binary_accuracy: 0.9681 - val_acc: 0.6134\n",
      "Epoch 989/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0356 - binary_accuracy: 0.9794 - acc: 0.6541 - val_loss: 0.0566 - val_binary_accuracy: 0.9669 - val_acc: 0.6014\n",
      "Epoch 990/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0356 - binary_accuracy: 0.9794 - acc: 0.6342 - val_loss: 0.0552 - val_binary_accuracy: 0.9676 - val_acc: 0.5794\n",
      "Epoch 991/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0354 - binary_accuracy: 0.9794 - acc: 0.6305 - val_loss: 0.0549 - val_binary_accuracy: 0.9683 - val_acc: 0.6007\n",
      "Epoch 992/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0354 - binary_accuracy: 0.9795 - acc: 0.6482 - val_loss: 0.0553 - val_binary_accuracy: 0.9679 - val_acc: 0.6297\n",
      "Epoch 993/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0353 - binary_accuracy: 0.9795 - acc: 0.6388 - val_loss: 0.0546 - val_binary_accuracy: 0.9682 - val_acc: 0.6061\n",
      "Epoch 994/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0353 - binary_accuracy: 0.9795 - acc: 0.6408 - val_loss: 0.0544 - val_binary_accuracy: 0.9683 - val_acc: 0.6054\n",
      "Epoch 995/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0353 - binary_accuracy: 0.9795 - acc: 0.6488 - val_loss: 0.0549 - val_binary_accuracy: 0.9678 - val_acc: 0.6221\n",
      "Epoch 996/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0353 - binary_accuracy: 0.9795 - acc: 0.6459 - val_loss: 0.0549 - val_binary_accuracy: 0.9680 - val_acc: 0.6231\n",
      "Epoch 997/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0352 - binary_accuracy: 0.9795 - acc: 0.6446 - val_loss: 0.0545 - val_binary_accuracy: 0.9682 - val_acc: 0.6116\n",
      "Epoch 998/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0352 - binary_accuracy: 0.9795 - acc: 0.6537 - val_loss: 0.0544 - val_binary_accuracy: 0.9684 - val_acc: 0.6315\n",
      "Epoch 999/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0352 - binary_accuracy: 0.9796 - acc: 0.6576 - val_loss: 0.0548 - val_binary_accuracy: 0.9681 - val_acc: 0.6282\n",
      "Epoch 1000/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0352 - binary_accuracy: 0.9796 - acc: 0.6567 - val_loss: 0.0549 - val_binary_accuracy: 0.9680 - val_acc: 0.6275\n",
      "Epoch 1001/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0352 - binary_accuracy: 0.9796 - acc: 0.6480 - val_loss: 0.0542 - val_binary_accuracy: 0.9685 - val_acc: 0.6278\n",
      "Epoch 1002/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0351 - binary_accuracy: 0.9796 - acc: 0.6572 - val_loss: 0.0540 - val_binary_accuracy: 0.9686 - val_acc: 0.6246\n",
      "Epoch 1003/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0353 - binary_accuracy: 0.9796 - acc: 0.6591 - val_loss: 0.0547 - val_binary_accuracy: 0.9683 - val_acc: 0.5892\n",
      "Epoch 1004/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0351 - binary_accuracy: 0.9796 - acc: 0.6528 - val_loss: 0.0544 - val_binary_accuracy: 0.9682 - val_acc: 0.6528\n",
      "Epoch 1005/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0351 - binary_accuracy: 0.9796 - acc: 0.6339 - val_loss: 0.0544 - val_binary_accuracy: 0.9683 - val_acc: 0.6278\n",
      "Epoch 1006/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6489 - val_loss: 0.0540 - val_binary_accuracy: 0.9686 - val_acc: 0.6177\n",
      "Epoch 1007/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6442 - val_loss: 0.0539 - val_binary_accuracy: 0.9686 - val_acc: 0.6192\n",
      "Epoch 1008/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6512 - val_loss: 0.0541 - val_binary_accuracy: 0.9685 - val_acc: 0.6119\n",
      "Epoch 1009/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6503 - val_loss: 0.0539 - val_binary_accuracy: 0.9686 - val_acc: 0.6224\n",
      "Epoch 1010/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6588 - val_loss: 0.0537 - val_binary_accuracy: 0.9687 - val_acc: 0.6213\n",
      "Epoch 1011/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6586 - val_loss: 0.0537 - val_binary_accuracy: 0.9687 - val_acc: 0.6141\n",
      "Epoch 1012/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6565 - val_loss: 0.0539 - val_binary_accuracy: 0.9687 - val_acc: 0.6264\n",
      "Epoch 1013/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6563 - val_loss: 0.0540 - val_binary_accuracy: 0.9683 - val_acc: 0.6322\n",
      "Epoch 1014/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6559 - val_loss: 0.0536 - val_binary_accuracy: 0.9686 - val_acc: 0.6250\n",
      "Epoch 1015/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6595 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6311\n",
      "Epoch 1016/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6613 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.6318\n",
      "Epoch 1017/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6607 - val_loss: 0.0535 - val_binary_accuracy: 0.9689 - val_acc: 0.6278\n",
      "Epoch 1018/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6643 - val_loss: 0.0535 - val_binary_accuracy: 0.9689 - val_acc: 0.6297\n",
      "Epoch 1019/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6630 - val_loss: 0.0534 - val_binary_accuracy: 0.9690 - val_acc: 0.6325\n",
      "Epoch 1020/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6668 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6340\n",
      "Epoch 1021/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6618 - val_loss: 0.0544 - val_binary_accuracy: 0.9683 - val_acc: 0.6369\n",
      "Epoch 1022/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6627 - val_loss: 0.0544 - val_binary_accuracy: 0.9683 - val_acc: 0.5913\n",
      "Epoch 1023/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6544 - val_loss: 0.0541 - val_binary_accuracy: 0.9686 - val_acc: 0.6467\n",
      "Epoch 1024/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6675 - val_loss: 0.0547 - val_binary_accuracy: 0.9680 - val_acc: 0.6676\n",
      "Epoch 1025/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0351 - binary_accuracy: 0.9797 - acc: 0.6639 - val_loss: 0.0541 - val_binary_accuracy: 0.9684 - val_acc: 0.6293\n",
      "Epoch 1026/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6655 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6315\n",
      "Epoch 1027/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6618 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6351\n",
      "Epoch 1028/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6651 - val_loss: 0.0531 - val_binary_accuracy: 0.9691 - val_acc: 0.6336\n",
      "Epoch 1029/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6638 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6336\n",
      "Epoch 1030/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6655 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6362\n",
      "Epoch 1031/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6685 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6333\n",
      "Epoch 1032/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6679 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6369\n",
      "Epoch 1033/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6673 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6369\n",
      "Epoch 1034/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6710 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6373\n",
      "Epoch 1035/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6712 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6420\n",
      "Epoch 1036/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6735 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6412\n",
      "Epoch 1037/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6733 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.6485\n",
      "Epoch 1038/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6732 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6459\n",
      "Epoch 1039/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6758 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6412\n",
      "Epoch 1040/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6772 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6441\n",
      "Epoch 1041/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6769 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6514\n",
      "Epoch 1042/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6791 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6438\n",
      "Epoch 1043/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6769 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6445\n",
      "Epoch 1044/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6780 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6485\n",
      "Epoch 1045/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6812 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6503\n",
      "Epoch 1046/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6830 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6571\n",
      "Epoch 1047/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6831 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6571\n",
      "Epoch 1048/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6863 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6524\n",
      "Epoch 1049/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6861 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6568\n",
      "Epoch 1050/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6851 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6553\n",
      "Epoch 1051/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6874 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6618\n",
      "Epoch 1052/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9797 - acc: 0.6893 - val_loss: 0.0531 - val_binary_accuracy: 0.9692 - val_acc: 0.6571\n",
      "Epoch 1053/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0350 - binary_accuracy: 0.9797 - acc: 0.6879 - val_loss: 0.0584 - val_binary_accuracy: 0.9658 - val_acc: 0.6593\n",
      "Epoch 1054/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0361 - binary_accuracy: 0.9791 - acc: 0.6725 - val_loss: 0.0557 - val_binary_accuracy: 0.9674 - val_acc: 0.6499\n",
      "Epoch 1055/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0351 - binary_accuracy: 0.9797 - acc: 0.6510 - val_loss: 0.0541 - val_binary_accuracy: 0.9685 - val_acc: 0.6615\n",
      "Epoch 1056/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6574 - val_loss: 0.0538 - val_binary_accuracy: 0.9685 - val_acc: 0.6239\n",
      "Epoch 1057/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6630 - val_loss: 0.0537 - val_binary_accuracy: 0.9686 - val_acc: 0.6409\n",
      "Epoch 1058/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6651 - val_loss: 0.0537 - val_binary_accuracy: 0.9687 - val_acc: 0.6351\n",
      "Epoch 1059/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6689 - val_loss: 0.0536 - val_binary_accuracy: 0.9687 - val_acc: 0.6409\n",
      "Epoch 1060/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6656 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.6373\n",
      "Epoch 1061/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6691 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6438\n",
      "Epoch 1062/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6680 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.6452\n",
      "Epoch 1063/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6750 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6322\n",
      "Epoch 1064/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6657 - val_loss: 0.0535 - val_binary_accuracy: 0.9689 - val_acc: 0.6448\n",
      "Epoch 1065/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6737 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.6456\n",
      "Epoch 1066/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6737 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.6470\n",
      "Epoch 1067/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6745 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.6463\n",
      "Epoch 1068/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6752 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6456\n",
      "Epoch 1069/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6747 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6510\n",
      "Epoch 1070/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6759 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6532\n",
      "Epoch 1071/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6816 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6532\n",
      "Epoch 1072/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6798 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.6546\n",
      "Epoch 1073/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6805 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6553\n",
      "Epoch 1074/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6825 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6571\n",
      "Epoch 1075/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6850 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.6571\n",
      "Epoch 1076/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6867 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6568\n",
      "Epoch 1077/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6865 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6590\n",
      "Epoch 1078/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6879 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.6604\n",
      "Epoch 1079/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6938 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6633\n",
      "Epoch 1080/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6927 - val_loss: 0.0533 - val_binary_accuracy: 0.9690 - val_acc: 0.6633\n",
      "Epoch 1081/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6893 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6582\n",
      "Epoch 1082/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6881 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.6615\n",
      "Epoch 1083/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6915 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6647\n",
      "Epoch 1084/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6925 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6644\n",
      "Epoch 1085/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6943 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6550\n",
      "Epoch 1086/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6885 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.6571\n",
      "Epoch 1087/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6938 - val_loss: 0.0534 - val_binary_accuracy: 0.9687 - val_acc: 0.6604\n",
      "Epoch 1088/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6911 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.6680\n",
      "Epoch 1089/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6953 - val_loss: 0.0537 - val_binary_accuracy: 0.9686 - val_acc: 0.6669\n",
      "Epoch 1090/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0353 - binary_accuracy: 0.9796 - acc: 0.6892 - val_loss: 0.0557 - val_binary_accuracy: 0.9674 - val_acc: 0.6781\n",
      "Epoch 1091/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0352 - binary_accuracy: 0.9796 - acc: 0.6701 - val_loss: 0.0545 - val_binary_accuracy: 0.9683 - val_acc: 0.6745\n",
      "Epoch 1092/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6861 - val_loss: 0.0539 - val_binary_accuracy: 0.9686 - val_acc: 0.6597\n",
      "Epoch 1093/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6812 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.6546\n",
      "Epoch 1094/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.6876 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6510\n",
      "Epoch 1095/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.6811 - val_loss: 0.0531 - val_binary_accuracy: 0.9688 - val_acc: 0.6651\n",
      "Epoch 1096/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6773 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.6506\n",
      "Epoch 1097/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6798 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.6528\n",
      "Epoch 1098/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6814 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.6539\n",
      "Epoch 1099/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6818 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.6593\n",
      "Epoch 1100/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6829 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.6597\n",
      "Epoch 1101/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6852 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6579\n",
      "Epoch 1102/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6895 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6521\n",
      "Epoch 1103/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6763 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.6579\n",
      "Epoch 1104/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6807 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6532\n",
      "Epoch 1105/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6781 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6438\n",
      "Epoch 1106/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6839 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6600\n",
      "Epoch 1107/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6853 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6604\n",
      "Epoch 1108/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6864 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6611\n",
      "Epoch 1109/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6888 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6640\n",
      "Epoch 1110/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6895 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6532\n",
      "Epoch 1111/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6851 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6665\n",
      "Epoch 1112/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6867 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6622\n",
      "Epoch 1113/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6927 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6611\n",
      "Epoch 1114/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6914 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6662\n",
      "Epoch 1115/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6913 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6658\n",
      "Epoch 1116/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6907 - val_loss: 0.0547 - val_binary_accuracy: 0.9680 - val_acc: 0.6072\n",
      "Epoch 1117/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9797 - acc: 0.6779 - val_loss: 0.0551 - val_binary_accuracy: 0.9676 - val_acc: 0.6427\n",
      "Epoch 1118/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0349 - binary_accuracy: 0.9798 - acc: 0.6726 - val_loss: 0.0549 - val_binary_accuracy: 0.9680 - val_acc: 0.6054\n",
      "Epoch 1119/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9798 - acc: 0.6575 - val_loss: 0.0541 - val_binary_accuracy: 0.9683 - val_acc: 0.6336\n",
      "Epoch 1120/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6679 - val_loss: 0.0536 - val_binary_accuracy: 0.9688 - val_acc: 0.6553\n",
      "Epoch 1121/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6758 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.6485\n",
      "Epoch 1122/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6778 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6528\n",
      "Epoch 1123/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6819 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6492\n",
      "Epoch 1124/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6780 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6481\n",
      "Epoch 1125/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6824 - val_loss: 0.0534 - val_binary_accuracy: 0.9686 - val_acc: 0.6662\n",
      "Epoch 1126/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6765 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6582\n",
      "Epoch 1127/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6830 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6611\n",
      "Epoch 1128/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6841 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6615\n",
      "Epoch 1129/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6851 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6662\n",
      "Epoch 1130/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6879 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6658\n",
      "Epoch 1131/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6894 - val_loss: 0.0530 - val_binary_accuracy: 0.9691 - val_acc: 0.6665\n",
      "Epoch 1132/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6892 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6673\n",
      "Epoch 1133/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6904 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6698\n",
      "Epoch 1134/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6922 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6716\n",
      "Epoch 1135/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6938 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6694\n",
      "Epoch 1136/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6944 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6535\n",
      "Epoch 1137/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6869 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.6799\n",
      "Epoch 1138/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6998 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.6514\n",
      "Epoch 1139/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.7026 - val_loss: 0.0541 - val_binary_accuracy: 0.9683 - val_acc: 0.6897\n",
      "Epoch 1140/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.6852 - val_loss: 0.0542 - val_binary_accuracy: 0.9683 - val_acc: 0.6474\n",
      "Epoch 1141/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6795 - val_loss: 0.0541 - val_binary_accuracy: 0.9684 - val_acc: 0.6524\n",
      "Epoch 1142/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6902 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6561\n",
      "Epoch 1143/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6876 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6676\n",
      "Epoch 1144/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6946 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6687\n",
      "Epoch 1145/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6968 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.6445\n",
      "Epoch 1146/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6911 - val_loss: 0.0531 - val_binary_accuracy: 0.9691 - val_acc: 0.6640\n",
      "Epoch 1147/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6947 - val_loss: 0.0530 - val_binary_accuracy: 0.9693 - val_acc: 0.6662\n",
      "Epoch 1148/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6964 - val_loss: 0.0529 - val_binary_accuracy: 0.9693 - val_acc: 0.6676\n",
      "Epoch 1149/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6997 - val_loss: 0.0529 - val_binary_accuracy: 0.9693 - val_acc: 0.6658\n",
      "Epoch 1150/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6959 - val_loss: 0.0529 - val_binary_accuracy: 0.9692 - val_acc: 0.6680\n",
      "Epoch 1151/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7009 - val_loss: 0.0529 - val_binary_accuracy: 0.9692 - val_acc: 0.6539\n",
      "Epoch 1152/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6909 - val_loss: 0.0529 - val_binary_accuracy: 0.9693 - val_acc: 0.6702\n",
      "Epoch 1153/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7017 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6626\n",
      "Epoch 1154/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6989 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6723\n",
      "Epoch 1155/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7017 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6716\n",
      "Epoch 1156/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7013 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6738\n",
      "Epoch 1157/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7022 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6731\n",
      "Epoch 1158/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7036 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6745\n",
      "Epoch 1159/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7039 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6749\n",
      "Epoch 1160/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7060 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6749\n",
      "Epoch 1161/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7035 - val_loss: 0.0530 - val_binary_accuracy: 0.9693 - val_acc: 0.6843\n",
      "Epoch 1162/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7058 - val_loss: 0.0529 - val_binary_accuracy: 0.9692 - val_acc: 0.6745\n",
      "Epoch 1163/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7068 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6738\n",
      "Epoch 1164/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7065 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6778\n",
      "Epoch 1165/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7087 - val_loss: 0.0528 - val_binary_accuracy: 0.9694 - val_acc: 0.6785\n",
      "Epoch 1166/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7101 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6778\n",
      "Epoch 1167/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7091 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6770\n",
      "Epoch 1168/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7098 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6807\n",
      "Epoch 1169/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7116 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6810\n",
      "Epoch 1170/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7131 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6821\n",
      "Epoch 1171/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7138 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6832\n",
      "Epoch 1172/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7151 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6857\n",
      "Epoch 1173/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7147 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6864\n",
      "Epoch 1174/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7151 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6864\n",
      "Epoch 1175/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7160 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6890\n",
      "Epoch 1176/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7182 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6875\n",
      "Epoch 1177/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7179 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6897\n",
      "Epoch 1178/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7192 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6937\n",
      "Epoch 1179/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7216 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6893\n",
      "Epoch 1180/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7202 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6922\n",
      "Epoch 1181/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7225 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6929\n",
      "Epoch 1182/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7199 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6958\n",
      "Epoch 1183/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7221 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6897\n",
      "Epoch 1184/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7243 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.6955\n",
      "Epoch 1185/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7204 - val_loss: 0.0543 - val_binary_accuracy: 0.9683 - val_acc: 0.6969\n",
      "Epoch 1186/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0359 - binary_accuracy: 0.9792 - acc: 0.7087 - val_loss: 0.0551 - val_binary_accuracy: 0.9678 - val_acc: 0.6553\n",
      "Epoch 1187/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0351 - binary_accuracy: 0.9796 - acc: 0.6879 - val_loss: 0.0542 - val_binary_accuracy: 0.9683 - val_acc: 0.6452\n",
      "Epoch 1188/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6960 - val_loss: 0.0535 - val_binary_accuracy: 0.9688 - val_acc: 0.6684\n",
      "Epoch 1189/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6957 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6716\n",
      "Epoch 1190/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6943 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6698\n",
      "Epoch 1191/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6960 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6734\n",
      "Epoch 1192/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7001 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6745\n",
      "Epoch 1193/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.7042 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6749\n",
      "Epoch 1194/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.7004 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6734\n",
      "Epoch 1195/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.7006 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6774\n",
      "Epoch 1196/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.7060 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6803\n",
      "Epoch 1197/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7054 - val_loss: 0.0531 - val_binary_accuracy: 0.9691 - val_acc: 0.6788\n",
      "Epoch 1198/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7059 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6799\n",
      "Epoch 1199/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7069 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6814\n",
      "Epoch 1200/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7070 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6821\n",
      "Epoch 1201/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7068 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.6835\n",
      "Epoch 1202/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7080 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6832\n",
      "Epoch 1203/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7096 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6821\n",
      "Epoch 1204/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7087 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6839\n",
      "Epoch 1205/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7096 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6832\n",
      "Epoch 1206/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7096 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6854\n",
      "Epoch 1207/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7098 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6861\n",
      "Epoch 1208/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7114 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6854\n",
      "Epoch 1209/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7119 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6875\n",
      "Epoch 1210/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7124 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6868\n",
      "Epoch 1211/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7112 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6879\n",
      "Epoch 1212/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7139 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6886\n",
      "Epoch 1213/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7134 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6901\n",
      "Epoch 1214/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7156 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6890\n",
      "Epoch 1215/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7156 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6901\n",
      "Epoch 1216/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7161 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6904\n",
      "Epoch 1217/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.7184 - val_loss: 0.0538 - val_binary_accuracy: 0.9684 - val_acc: 0.6922\n",
      "Epoch 1218/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.7143 - val_loss: 0.0538 - val_binary_accuracy: 0.9686 - val_acc: 0.6951\n",
      "Epoch 1219/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.7066 - val_loss: 0.0554 - val_binary_accuracy: 0.9677 - val_acc: 0.6398\n",
      "Epoch 1220/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0348 - binary_accuracy: 0.9798 - acc: 0.6918 - val_loss: 0.0540 - val_binary_accuracy: 0.9683 - val_acc: 0.6723\n",
      "Epoch 1221/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0345 - binary_accuracy: 0.9799 - acc: 0.6988 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.6767\n",
      "Epoch 1222/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.6996 - val_loss: 0.0534 - val_binary_accuracy: 0.9687 - val_acc: 0.6944\n",
      "Epoch 1223/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7024 - val_loss: 0.0533 - val_binary_accuracy: 0.9687 - val_acc: 0.6807\n",
      "Epoch 1224/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6982 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6745\n",
      "Epoch 1225/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6974 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6691\n",
      "Epoch 1226/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6951 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6767\n",
      "Epoch 1227/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6964 - val_loss: 0.0527 - val_binary_accuracy: 0.9690 - val_acc: 0.6835\n",
      "Epoch 1228/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7020 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6756\n",
      "Epoch 1229/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6985 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6752\n",
      "Epoch 1230/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7025 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6825\n",
      "Epoch 1231/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7024 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6817\n",
      "Epoch 1232/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6995 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6785\n",
      "Epoch 1233/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7018 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6810\n",
      "Epoch 1234/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7025 - val_loss: 0.0535 - val_binary_accuracy: 0.9689 - val_acc: 0.6872\n",
      "Epoch 1235/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7066 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6698\n",
      "Epoch 1236/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.6975 - val_loss: 0.0527 - val_binary_accuracy: 0.9693 - val_acc: 0.6694\n",
      "Epoch 1237/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7024 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6825\n",
      "Epoch 1238/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7093 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6835\n",
      "Epoch 1239/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7186 - val_loss: 0.0528 - val_binary_accuracy: 0.9690 - val_acc: 0.6846\n",
      "Epoch 1240/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7075 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6810\n",
      "Epoch 1241/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7074 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6854\n",
      "Epoch 1242/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7105 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6861\n",
      "Epoch 1243/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7107 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6872\n",
      "Epoch 1244/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7113 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6893\n",
      "Epoch 1245/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7133 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6929\n",
      "Epoch 1246/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7181 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.6944\n",
      "Epoch 1247/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.7121 - val_loss: 0.0543 - val_binary_accuracy: 0.9683 - val_acc: 0.6875\n",
      "Epoch 1248/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0348 - binary_accuracy: 0.9799 - acc: 0.6953 - val_loss: 0.0543 - val_binary_accuracy: 0.9683 - val_acc: 0.6463\n",
      "Epoch 1249/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0346 - binary_accuracy: 0.9800 - acc: 0.6880 - val_loss: 0.0543 - val_binary_accuracy: 0.9683 - val_acc: 0.6651\n",
      "Epoch 1250/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7028 - val_loss: 0.0534 - val_binary_accuracy: 0.9687 - val_acc: 0.6745\n",
      "Epoch 1251/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7024 - val_loss: 0.0531 - val_binary_accuracy: 0.9688 - val_acc: 0.6749\n",
      "Epoch 1252/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7036 - val_loss: 0.0532 - val_binary_accuracy: 0.9691 - val_acc: 0.6752\n",
      "Epoch 1253/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7027 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6759\n",
      "Epoch 1254/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7037 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6774\n",
      "Epoch 1255/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7049 - val_loss: 0.0528 - val_binary_accuracy: 0.9690 - val_acc: 0.6803\n",
      "Epoch 1256/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7052 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6796\n",
      "Epoch 1257/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7071 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6817\n",
      "Epoch 1258/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7098 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6832\n",
      "Epoch 1259/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7095 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6835\n",
      "Epoch 1260/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7105 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6832\n",
      "Epoch 1261/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7122 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6850\n",
      "Epoch 1262/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7124 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6854\n",
      "Epoch 1263/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7130 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6864\n",
      "Epoch 1264/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7128 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6886\n",
      "Epoch 1265/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7144 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6886\n",
      "Epoch 1266/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7147 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6890\n",
      "Epoch 1267/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7148 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6897\n",
      "Epoch 1268/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7160 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6904\n",
      "Epoch 1269/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7160 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6922\n",
      "Epoch 1270/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7113 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6825\n",
      "Epoch 1271/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7190 - val_loss: 0.0527 - val_binary_accuracy: 0.9693 - val_acc: 0.6933\n",
      "Epoch 1272/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7216 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6948\n",
      "Epoch 1273/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7222 - val_loss: 0.0527 - val_binary_accuracy: 0.9694 - val_acc: 0.6933\n",
      "Epoch 1274/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7227 - val_loss: 0.0526 - val_binary_accuracy: 0.9694 - val_acc: 0.6966\n",
      "Epoch 1275/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7225 - val_loss: 0.0526 - val_binary_accuracy: 0.9694 - val_acc: 0.6966\n",
      "Epoch 1276/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7237 - val_loss: 0.0526 - val_binary_accuracy: 0.9694 - val_acc: 0.6987\n",
      "Epoch 1277/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7252 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6962\n",
      "Epoch 1278/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7220 - val_loss: 0.0529 - val_binary_accuracy: 0.9692 - val_acc: 0.7139\n",
      "Epoch 1279/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7314 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.6933\n",
      "Epoch 1280/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7159 - val_loss: 0.0539 - val_binary_accuracy: 0.9687 - val_acc: 0.7110\n",
      "Epoch 1281/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7092 - val_loss: 0.0536 - val_binary_accuracy: 0.9688 - val_acc: 0.6687\n",
      "Epoch 1282/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.7186 - val_loss: 0.0548 - val_binary_accuracy: 0.9681 - val_acc: 0.6843\n",
      "Epoch 1283/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.6869 - val_loss: 0.0542 - val_binary_accuracy: 0.9683 - val_acc: 0.6597\n",
      "Epoch 1284/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7162 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.7045\n",
      "Epoch 1285/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7196 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6908\n",
      "Epoch 1286/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9800 - acc: 0.7193 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.7045\n",
      "Epoch 1287/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7245 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6951\n",
      "Epoch 1288/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7193 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6893\n",
      "Epoch 1289/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7153 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6817\n",
      "Epoch 1290/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7152 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6861\n",
      "Epoch 1291/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7152 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6843\n",
      "Epoch 1292/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7107 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6774\n",
      "Epoch 1293/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7132 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6955\n",
      "Epoch 1294/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7169 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6872\n",
      "Epoch 1295/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7204 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6998\n",
      "Epoch 1296/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7242 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6984\n",
      "Epoch 1297/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7267 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.7161\n",
      "Epoch 1298/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7262 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.6879\n",
      "Epoch 1299/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7224 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6922\n",
      "Epoch 1300/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7242 - val_loss: 0.0527 - val_binary_accuracy: 0.9694 - val_acc: 0.6825\n",
      "Epoch 1301/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7161 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7052\n",
      "Epoch 1302/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7248 - val_loss: 0.0524 - val_binary_accuracy: 0.9696 - val_acc: 0.7056\n",
      "Epoch 1303/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7273 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7056\n",
      "Epoch 1304/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7267 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7027\n",
      "Epoch 1305/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7266 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7027\n",
      "Epoch 1306/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7269 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7016\n",
      "Epoch 1307/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7272 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7027\n",
      "Epoch 1308/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7283 - val_loss: 0.0523 - val_binary_accuracy: 0.9697 - val_acc: 0.7034\n",
      "Epoch 1309/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7290 - val_loss: 0.0523 - val_binary_accuracy: 0.9697 - val_acc: 0.7045\n",
      "Epoch 1310/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7286 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7049\n",
      "Epoch 1311/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7293 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7056\n",
      "Epoch 1312/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7296 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7042\n",
      "Epoch 1313/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7296 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7078\n",
      "Epoch 1314/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7289 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7081\n",
      "Epoch 1315/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7315 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7103\n",
      "Epoch 1316/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7312 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7107\n",
      "Epoch 1317/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7316 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7092\n",
      "Epoch 1318/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7317 - val_loss: 0.0523 - val_binary_accuracy: 0.9697 - val_acc: 0.7110\n",
      "Epoch 1319/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7330 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7118\n",
      "Epoch 1320/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7341 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7150\n",
      "Epoch 1321/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7359 - val_loss: 0.0524 - val_binary_accuracy: 0.9696 - val_acc: 0.7118\n",
      "Epoch 1322/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7335 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7132\n",
      "Epoch 1323/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7350 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7125\n",
      "Epoch 1324/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7350 - val_loss: 0.0523 - val_binary_accuracy: 0.9697 - val_acc: 0.7146\n",
      "Epoch 1325/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7354 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.7027\n",
      "Epoch 1326/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.7194 - val_loss: 0.0556 - val_binary_accuracy: 0.9673 - val_acc: 0.6470\n",
      "Epoch 1327/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0353 - binary_accuracy: 0.9796 - acc: 0.7053 - val_loss: 0.0545 - val_binary_accuracy: 0.9679 - val_acc: 0.6528\n",
      "Epoch 1328/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7020 - val_loss: 0.0535 - val_binary_accuracy: 0.9686 - val_acc: 0.6875\n",
      "Epoch 1329/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7001 - val_loss: 0.0532 - val_binary_accuracy: 0.9686 - val_acc: 0.6886\n",
      "Epoch 1330/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7076 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6821\n",
      "Epoch 1331/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7123 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6893\n",
      "Epoch 1332/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7128 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6897\n",
      "Epoch 1333/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7128 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6933\n",
      "Epoch 1334/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7133 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6926\n",
      "Epoch 1335/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7136 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6929\n",
      "Epoch 1336/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7133 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6937\n",
      "Epoch 1337/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7151 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6929\n",
      "Epoch 1338/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7153 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6937\n",
      "Epoch 1339/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7159 - val_loss: 0.0525 - val_binary_accuracy: 0.9694 - val_acc: 0.6951\n",
      "Epoch 1340/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7178 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6955\n",
      "Epoch 1341/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7172 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6955\n",
      "Epoch 1342/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7180 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6969\n",
      "Epoch 1343/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7183 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6976\n",
      "Epoch 1344/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7195 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6984\n",
      "Epoch 1345/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7201 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6984\n",
      "Epoch 1346/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7206 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6980\n",
      "Epoch 1347/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7210 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6980\n",
      "Epoch 1348/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7215 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6987\n",
      "Epoch 1349/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7229 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.7002\n",
      "Epoch 1350/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7229 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.6995\n",
      "Epoch 1351/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7239 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7034\n",
      "Epoch 1352/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7238 - val_loss: 0.0525 - val_binary_accuracy: 0.9694 - val_acc: 0.7056\n",
      "Epoch 1353/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7269 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.7099\n",
      "Epoch 1354/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7188 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.6998\n",
      "Epoch 1355/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7261 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6969\n",
      "Epoch 1356/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7211 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7031\n",
      "Epoch 1357/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7241 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7027\n",
      "Epoch 1358/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7245 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7031\n",
      "Epoch 1359/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7257 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7045\n",
      "Epoch 1360/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7281 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7063\n",
      "Epoch 1361/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7283 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.7074\n",
      "Epoch 1362/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7290 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7071\n",
      "Epoch 1363/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7291 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.7078\n",
      "Epoch 1364/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7296 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7081\n",
      "Epoch 1365/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7317 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7092\n",
      "Epoch 1366/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7306 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7096\n",
      "Epoch 1367/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7347 - val_loss: 0.0546 - val_binary_accuracy: 0.9683 - val_acc: 0.7255\n",
      "Epoch 1368/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0349 - binary_accuracy: 0.9798 - acc: 0.7325 - val_loss: 0.0546 - val_binary_accuracy: 0.9680 - val_acc: 0.6752\n",
      "Epoch 1369/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9801 - acc: 0.7200 - val_loss: 0.0538 - val_binary_accuracy: 0.9685 - val_acc: 0.6821\n",
      "Epoch 1370/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7120 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.6966\n",
      "Epoch 1371/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7100 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6973\n",
      "Epoch 1372/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7140 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7020\n",
      "Epoch 1373/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7153 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6995\n",
      "Epoch 1374/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7114 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6948\n",
      "Epoch 1375/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7170 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.7045\n",
      "Epoch 1376/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7155 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.6973\n",
      "Epoch 1377/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7153 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6991\n",
      "Epoch 1378/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7168 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7002\n",
      "Epoch 1379/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7193 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7009\n",
      "Epoch 1380/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7201 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7013\n",
      "Epoch 1381/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7213 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7038\n",
      "Epoch 1382/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7220 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7038\n",
      "Epoch 1383/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7218 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7049\n",
      "Epoch 1384/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7237 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7060\n",
      "Epoch 1385/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7241 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7071\n",
      "Epoch 1386/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7248 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7071\n",
      "Epoch 1387/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7259 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7078\n",
      "Epoch 1388/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7259 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7074\n",
      "Epoch 1389/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7269 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7085\n",
      "Epoch 1390/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7268 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7067\n",
      "Epoch 1391/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7272 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.6897\n",
      "Epoch 1392/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7200 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7092\n",
      "Epoch 1393/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7310 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7096\n",
      "Epoch 1394/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7298 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7089\n",
      "Epoch 1395/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7301 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7096\n",
      "Epoch 1396/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7305 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7096\n",
      "Epoch 1397/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7319 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7136\n",
      "Epoch 1398/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7318 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7139\n",
      "Epoch 1399/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7333 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7139\n",
      "Epoch 1400/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7322 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7150\n",
      "Epoch 1401/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7340 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7154\n",
      "Epoch 1402/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7346 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7157\n",
      "Epoch 1403/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7349 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7157\n",
      "Epoch 1404/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7368 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7157\n",
      "Epoch 1405/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7367 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7157\n",
      "Epoch 1406/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7369 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7175\n",
      "Epoch 1407/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7385 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7190\n",
      "Epoch 1408/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7386 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7190\n",
      "Epoch 1409/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7396 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7183\n",
      "Epoch 1410/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7416 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7219\n",
      "Epoch 1411/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7417 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.7114\n",
      "Epoch 1412/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.7257 - val_loss: 0.0554 - val_binary_accuracy: 0.9677 - val_acc: 0.6568\n",
      "Epoch 1413/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0347 - binary_accuracy: 0.9799 - acc: 0.6957 - val_loss: 0.0547 - val_binary_accuracy: 0.9682 - val_acc: 0.7013\n",
      "Epoch 1414/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0343 - binary_accuracy: 0.9801 - acc: 0.7124 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.6969\n",
      "Epoch 1415/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7039 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6872\n",
      "Epoch 1416/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7236 - val_loss: 0.0530 - val_binary_accuracy: 0.9691 - val_acc: 0.6969\n",
      "Epoch 1417/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7238 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7009\n",
      "Epoch 1418/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7156 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.7056\n",
      "Epoch 1419/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7275 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7042\n",
      "Epoch 1420/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7192 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.7042\n",
      "Epoch 1421/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7262 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.7031\n",
      "Epoch 1422/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7123 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6937\n",
      "Epoch 1423/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7178 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.7038\n",
      "Epoch 1424/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7218 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7049\n",
      "Epoch 1425/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7209 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7060\n",
      "Epoch 1426/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7235 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7045\n",
      "Epoch 1427/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7238 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7063\n",
      "Epoch 1428/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7251 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7067\n",
      "Epoch 1429/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7253 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7071\n",
      "Epoch 1430/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7252 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7063\n",
      "Epoch 1431/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7273 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7056\n",
      "Epoch 1432/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7236 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6991\n",
      "Epoch 1433/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7262 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7074\n",
      "Epoch 1434/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7296 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7081\n",
      "Epoch 1435/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7290 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.7107\n",
      "Epoch 1436/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7306 - val_loss: 0.0531 - val_binary_accuracy: 0.9688 - val_acc: 0.6857\n",
      "Epoch 1437/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7299 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.7002\n",
      "Epoch 1438/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7105 - val_loss: 0.0543 - val_binary_accuracy: 0.9682 - val_acc: 0.7052\n",
      "Epoch 1439/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0345 - binary_accuracy: 0.9800 - acc: 0.7133 - val_loss: 0.0543 - val_binary_accuracy: 0.9683 - val_acc: 0.6698\n",
      "Epoch 1440/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7028 - val_loss: 0.0541 - val_binary_accuracy: 0.9683 - val_acc: 0.6752\n",
      "Epoch 1441/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7084 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.7056\n",
      "Epoch 1442/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7191 - val_loss: 0.0541 - val_binary_accuracy: 0.9684 - val_acc: 0.6879\n",
      "Epoch 1443/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7158 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.6897\n",
      "Epoch 1444/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0340 - binary_accuracy: 0.9802 - acc: 0.7202 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.6821\n",
      "Epoch 1445/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7179 - val_loss: 0.0530 - val_binary_accuracy: 0.9692 - val_acc: 0.7078\n",
      "Epoch 1446/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7104 - val_loss: 0.0526 - val_binary_accuracy: 0.9694 - val_acc: 0.6738\n",
      "Epoch 1447/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7128 - val_loss: 0.0525 - val_binary_accuracy: 0.9694 - val_acc: 0.6828\n",
      "Epoch 1448/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7190 - val_loss: 0.0526 - val_binary_accuracy: 0.9694 - val_acc: 0.6897\n",
      "Epoch 1449/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7213 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.6901\n",
      "Epoch 1450/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7228 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.6922\n",
      "Epoch 1451/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7255 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6929\n",
      "Epoch 1452/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7285 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6915\n",
      "Epoch 1453/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7208 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.6886\n",
      "Epoch 1454/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7216 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.6897\n",
      "Epoch 1455/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7224 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.6904\n",
      "Epoch 1456/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7225 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.6933\n",
      "Epoch 1457/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7227 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.6998\n",
      "Epoch 1458/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7212 - val_loss: 0.0525 - val_binary_accuracy: 0.9694 - val_acc: 0.6911\n",
      "Epoch 1459/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7231 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6966\n",
      "Epoch 1460/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7303 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.6926\n",
      "Epoch 1461/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7251 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6987\n",
      "Epoch 1462/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7267 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.6969\n",
      "Epoch 1463/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7307 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7020\n",
      "Epoch 1464/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7289 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7060\n",
      "Epoch 1465/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7352 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7099\n",
      "Epoch 1466/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7340 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.7508\n",
      "Epoch 1467/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7300 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6929\n",
      "Epoch 1468/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7352 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.7038\n",
      "Epoch 1469/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7200 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.6857\n",
      "Epoch 1470/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7210 - val_loss: 0.0529 - val_binary_accuracy: 0.9689 - val_acc: 0.6919\n",
      "Epoch 1471/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7211 - val_loss: 0.0544 - val_binary_accuracy: 0.9682 - val_acc: 0.7230\n",
      "Epoch 1472/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7262 - val_loss: 0.0541 - val_binary_accuracy: 0.9684 - val_acc: 0.7277\n",
      "Epoch 1473/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7262 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.6897\n",
      "Epoch 1474/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7104 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.7042\n",
      "Epoch 1475/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9803 - acc: 0.7096 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.7038\n",
      "Epoch 1476/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9804 - acc: 0.7195 - val_loss: 0.0530 - val_binary_accuracy: 0.9688 - val_acc: 0.6926\n",
      "Epoch 1477/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9804 - acc: 0.7209 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.7306\n",
      "Epoch 1478/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9804 - acc: 0.7199 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.6712\n",
      "Epoch 1479/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7114 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.6864\n",
      "Epoch 1480/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7139 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.6767\n",
      "Epoch 1481/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7170 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.6879\n",
      "Epoch 1482/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7165 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.6778\n",
      "Epoch 1483/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7139 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.6872\n",
      "Epoch 1484/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7217 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.6886\n",
      "Epoch 1485/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7230 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6882\n",
      "Epoch 1486/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7211 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6944\n",
      "Epoch 1487/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7253 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.6948\n",
      "Epoch 1488/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7271 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.6980\n",
      "Epoch 1489/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7279 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.6973\n",
      "Epoch 1490/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7288 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7005\n",
      "Epoch 1491/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7315 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.6984\n",
      "Epoch 1492/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7111 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6582\n",
      "Epoch 1493/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7271 - val_loss: 0.0537 - val_binary_accuracy: 0.9685 - val_acc: 0.6937\n",
      "Epoch 1494/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7169 - val_loss: 0.0533 - val_binary_accuracy: 0.9688 - val_acc: 0.6499\n",
      "Epoch 1495/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7237 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.7027\n",
      "Epoch 1496/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7225 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.7013\n",
      "Epoch 1497/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7366 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.7110\n",
      "Epoch 1498/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7200 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7139\n",
      "Epoch 1499/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7276 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.7136\n",
      "Epoch 1500/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7285 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6929\n",
      "Epoch 1501/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7234 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7016\n",
      "Epoch 1502/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7246 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.6995\n",
      "Epoch 1503/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7241 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.6991\n",
      "Epoch 1504/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7254 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.6991\n",
      "Epoch 1505/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7262 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.6998\n",
      "Epoch 1506/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7266 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7013\n",
      "Epoch 1507/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7296 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7020\n",
      "Epoch 1508/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7290 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7013\n",
      "Epoch 1509/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7294 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7045\n",
      "Epoch 1510/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7314 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7024\n",
      "Epoch 1511/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7281 - val_loss: 0.0530 - val_binary_accuracy: 0.9691 - val_acc: 0.6835\n",
      "Epoch 1512/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9802 - acc: 0.7198 - val_loss: 0.0545 - val_binary_accuracy: 0.9684 - val_acc: 0.7150\n",
      "Epoch 1513/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9802 - acc: 0.7098 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.7251\n",
      "Epoch 1514/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7229 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6944\n",
      "Epoch 1515/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7342 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7056\n",
      "Epoch 1516/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7294 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7056\n",
      "Epoch 1517/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7276 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7042\n",
      "Epoch 1518/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7275 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7016\n",
      "Epoch 1519/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7265 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.6872\n",
      "Epoch 1520/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9804 - acc: 0.7255 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.6980\n",
      "Epoch 1521/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7237 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7031\n",
      "Epoch 1522/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7303 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.6991\n",
      "Epoch 1523/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7262 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.6995\n",
      "Epoch 1524/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7262 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7013\n",
      "Epoch 1525/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7287 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7027\n",
      "Epoch 1526/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7312 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7063\n",
      "Epoch 1527/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7282 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.6980\n",
      "Epoch 1528/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7266 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7009\n",
      "Epoch 1529/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7293 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7038\n",
      "Epoch 1530/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7396 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7042\n",
      "Epoch 1531/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7301 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7002\n",
      "Epoch 1532/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7326 - val_loss: 0.0528 - val_binary_accuracy: 0.9690 - val_acc: 0.7425\n",
      "Epoch 1533/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7223 - val_loss: 0.0531 - val_binary_accuracy: 0.9688 - val_acc: 0.6915\n",
      "Epoch 1534/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7268 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.7056\n",
      "Epoch 1535/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7184 - val_loss: 0.0524 - val_binary_accuracy: 0.9696 - val_acc: 0.6908\n",
      "Epoch 1536/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7208 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.6951\n",
      "Epoch 1537/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7240 - val_loss: 0.0525 - val_binary_accuracy: 0.9694 - val_acc: 0.6948\n",
      "Epoch 1538/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7311 - val_loss: 0.0528 - val_binary_accuracy: 0.9692 - val_acc: 0.6875\n",
      "Epoch 1539/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7202 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.6987\n",
      "Epoch 1540/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7223 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.6846\n",
      "Epoch 1541/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7297 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.6966\n",
      "Epoch 1542/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7324 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.7179\n",
      "Epoch 1543/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7285 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7092\n",
      "Epoch 1544/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7252 - val_loss: 0.0532 - val_binary_accuracy: 0.9687 - val_acc: 0.7295\n",
      "Epoch 1545/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7277 - val_loss: 0.0535 - val_binary_accuracy: 0.9686 - val_acc: 0.6738\n",
      "Epoch 1546/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9805 - acc: 0.7329 - val_loss: 0.0531 - val_binary_accuracy: 0.9690 - val_acc: 0.7193\n",
      "Epoch 1547/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0339 - binary_accuracy: 0.9803 - acc: 0.7336 - val_loss: 0.0541 - val_binary_accuracy: 0.9686 - val_acc: 0.6590\n",
      "Epoch 1548/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9804 - acc: 0.7059 - val_loss: 0.0536 - val_binary_accuracy: 0.9688 - val_acc: 0.6698\n",
      "Epoch 1549/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7019 - val_loss: 0.0527 - val_binary_accuracy: 0.9694 - val_acc: 0.6307\n",
      "Epoch 1550/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0335 - binary_accuracy: 0.9806 - acc: 0.7109 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.6662\n",
      "Epoch 1551/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7063 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.6759\n",
      "Epoch 1552/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7183 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.6926\n",
      "Epoch 1553/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7245 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.6951\n",
      "Epoch 1554/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7237 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.6948\n",
      "Epoch 1555/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7252 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.6933\n",
      "Epoch 1556/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7252 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.6875\n",
      "Epoch 1557/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7179 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.6995\n",
      "Epoch 1558/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7260 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7060\n",
      "Epoch 1559/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7324 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7081\n",
      "Epoch 1560/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7338 - val_loss: 0.0522 - val_binary_accuracy: 0.9697 - val_acc: 0.7034\n",
      "Epoch 1561/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7344 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7071\n",
      "Epoch 1562/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7327 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7038\n",
      "Epoch 1563/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7328 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7045\n",
      "Epoch 1564/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7323 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7049\n",
      "Epoch 1565/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7323 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7060\n",
      "Epoch 1566/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7321 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7056\n",
      "Epoch 1567/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7366 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7179\n",
      "Epoch 1568/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7377 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7038\n",
      "Epoch 1569/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7314 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7071\n",
      "Epoch 1570/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7337 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7078\n",
      "Epoch 1571/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7347 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7089\n",
      "Epoch 1572/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7369 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7092\n",
      "Epoch 1573/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7357 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7096\n",
      "Epoch 1574/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7377 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7107\n",
      "Epoch 1575/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7377 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7107\n",
      "Epoch 1576/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7395 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7110\n",
      "Epoch 1577/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7379 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7103\n",
      "Epoch 1578/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7398 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7103\n",
      "Epoch 1579/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7405 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7107\n",
      "Epoch 1580/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7397 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7118\n",
      "Epoch 1581/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7407 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7121\n",
      "Epoch 1582/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7411 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7118\n",
      "Epoch 1583/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7418 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7132\n",
      "Epoch 1584/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7421 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7136\n",
      "Epoch 1585/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7424 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7146\n",
      "Epoch 1586/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7433 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7146\n",
      "Epoch 1587/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7426 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7154\n",
      "Epoch 1588/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7442 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7154\n",
      "Epoch 1589/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7440 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7161\n",
      "Epoch 1590/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7443 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7165\n",
      "Epoch 1591/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7449 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7168\n",
      "Epoch 1592/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7455 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7183\n",
      "Epoch 1593/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7462 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7190\n",
      "Epoch 1594/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7468 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7208\n",
      "Epoch 1595/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7477 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7212\n",
      "Epoch 1596/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7460 - val_loss: 0.0540 - val_binary_accuracy: 0.9684 - val_acc: 0.7273\n",
      "Epoch 1597/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0344 - binary_accuracy: 0.9800 - acc: 0.7352 - val_loss: 0.0551 - val_binary_accuracy: 0.9677 - val_acc: 0.7092\n",
      "Epoch 1598/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7319 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.7161\n",
      "Epoch 1599/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7252 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7052\n",
      "Epoch 1600/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7294 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7042\n",
      "Epoch 1601/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7289 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7071\n",
      "Epoch 1602/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7284 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7063\n",
      "Epoch 1603/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7312 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7063\n",
      "Epoch 1604/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7321 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7132\n",
      "Epoch 1605/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7342 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7125\n",
      "Epoch 1606/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7341 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7132\n",
      "Epoch 1607/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7336 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7132\n",
      "Epoch 1608/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7344 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7118\n",
      "Epoch 1609/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7336 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7103\n",
      "Epoch 1610/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7347 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7074\n",
      "Epoch 1611/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7348 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7107\n",
      "Epoch 1612/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7361 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7103\n",
      "Epoch 1613/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7360 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7103\n",
      "Epoch 1614/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7371 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7118\n",
      "Epoch 1615/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7377 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7128\n",
      "Epoch 1616/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7377 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7146\n",
      "Epoch 1617/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7384 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7165\n",
      "Epoch 1618/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7381 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7136\n",
      "Epoch 1619/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7384 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7136\n",
      "Epoch 1620/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7394 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7146\n",
      "Epoch 1621/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7397 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7150\n",
      "Epoch 1622/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7393 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7172\n",
      "Epoch 1623/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7405 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7165\n",
      "Epoch 1624/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7407 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7183\n",
      "Epoch 1625/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7426 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7193\n",
      "Epoch 1626/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7433 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7193\n",
      "Epoch 1627/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7430 - val_loss: 0.0527 - val_binary_accuracy: 0.9693 - val_acc: 0.7118\n",
      "Epoch 1628/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7346 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.6980\n",
      "Epoch 1629/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0335 - binary_accuracy: 0.9806 - acc: 0.7492 - val_loss: 0.0538 - val_binary_accuracy: 0.9685 - val_acc: 0.6966\n",
      "Epoch 1630/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7320 - val_loss: 0.0539 - val_binary_accuracy: 0.9685 - val_acc: 0.6926\n",
      "Epoch 1631/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7304 - val_loss: 0.0529 - val_binary_accuracy: 0.9693 - val_acc: 0.7306\n",
      "Epoch 1632/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7414 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.7175\n",
      "Epoch 1633/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7361 - val_loss: 0.0534 - val_binary_accuracy: 0.9686 - val_acc: 0.7262\n",
      "Epoch 1634/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7307 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7121\n",
      "Epoch 1635/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7299 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7139\n",
      "Epoch 1636/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7332 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7103\n",
      "Epoch 1637/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7306 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7092\n",
      "Epoch 1638/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7310 - val_loss: 0.0520 - val_binary_accuracy: 0.9694 - val_acc: 0.7139\n",
      "Epoch 1639/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7317 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7136\n",
      "Epoch 1640/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7337 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7175\n",
      "Epoch 1641/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9807 - acc: 0.7354 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7175\n",
      "Epoch 1642/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9807 - acc: 0.7343 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7150\n",
      "Epoch 1643/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7274 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7222\n",
      "Epoch 1644/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9807 - acc: 0.7422 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7157\n",
      "Epoch 1645/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7446 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7313\n",
      "Epoch 1646/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7236 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7168\n",
      "Epoch 1647/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7379 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7067\n",
      "Epoch 1648/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7352 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7392\n",
      "Epoch 1649/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7462 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7150\n",
      "Epoch 1650/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7390 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7139\n",
      "Epoch 1651/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7396 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7154\n",
      "Epoch 1652/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7442 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.7385\n",
      "Epoch 1653/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7298 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7284\n",
      "Epoch 1654/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7421 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7168\n",
      "Epoch 1655/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7385 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7172\n",
      "Epoch 1656/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7411 - val_loss: 0.0519 - val_binary_accuracy: 0.9699 - val_acc: 0.7172\n",
      "Epoch 1657/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7425 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7165\n",
      "Epoch 1658/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7426 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7157\n",
      "Epoch 1659/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7426 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7179\n",
      "Epoch 1660/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7439 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7219\n",
      "Epoch 1661/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7400 - val_loss: 0.0521 - val_binary_accuracy: 0.9693 - val_acc: 0.7154\n",
      "Epoch 1662/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7421 - val_loss: 0.0520 - val_binary_accuracy: 0.9694 - val_acc: 0.7165\n",
      "Epoch 1663/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7437 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7168\n",
      "Epoch 1664/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7438 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7179\n",
      "Epoch 1665/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7453 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7197\n",
      "Epoch 1666/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7469 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7215\n",
      "Epoch 1667/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7540 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7215\n",
      "Epoch 1668/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7473 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7273\n",
      "Epoch 1669/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7495 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7266\n",
      "Epoch 1670/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7528 - val_loss: 0.0538 - val_binary_accuracy: 0.9686 - val_acc: 0.7544\n",
      "Epoch 1671/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0339 - binary_accuracy: 0.9804 - acc: 0.7451 - val_loss: 0.0547 - val_binary_accuracy: 0.9679 - val_acc: 0.6608\n",
      "Epoch 1672/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7267 - val_loss: 0.0540 - val_binary_accuracy: 0.9685 - val_acc: 0.6890\n",
      "Epoch 1673/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7206 - val_loss: 0.0530 - val_binary_accuracy: 0.9692 - val_acc: 0.7002\n",
      "Epoch 1674/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7308 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7081\n",
      "Epoch 1675/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7333 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7092\n",
      "Epoch 1676/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7328 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7031\n",
      "Epoch 1677/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7301 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7060\n",
      "Epoch 1678/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7328 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7071\n",
      "Epoch 1679/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7331 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7074\n",
      "Epoch 1680/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7321 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7092\n",
      "Epoch 1681/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7365 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7110\n",
      "Epoch 1682/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7349 - val_loss: 0.0521 - val_binary_accuracy: 0.9697 - val_acc: 0.7107\n",
      "Epoch 1683/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7362 - val_loss: 0.0521 - val_binary_accuracy: 0.9697 - val_acc: 0.7110\n",
      "Epoch 1684/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7359 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7103\n",
      "Epoch 1685/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7367 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7118\n",
      "Epoch 1686/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7376 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7121\n",
      "Epoch 1687/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7382 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7136\n",
      "Epoch 1688/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7388 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7143\n",
      "Epoch 1689/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7391 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7146\n",
      "Epoch 1690/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7403 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7154\n",
      "Epoch 1691/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7397 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7150\n",
      "Epoch 1692/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7406 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7154\n",
      "Epoch 1693/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7417 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7150\n",
      "Epoch 1694/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7423 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7157\n",
      "Epoch 1695/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7433 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7161\n",
      "Epoch 1696/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7433 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7161\n",
      "Epoch 1697/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7444 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7154\n",
      "Epoch 1698/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7447 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7161\n",
      "Epoch 1699/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7450 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7172\n",
      "Epoch 1700/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7451 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7172\n",
      "Epoch 1701/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7457 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7190\n",
      "Epoch 1702/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7458 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7197\n",
      "Epoch 1703/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7474 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7208\n",
      "Epoch 1704/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7464 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7208\n",
      "Epoch 1705/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7477 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7244\n",
      "Epoch 1706/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7476 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7248\n",
      "Epoch 1707/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7477 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7266\n",
      "Epoch 1708/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7485 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7266\n",
      "Epoch 1709/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7494 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7269\n",
      "Epoch 1710/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7495 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7266\n",
      "Epoch 1711/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7503 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7262\n",
      "Epoch 1712/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7493 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7277\n",
      "Epoch 1713/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7516 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7277\n",
      "Epoch 1714/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7513 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7291\n",
      "Epoch 1715/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7523 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7291\n",
      "Epoch 1716/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7526 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7298\n",
      "Epoch 1717/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7535 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7320\n",
      "Epoch 1718/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7546 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7327\n",
      "Epoch 1719/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7572 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7338\n",
      "Epoch 1720/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7567 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7320\n",
      "Epoch 1721/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7560 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7324\n",
      "Epoch 1722/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7572 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7327\n",
      "Epoch 1723/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7569 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7331\n",
      "Epoch 1724/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7584 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7338\n",
      "Epoch 1725/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7580 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7335\n",
      "Epoch 1726/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7585 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7338\n",
      "Epoch 1727/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7585 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7353\n",
      "Epoch 1728/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7595 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7356\n",
      "Epoch 1729/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7605 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7374\n",
      "Epoch 1730/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7611 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7374\n",
      "Epoch 1731/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7618 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7392\n",
      "Epoch 1732/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7631 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7363\n",
      "Epoch 1733/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7617 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7403\n",
      "Epoch 1734/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7631 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7410\n",
      "Epoch 1735/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7633 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7421\n",
      "Epoch 1736/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7652 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7429\n",
      "Epoch 1737/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7649 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7436\n",
      "Epoch 1738/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7648 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7439\n",
      "Epoch 1739/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7662 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7443\n",
      "Epoch 1740/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7661 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7450\n",
      "Epoch 1741/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7672 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7454\n",
      "Epoch 1742/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7675 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7476\n",
      "Epoch 1743/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7687 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7476\n",
      "Epoch 1744/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7686 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7486\n",
      "Epoch 1745/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7696 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7483\n",
      "Epoch 1746/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7696 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7486\n",
      "Epoch 1747/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7704 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7497\n",
      "Epoch 1748/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7712 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7497\n",
      "Epoch 1749/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7713 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7508\n",
      "Epoch 1750/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7727 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7479\n",
      "Epoch 1751/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7728 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7486\n",
      "Epoch 1752/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7729 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7508\n",
      "Epoch 1753/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7728 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7512\n",
      "Epoch 1754/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7739 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7526\n",
      "Epoch 1755/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7739 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7523\n",
      "Epoch 1756/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7746 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7555\n",
      "Epoch 1757/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7750 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7537\n",
      "Epoch 1758/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7764 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7537\n",
      "Epoch 1759/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7760 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7559\n",
      "Epoch 1760/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7762 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7580\n",
      "Epoch 1761/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7774 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7599\n",
      "Epoch 1762/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7788 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7599\n",
      "Epoch 1763/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7791 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7599\n",
      "Epoch 1764/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7784 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7620\n",
      "Epoch 1765/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7795 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7602\n",
      "Epoch 1766/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7795 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7606\n",
      "Epoch 1767/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7807 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7613\n",
      "Epoch 1768/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7817 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7624\n",
      "Epoch 1769/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7807 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7627\n",
      "Epoch 1770/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7826 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7631\n",
      "Epoch 1771/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7829 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7631\n",
      "Epoch 1772/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7827 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7646\n",
      "Epoch 1773/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7831 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7646\n",
      "Epoch 1774/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7841 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7649\n",
      "Epoch 1775/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7836 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7656\n",
      "Epoch 1776/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7855 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7675\n",
      "Epoch 1777/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7866 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7675\n",
      "Epoch 1778/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7866 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7671\n",
      "Epoch 1779/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7866 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7685\n",
      "Epoch 1780/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7864 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7696\n",
      "Epoch 1781/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7887 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7693\n",
      "Epoch 1782/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7888 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7696\n",
      "Epoch 1783/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7891 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7693\n",
      "Epoch 1784/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7892 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7707\n",
      "Epoch 1785/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7893 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7722\n",
      "Epoch 1786/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7909 - val_loss: 0.0518 - val_binary_accuracy: 0.9695 - val_acc: 0.7714\n",
      "Epoch 1787/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7905 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7722\n",
      "Epoch 1788/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7910 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 1789/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7921 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7707\n",
      "Epoch 1790/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7905 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7732\n",
      "Epoch 1791/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7931 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7743\n",
      "Epoch 1792/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7937 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7732\n",
      "Epoch 1793/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7928 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7754\n",
      "Epoch 1794/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7944 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7747\n",
      "Epoch 1795/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7940 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7758\n",
      "Epoch 1796/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7961 - val_loss: 0.0518 - val_binary_accuracy: 0.9695 - val_acc: 0.7736\n",
      "Epoch 1797/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7944 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7761\n",
      "Epoch 1798/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7964 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7769\n",
      "Epoch 1799/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7966 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7765\n",
      "Epoch 1800/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7966 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7794\n",
      "Epoch 1801/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7975 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7769\n",
      "Epoch 1802/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7984 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7761\n",
      "Epoch 1803/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7971 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7783\n",
      "Epoch 1804/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.8000 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7794\n",
      "Epoch 1805/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7943 - val_loss: 0.0564 - val_binary_accuracy: 0.9671 - val_acc: 0.7468\n",
      "Epoch 1806/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0346 - binary_accuracy: 0.9799 - acc: 0.7690 - val_loss: 0.0535 - val_binary_accuracy: 0.9687 - val_acc: 0.7501\n",
      "Epoch 1807/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.7543 - val_loss: 0.0527 - val_binary_accuracy: 0.9694 - val_acc: 0.7219\n",
      "Epoch 1808/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7446 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7291\n",
      "Epoch 1809/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7474 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7385\n",
      "Epoch 1810/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7560 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7418\n",
      "Epoch 1811/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7585 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7432\n",
      "Epoch 1812/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7606 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7436\n",
      "Epoch 1813/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7620 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7443\n",
      "Epoch 1814/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7627 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7443\n",
      "Epoch 1815/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7638 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7443\n",
      "Epoch 1816/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7641 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7450\n",
      "Epoch 1817/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7643 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7458\n",
      "Epoch 1818/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7650 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7472\n",
      "Epoch 1819/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7658 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7468\n",
      "Epoch 1820/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7653 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7458\n",
      "Epoch 1821/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7654 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7472\n",
      "Epoch 1822/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7662 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7483\n",
      "Epoch 1823/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7668 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7486\n",
      "Epoch 1824/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7677 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7486\n",
      "Epoch 1825/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7680 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7458\n",
      "Epoch 1826/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7631 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7465\n",
      "Epoch 1827/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7642 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7476\n",
      "Epoch 1828/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7652 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7479\n",
      "Epoch 1829/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7673 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7494\n",
      "Epoch 1830/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7675 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7497\n",
      "Epoch 1831/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7679 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7501\n",
      "Epoch 1832/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7667 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7392\n",
      "Epoch 1833/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7600 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7465\n",
      "Epoch 1834/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7680 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7533\n",
      "Epoch 1835/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7689 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7533\n",
      "Epoch 1836/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7707 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7541\n",
      "Epoch 1837/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7710 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7548\n",
      "Epoch 1838/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7710 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7552\n",
      "Epoch 1839/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7721 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7559\n",
      "Epoch 1840/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7720 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7559\n",
      "Epoch 1841/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7723 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7577\n",
      "Epoch 1842/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7730 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7580\n",
      "Epoch 1843/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7659 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.6922\n",
      "Epoch 1844/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7723 - val_loss: 0.0564 - val_binary_accuracy: 0.9670 - val_acc: 0.7432\n",
      "Epoch 1845/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0337 - binary_accuracy: 0.9804 - acc: 0.7580 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7161\n",
      "Epoch 1846/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7650 - val_loss: 0.0536 - val_binary_accuracy: 0.9685 - val_acc: 0.7834\n",
      "Epoch 1847/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7666 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7031\n",
      "Epoch 1848/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7606 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7367\n",
      "Epoch 1849/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7594 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7306\n",
      "Epoch 1850/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7612 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7385\n",
      "Epoch 1851/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7592 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7302\n",
      "Epoch 1852/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7582 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7306\n",
      "Epoch 1853/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7610 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7331\n",
      "Epoch 1854/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7648 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7320\n",
      "Epoch 1855/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7664 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7331\n",
      "Epoch 1856/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7666 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7345\n",
      "Epoch 1857/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7665 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7349\n",
      "Epoch 1858/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7670 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7371\n",
      "Epoch 1859/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7671 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7374\n",
      "Epoch 1860/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7694 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7389\n",
      "Epoch 1861/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7693 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7389\n",
      "Epoch 1862/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7737 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7461\n",
      "Epoch 1863/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7730 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7403\n",
      "Epoch 1864/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7701 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7421\n",
      "Epoch 1865/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7718 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7432\n",
      "Epoch 1866/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7730 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7425\n",
      "Epoch 1867/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7728 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7447\n",
      "Epoch 1868/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7751 - val_loss: 0.0523 - val_binary_accuracy: 0.9696 - val_acc: 0.7570\n",
      "Epoch 1869/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7698 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7418\n",
      "Epoch 1870/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7748 - val_loss: 0.0541 - val_binary_accuracy: 0.9682 - val_acc: 0.7074\n",
      "Epoch 1871/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9807 - acc: 0.7650 - val_loss: 0.0539 - val_binary_accuracy: 0.9684 - val_acc: 0.7085\n",
      "Epoch 1872/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7635 - val_loss: 0.0527 - val_binary_accuracy: 0.9693 - val_acc: 0.7483\n",
      "Epoch 1873/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7681 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7374\n",
      "Epoch 1874/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7659 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7371\n",
      "Epoch 1875/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7622 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7342\n",
      "Epoch 1876/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7533 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7418\n",
      "Epoch 1877/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7662 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7363\n",
      "Epoch 1878/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7645 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7349\n",
      "Epoch 1879/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7639 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7349\n",
      "Epoch 1880/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7643 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7349\n",
      "Epoch 1881/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7656 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7360\n",
      "Epoch 1882/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7658 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7367\n",
      "Epoch 1883/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7668 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7371\n",
      "Epoch 1884/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7667 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7356\n",
      "Epoch 1885/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7673 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7356\n",
      "Epoch 1886/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7680 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7371\n",
      "Epoch 1887/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7682 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7400\n",
      "Epoch 1888/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7697 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7410\n",
      "Epoch 1889/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7715 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7465\n",
      "Epoch 1890/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7756 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7360\n",
      "Epoch 1891/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7474 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7515\n",
      "Epoch 1892/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7724 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7436\n",
      "Epoch 1893/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7684 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7400\n",
      "Epoch 1894/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7678 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7396\n",
      "Epoch 1895/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7693 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7414\n",
      "Epoch 1896/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7698 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7421\n",
      "Epoch 1897/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7702 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7429\n",
      "Epoch 1898/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7709 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7429\n",
      "Epoch 1899/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7711 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7436\n",
      "Epoch 1900/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7717 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7447\n",
      "Epoch 1901/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7726 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7432\n",
      "Epoch 1902/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7731 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7443\n",
      "Epoch 1903/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7726 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7461\n",
      "Epoch 1904/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7739 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7458\n",
      "Epoch 1905/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7740 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7468\n",
      "Epoch 1906/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7750 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7472\n",
      "Epoch 1907/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7744 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7468\n",
      "Epoch 1908/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7749 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7465\n",
      "Epoch 1909/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7760 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7465\n",
      "Epoch 1910/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7758 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7461\n",
      "Epoch 1911/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7759 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7461\n",
      "Epoch 1912/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7774 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7472\n",
      "Epoch 1913/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7774 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7479\n",
      "Epoch 1914/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7777 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7483\n",
      "Epoch 1915/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7786 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7483\n",
      "Epoch 1916/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7793 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7483\n",
      "Epoch 1917/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7790 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7486\n",
      "Epoch 1918/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7806 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7486\n",
      "Epoch 1919/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7815 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7505\n",
      "Epoch 1920/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7805 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7501\n",
      "Epoch 1921/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7816 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7501\n",
      "Epoch 1922/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7816 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7512\n",
      "Epoch 1923/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7816 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7512\n",
      "Epoch 1924/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7820 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7512\n",
      "Epoch 1925/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7822 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7533\n",
      "Epoch 1926/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7829 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7530\n",
      "Epoch 1927/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7835 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7541\n",
      "Epoch 1928/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7835 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7541\n",
      "Epoch 1929/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7848 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7544\n",
      "Epoch 1930/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7843 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7548\n",
      "Epoch 1931/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7848 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7555\n",
      "Epoch 1932/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7855 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7555\n",
      "Epoch 1933/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7867 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7562\n",
      "Epoch 1934/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7873 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7570\n",
      "Epoch 1935/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7864 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7566\n",
      "Epoch 1936/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7875 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7566\n",
      "Epoch 1937/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7869 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7584\n",
      "Epoch 1938/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7884 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7613\n",
      "Epoch 1939/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7896 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7602\n",
      "Epoch 1940/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7894 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7613\n",
      "Epoch 1941/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7880 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7613\n",
      "Epoch 1942/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7892 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7620\n",
      "Epoch 1943/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7899 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7620\n",
      "Epoch 1944/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7911 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7635\n",
      "Epoch 1945/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7912 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7642\n",
      "Epoch 1946/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7905 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7642\n",
      "Epoch 1947/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7919 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7649\n",
      "Epoch 1948/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7925 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7664\n",
      "Epoch 1949/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7922 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7656\n",
      "Epoch 1950/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7926 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7675\n",
      "Epoch 1951/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7927 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7685\n",
      "Epoch 1952/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7936 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7685\n",
      "Epoch 1953/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7939 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7696\n",
      "Epoch 1954/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7696\n",
      "Epoch 1955/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7696\n",
      "Epoch 1956/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7950 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7703\n",
      "Epoch 1957/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7957 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 1958/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7966 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 1959/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7970 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 1960/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7961 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 1961/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7979 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7703\n",
      "Epoch 1962/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7972 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7707\n",
      "Epoch 1963/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7984 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7718\n",
      "Epoch 1964/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7983 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7707\n",
      "Epoch 1965/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7987 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7722\n",
      "Epoch 1966/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7996 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7747\n",
      "Epoch 1967/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8000 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 1968/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8000 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7750\n",
      "Epoch 1969/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8010 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7765\n",
      "Epoch 1970/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8011 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7776\n",
      "Epoch 1971/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8021 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7779\n",
      "Epoch 1972/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8028 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7769\n",
      "Epoch 1973/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8019 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7794\n",
      "Epoch 1974/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8024 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7797\n",
      "Epoch 1975/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8039 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7797\n",
      "Epoch 1976/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8039 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7797\n",
      "Epoch 1977/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8046 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7797\n",
      "Epoch 1978/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8049 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7801\n",
      "Epoch 1979/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8047 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7816\n",
      "Epoch 1980/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8053 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7812\n",
      "Epoch 1981/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8065 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7816\n",
      "Epoch 1982/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8065 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7823\n",
      "Epoch 1983/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8065 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7855\n",
      "Epoch 1984/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8064 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7866\n",
      "Epoch 1985/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8075 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7852\n",
      "Epoch 1986/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8077 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7844\n",
      "Epoch 1987/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8074 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7863\n",
      "Epoch 1988/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8088 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7859\n",
      "Epoch 1989/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8090 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7852\n",
      "Epoch 1990/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8081 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7873\n",
      "Epoch 1991/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8096 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7859\n",
      "Epoch 1992/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8097 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7866\n",
      "Epoch 1993/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8106 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7863\n",
      "Epoch 1994/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8111 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7870\n",
      "Epoch 1995/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8103 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7877\n",
      "Epoch 1996/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8110 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7888\n",
      "Epoch 1997/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8119 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7881\n",
      "Epoch 1998/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8118 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7888\n",
      "Epoch 1999/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8130 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7881\n",
      "Epoch 2000/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8127 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7892\n",
      "Epoch 2001/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8126 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7899\n",
      "Epoch 2002/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8140 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7899\n",
      "Epoch 2003/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8130 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7906\n",
      "Epoch 2004/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8141 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7906\n",
      "Epoch 2005/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8140 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7913\n",
      "Epoch 2006/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8147 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7902\n",
      "Epoch 2007/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8143 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7928\n",
      "Epoch 2008/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8152 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7913\n",
      "Epoch 2009/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8148 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7924\n",
      "Epoch 2010/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.8152 - val_loss: 0.0559 - val_binary_accuracy: 0.9673 - val_acc: 0.7823\n",
      "Epoch 2011/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0342 - binary_accuracy: 0.9801 - acc: 0.7809 - val_loss: 0.0537 - val_binary_accuracy: 0.9686 - val_acc: 0.7400\n",
      "Epoch 2012/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7905 - val_loss: 0.0529 - val_binary_accuracy: 0.9692 - val_acc: 0.7910\n",
      "Epoch 2013/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8023 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7508\n",
      "Epoch 2014/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7749 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.7624\n",
      "Epoch 2015/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7880 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7700\n",
      "Epoch 2016/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7866 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7675\n",
      "Epoch 2017/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7880 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7635\n",
      "Epoch 2018/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7884 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.7627\n",
      "Epoch 2019/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7965 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.7729\n",
      "Epoch 2020/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7656\n",
      "Epoch 2021/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7941 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7682\n",
      "Epoch 2022/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7942 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7711\n",
      "Epoch 2023/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7946 - val_loss: 0.0524 - val_binary_accuracy: 0.9695 - val_acc: 0.7707\n",
      "Epoch 2024/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7703\n",
      "Epoch 2025/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7707\n",
      "Epoch 2026/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7700\n",
      "Epoch 2027/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7948 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7700\n",
      "Epoch 2028/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7947 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7696\n",
      "Epoch 2029/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7947 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7714\n",
      "Epoch 2030/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7970 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7736\n",
      "Epoch 2031/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7956 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7718\n",
      "Epoch 2032/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7951 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7707\n",
      "Epoch 2033/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7949 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7703\n",
      "Epoch 2034/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7947 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7714\n",
      "Epoch 2035/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7954 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7722\n",
      "Epoch 2036/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8000 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.7910\n",
      "Epoch 2037/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8021 - val_loss: 0.0521 - val_binary_accuracy: 0.9697 - val_acc: 0.7740\n",
      "Epoch 2038/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7942 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7707\n",
      "Epoch 2039/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7940 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7700\n",
      "Epoch 2040/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7937 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7703\n",
      "Epoch 2041/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7934 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7707\n",
      "Epoch 2042/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7943 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2043/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7945 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2044/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7943 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2045/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7947 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2046/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7951 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2047/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7954 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7714\n",
      "Epoch 2048/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7962 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2049/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7967 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2050/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7965 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2051/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7966 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2052/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7972 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2053/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7972 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2054/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7972 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7729\n",
      "Epoch 2055/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7977 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7732\n",
      "Epoch 2056/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7976 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7729\n",
      "Epoch 2057/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7984 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7725\n",
      "Epoch 2058/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7986 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7732\n",
      "Epoch 2059/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7984 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7736\n",
      "Epoch 2060/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7986 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7732\n",
      "Epoch 2061/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7988 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7740\n",
      "Epoch 2062/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7986 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7736\n",
      "Epoch 2063/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7990 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7743\n",
      "Epoch 2064/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.7998 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7747\n",
      "Epoch 2065/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8000 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7743\n",
      "Epoch 2066/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8008 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7736\n",
      "Epoch 2067/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8003 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7736\n",
      "Epoch 2068/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8005 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7740\n",
      "Epoch 2069/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8009 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7743\n",
      "Epoch 2070/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8011 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7740\n",
      "Epoch 2071/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8009 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7743\n",
      "Epoch 2072/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8010 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7743\n",
      "Epoch 2073/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8012 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7750\n",
      "Epoch 2074/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8011 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7750\n",
      "Epoch 2075/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8016 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7754\n",
      "Epoch 2076/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8021 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7754\n",
      "Epoch 2077/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8020 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 2078/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8025 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 2079/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8028 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7754\n",
      "Epoch 2080/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8032 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7750\n",
      "Epoch 2081/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8032 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7754\n",
      "Epoch 2082/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8040 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7765\n",
      "Epoch 2083/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8037 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7754\n",
      "Epoch 2084/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8039 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7765\n",
      "Epoch 2085/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8045 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7761\n",
      "Epoch 2086/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8046 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7772\n",
      "Epoch 2087/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8047 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7769\n",
      "Epoch 2088/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8049 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7765\n",
      "Epoch 2089/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8051 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 2090/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8047 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7769\n",
      "Epoch 2091/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8052 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7776\n",
      "Epoch 2092/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8064 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 2093/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8057 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 2094/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8060 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 2095/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8065 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7779\n",
      "Epoch 2096/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8059 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7783\n",
      "Epoch 2097/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8065 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7790\n",
      "Epoch 2098/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8059 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7812\n",
      "Epoch 2099/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.8039 - val_loss: 0.0548 - val_binary_accuracy: 0.9679 - val_acc: 0.7852\n",
      "Epoch 2100/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0341 - binary_accuracy: 0.9801 - acc: 0.7828 - val_loss: 0.0541 - val_binary_accuracy: 0.9683 - val_acc: 0.7508\n",
      "Epoch 2101/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7753 - val_loss: 0.0535 - val_binary_accuracy: 0.9686 - val_acc: 0.7360\n",
      "Epoch 2102/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7758 - val_loss: 0.0528 - val_binary_accuracy: 0.9689 - val_acc: 0.7566\n",
      "Epoch 2103/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7811 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7324\n",
      "Epoch 2104/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7855 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.7595\n",
      "Epoch 2105/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7892 - val_loss: 0.0527 - val_binary_accuracy: 0.9690 - val_acc: 0.7631\n",
      "Epoch 2106/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7905 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7577\n",
      "Epoch 2107/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7892 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7580\n",
      "Epoch 2108/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7887 - val_loss: 0.0523 - val_binary_accuracy: 0.9692 - val_acc: 0.7584\n",
      "Epoch 2109/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7893 - val_loss: 0.0523 - val_binary_accuracy: 0.9692 - val_acc: 0.7588\n",
      "Epoch 2110/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7889 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7588\n",
      "Epoch 2111/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7899 - val_loss: 0.0522 - val_binary_accuracy: 0.9692 - val_acc: 0.7591\n",
      "Epoch 2112/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7896 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7591\n",
      "Epoch 2113/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7897 - val_loss: 0.0521 - val_binary_accuracy: 0.9693 - val_acc: 0.7588\n",
      "Epoch 2114/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7897 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7584\n",
      "Epoch 2115/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7899 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7591\n",
      "Epoch 2116/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7902 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7595\n",
      "Epoch 2117/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7903 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7595\n",
      "Epoch 2118/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7903 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7591\n",
      "Epoch 2119/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7908 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7595\n",
      "Epoch 2120/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7906 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7599\n",
      "Epoch 2121/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7905 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7606\n",
      "Epoch 2122/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7912 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7606\n",
      "Epoch 2123/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7910 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7599\n",
      "Epoch 2124/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7908 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7602\n",
      "Epoch 2125/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7909 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7602\n",
      "Epoch 2126/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7915 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7602\n",
      "Epoch 2127/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7915 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7602\n",
      "Epoch 2128/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7914 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7602\n",
      "Epoch 2129/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7922 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7606\n",
      "Epoch 2130/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7919 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7609\n",
      "Epoch 2131/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7920 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7613\n",
      "Epoch 2132/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7922 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7613\n",
      "Epoch 2133/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7921 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7620\n",
      "Epoch 2134/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7925 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7624\n",
      "Epoch 2135/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7928 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7617\n",
      "Epoch 2136/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7929 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7620\n",
      "Epoch 2137/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7945 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7617\n",
      "Epoch 2138/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7924 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7573\n",
      "Epoch 2139/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7889 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7638\n",
      "Epoch 2140/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7912 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7642\n",
      "Epoch 2141/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7926 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7555\n",
      "Epoch 2142/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7892 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7635\n",
      "Epoch 2143/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7920 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7642\n",
      "Epoch 2144/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7936 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7660\n",
      "Epoch 2145/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7947 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7675\n",
      "Epoch 2146/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7949 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7675\n",
      "Epoch 2147/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7942 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7667\n",
      "Epoch 2148/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7989 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2149/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7982 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7667\n",
      "Epoch 2150/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7961 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7678\n",
      "Epoch 2151/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9809 - acc: 0.7931 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7703\n",
      "Epoch 2152/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.7883 - val_loss: 0.0556 - val_binary_accuracy: 0.9674 - val_acc: 0.7812\n",
      "Epoch 2153/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0336 - binary_accuracy: 0.9805 - acc: 0.7946 - val_loss: 0.0540 - val_binary_accuracy: 0.9684 - val_acc: 0.8040\n",
      "Epoch 2154/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7586 - val_loss: 0.0530 - val_binary_accuracy: 0.9690 - val_acc: 0.7342\n",
      "Epoch 2155/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7603 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7259\n",
      "Epoch 2156/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7635 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7410\n",
      "Epoch 2157/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7707 - val_loss: 0.0518 - val_binary_accuracy: 0.9699 - val_acc: 0.7443\n",
      "Epoch 2158/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7744 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7501\n",
      "Epoch 2159/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7698 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7461\n",
      "Epoch 2160/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7742 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7512\n",
      "Epoch 2161/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7758 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7548\n",
      "Epoch 2162/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7766 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7548\n",
      "Epoch 2163/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7777 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7573\n",
      "Epoch 2164/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7789 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7580\n",
      "Epoch 2165/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7795 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7599\n",
      "Epoch 2166/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7799 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7602\n",
      "Epoch 2167/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7807 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7613\n",
      "Epoch 2168/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7818 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7620\n",
      "Epoch 2169/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7821 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7631\n",
      "Epoch 2170/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7831 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7638\n",
      "Epoch 2171/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7843 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7646\n",
      "Epoch 2172/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7848 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7649\n",
      "Epoch 2173/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7846 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7649\n",
      "Epoch 2174/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7852 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7653\n",
      "Epoch 2175/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7855 - val_loss: 0.0519 - val_binary_accuracy: 0.9698 - val_acc: 0.7635\n",
      "Epoch 2176/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7818 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7599\n",
      "Epoch 2177/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7850 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7635\n",
      "Epoch 2178/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7872 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7649\n",
      "Epoch 2179/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7885 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7656\n",
      "Epoch 2180/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7886 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7653\n",
      "Epoch 2181/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7889 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7656\n",
      "Epoch 2182/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7899 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7671\n",
      "Epoch 2183/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7901 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7678\n",
      "Epoch 2184/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7910 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7682\n",
      "Epoch 2185/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7946 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7685\n",
      "Epoch 2186/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7913 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7664\n",
      "Epoch 2187/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7892 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7664\n",
      "Epoch 2188/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7901 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7664\n",
      "Epoch 2189/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7903 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7675\n",
      "Epoch 2190/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7906 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7682\n",
      "Epoch 2191/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7917 - val_loss: 0.0516 - val_binary_accuracy: 0.9700 - val_acc: 0.7689\n",
      "Epoch 2192/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7909 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7675\n",
      "Epoch 2193/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7900 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7685\n",
      "Epoch 2194/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7918 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7700\n",
      "Epoch 2195/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7926 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7700\n",
      "Epoch 2196/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7926 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7675\n",
      "Epoch 2197/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7851 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7624\n",
      "Epoch 2198/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7909 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7675\n",
      "Epoch 2199/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7926 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7682\n",
      "Epoch 2200/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7917 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7660\n",
      "Epoch 2201/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7889 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7638\n",
      "Epoch 2202/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7913 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7689\n",
      "Epoch 2203/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7919 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7696\n",
      "Epoch 2204/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7926 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7689\n",
      "Epoch 2205/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7922 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7823\n",
      "Epoch 2206/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7984 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7678\n",
      "Epoch 2207/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7963 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2208/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7958 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7718\n",
      "Epoch 2209/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7952 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7711\n",
      "Epoch 2210/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7960 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2211/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7955 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7732\n",
      "Epoch 2212/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7961 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7732\n",
      "Epoch 2213/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7969 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7729\n",
      "Epoch 2214/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7970 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7736\n",
      "Epoch 2215/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7981 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7750\n",
      "Epoch 2216/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7979 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7750\n",
      "Epoch 2217/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7987 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7761\n",
      "Epoch 2218/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7984 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7761\n",
      "Epoch 2219/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7990 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7761\n",
      "Epoch 2220/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7993 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 2221/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7995 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7769\n",
      "Epoch 2222/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7994 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 2223/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8007 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7779\n",
      "Epoch 2224/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8002 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 2225/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8008 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 2226/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8012 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7779\n",
      "Epoch 2227/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8011 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7779\n",
      "Epoch 2228/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8003 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 2229/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8030 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7736\n",
      "Epoch 2230/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9809 - acc: 0.7995 - val_loss: 0.0529 - val_binary_accuracy: 0.9690 - val_acc: 0.7656\n",
      "Epoch 2231/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9804 - acc: 0.7818 - val_loss: 0.0553 - val_binary_accuracy: 0.9675 - val_acc: 0.7906\n",
      "Epoch 2232/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7826 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7378\n",
      "Epoch 2233/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7767 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7685\n",
      "Epoch 2234/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7876 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7400\n",
      "Epoch 2235/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7950 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.7642\n",
      "Epoch 2236/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7920 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7584\n",
      "Epoch 2237/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7919 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7584\n",
      "Epoch 2238/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7913 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7591\n",
      "Epoch 2239/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7915 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7591\n",
      "Epoch 2240/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7909 - val_loss: 0.0516 - val_binary_accuracy: 0.9701 - val_acc: 0.7508\n",
      "Epoch 2241/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7876 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7552\n",
      "Epoch 2242/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7910 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7577\n",
      "Epoch 2243/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7924 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7584\n",
      "Epoch 2244/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7927 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7591\n",
      "Epoch 2245/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7926 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7588\n",
      "Epoch 2246/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7927 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7591\n",
      "Epoch 2247/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7931 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7595\n",
      "Epoch 2248/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7935 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7606\n",
      "Epoch 2249/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7935 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7609\n",
      "Epoch 2250/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7938 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7624\n",
      "Epoch 2251/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7942 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7613\n",
      "Epoch 2252/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7938 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7617\n",
      "Epoch 2253/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7933 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7617\n",
      "Epoch 2254/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7938 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7620\n",
      "Epoch 2255/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7944 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7631\n",
      "Epoch 2256/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7943 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7631\n",
      "Epoch 2257/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7940 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7631\n",
      "Epoch 2258/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7950 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7631\n",
      "Epoch 2259/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7949 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7638\n",
      "Epoch 2260/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7952 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7638\n",
      "Epoch 2261/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7955 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7635\n",
      "Epoch 2262/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7957 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7638\n",
      "Epoch 2263/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7961 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7642\n",
      "Epoch 2264/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7961 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7635\n",
      "Epoch 2265/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7964 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7631\n",
      "Epoch 2266/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7959 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7635\n",
      "Epoch 2267/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7966 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7642\n",
      "Epoch 2268/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7966 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7642\n",
      "Epoch 2269/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7963 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7646\n",
      "Epoch 2270/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7966 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7646\n",
      "Epoch 2271/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7969 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7649\n",
      "Epoch 2272/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7969 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7649\n",
      "Epoch 2273/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7971 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7642\n",
      "Epoch 2274/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7975 - val_loss: 0.0514 - val_binary_accuracy: 0.9697 - val_acc: 0.7649\n",
      "Epoch 2275/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7968 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7646\n",
      "Epoch 2276/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7981 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7649\n",
      "Epoch 2277/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7973 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7653\n",
      "Epoch 2278/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7977 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7653\n",
      "Epoch 2279/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7972 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7656\n",
      "Epoch 2280/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7957 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7635\n",
      "Epoch 2281/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7977 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7664\n",
      "Epoch 2282/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7991 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7675\n",
      "Epoch 2283/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7989 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7671\n",
      "Epoch 2284/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7993 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7671\n",
      "Epoch 2285/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7989 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7685\n",
      "Epoch 2286/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7991 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7689\n",
      "Epoch 2287/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7995 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7689\n",
      "Epoch 2288/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7995 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7689\n",
      "Epoch 2289/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7994 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7685\n",
      "Epoch 2290/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8010 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7689\n",
      "Epoch 2291/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8003 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7689\n",
      "Epoch 2292/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8009 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7689\n",
      "Epoch 2293/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8007 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7689\n",
      "Epoch 2294/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8012 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7693\n",
      "Epoch 2295/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8023 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 2296/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8024 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7700\n",
      "Epoch 2297/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8022 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 2298/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8025 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 2299/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8025 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7714\n",
      "Epoch 2300/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8032 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7714\n",
      "Epoch 2301/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0332 - binary_accuracy: 0.9807 - acc: 0.8011 - val_loss: 0.0555 - val_binary_accuracy: 0.9675 - val_acc: 0.8022\n",
      "Epoch 2302/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0334 - binary_accuracy: 0.9806 - acc: 0.7933 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.7461\n",
      "Epoch 2303/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.7782 - val_loss: 0.0527 - val_binary_accuracy: 0.9691 - val_acc: 0.7624\n",
      "Epoch 2304/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7984 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7465\n",
      "Epoch 2305/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7686 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7537\n",
      "Epoch 2306/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7824 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7642\n",
      "Epoch 2307/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7815 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7530\n",
      "Epoch 2308/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7790 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7570\n",
      "Epoch 2309/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7826 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7588\n",
      "Epoch 2310/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7841 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7606\n",
      "Epoch 2311/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7853 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7617\n",
      "Epoch 2312/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7867 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7627\n",
      "Epoch 2313/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7877 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7627\n",
      "Epoch 2314/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7873 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7638\n",
      "Epoch 2315/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7880 - val_loss: 0.0517 - val_binary_accuracy: 0.9695 - val_acc: 0.7613\n",
      "Epoch 2316/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7869 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7537\n",
      "Epoch 2317/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7876 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7620\n",
      "Epoch 2318/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7873 - val_loss: 0.0520 - val_binary_accuracy: 0.9694 - val_acc: 0.7624\n",
      "Epoch 2319/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7864 - val_loss: 0.0519 - val_binary_accuracy: 0.9694 - val_acc: 0.7609\n",
      "Epoch 2320/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7882 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7627\n",
      "Epoch 2321/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7883 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7638\n",
      "Epoch 2322/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7889 - val_loss: 0.0518 - val_binary_accuracy: 0.9695 - val_acc: 0.7646\n",
      "Epoch 2323/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7897 - val_loss: 0.0518 - val_binary_accuracy: 0.9695 - val_acc: 0.7649\n",
      "Epoch 2324/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7901 - val_loss: 0.0518 - val_binary_accuracy: 0.9695 - val_acc: 0.7642\n",
      "Epoch 2325/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7914 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7646\n",
      "Epoch 2326/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7914 - val_loss: 0.0517 - val_binary_accuracy: 0.9695 - val_acc: 0.7638\n",
      "Epoch 2327/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7915 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7642\n",
      "Epoch 2328/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7916 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7649\n",
      "Epoch 2329/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7926 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7649\n",
      "Epoch 2330/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7933 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7646\n",
      "Epoch 2331/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7934 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7649\n",
      "Epoch 2332/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7938 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7649\n",
      "Epoch 2333/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7945 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7664\n",
      "Epoch 2334/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7946 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7660\n",
      "Epoch 2335/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7947 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7664\n",
      "Epoch 2336/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7939 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7646\n",
      "Epoch 2337/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7945 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7653\n",
      "Epoch 2338/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7948 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7660\n",
      "Epoch 2339/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7956 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7660\n",
      "Epoch 2340/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7954 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7671\n",
      "Epoch 2341/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7965 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7685\n",
      "Epoch 2342/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7970 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7693\n",
      "Epoch 2343/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7968 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7685\n",
      "Epoch 2344/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7973 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7703\n",
      "Epoch 2345/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7975 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7703\n",
      "Epoch 2346/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7980 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7707\n",
      "Epoch 2347/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7979 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7700\n",
      "Epoch 2348/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7987 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2349/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7991 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2350/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7993 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7718\n",
      "Epoch 2351/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7995 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7714\n",
      "Epoch 2352/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7997 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7722\n",
      "Epoch 2353/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7996 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7725\n",
      "Epoch 2354/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8002 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7729\n",
      "Epoch 2355/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8005 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7747\n",
      "Epoch 2356/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8005 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7740\n",
      "Epoch 2357/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8014 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7747\n",
      "Epoch 2358/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8019 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7758\n",
      "Epoch 2359/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8014 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7754\n",
      "Epoch 2360/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8021 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7761\n",
      "Epoch 2361/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8019 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7758\n",
      "Epoch 2362/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8021 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7769\n",
      "Epoch 2363/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8024 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 2364/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8026 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7765\n",
      "Epoch 2365/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8035 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 2366/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8039 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 2367/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8039 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7776\n",
      "Epoch 2368/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8041 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7787\n",
      "Epoch 2369/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8046 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7794\n",
      "Epoch 2370/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8062 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7797\n",
      "Epoch 2371/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.8009 - val_loss: 0.0566 - val_binary_accuracy: 0.9668 - val_acc: 0.8025\n",
      "Epoch 2372/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0338 - binary_accuracy: 0.9804 - acc: 0.7716 - val_loss: 0.0539 - val_binary_accuracy: 0.9685 - val_acc: 0.7678\n",
      "Epoch 2373/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7880 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.7497\n",
      "Epoch 2374/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7720 - val_loss: 0.0525 - val_binary_accuracy: 0.9695 - val_acc: 0.7841\n",
      "Epoch 2375/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7961 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7808\n",
      "Epoch 2376/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7986 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7747\n",
      "Epoch 2377/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7985 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7729\n",
      "Epoch 2378/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7969 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7722\n",
      "Epoch 2379/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7962 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7700\n",
      "Epoch 2380/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7940 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7664\n",
      "Epoch 2381/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7935 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7653\n",
      "Epoch 2382/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7926 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7653\n",
      "Epoch 2383/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7924 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7646\n",
      "Epoch 2384/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7925 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7635\n",
      "Epoch 2385/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7926 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7638\n",
      "Epoch 2386/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7925 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7642\n",
      "Epoch 2387/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7924 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7656\n",
      "Epoch 2388/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7922 - val_loss: 0.0514 - val_binary_accuracy: 0.9701 - val_acc: 0.7660\n",
      "Epoch 2389/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7922 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7664\n",
      "Epoch 2390/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7871 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7613\n",
      "Epoch 2391/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7858 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7646\n",
      "Epoch 2392/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7879 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7646\n",
      "Epoch 2393/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7878 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7609\n",
      "Epoch 2394/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7859 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7642\n",
      "Epoch 2395/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7871 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7667\n",
      "Epoch 2396/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7855 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7515\n",
      "Epoch 2397/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7900 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7707\n",
      "Epoch 2398/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9811 - acc: 0.7977 - val_loss: 0.0528 - val_binary_accuracy: 0.9689 - val_acc: 0.7761\n",
      "Epoch 2399/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.7713 - val_loss: 0.0534 - val_binary_accuracy: 0.9688 - val_acc: 0.7656\n",
      "Epoch 2400/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7859 - val_loss: 0.0528 - val_binary_accuracy: 0.9690 - val_acc: 0.7675\n",
      "Epoch 2401/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7939 - val_loss: 0.0527 - val_binary_accuracy: 0.9693 - val_acc: 0.7251\n",
      "Epoch 2402/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9811 - acc: 0.7743 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7458\n",
      "Epoch 2403/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7829 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7530\n",
      "Epoch 2404/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7818 - val_loss: 0.0514 - val_binary_accuracy: 0.9701 - val_acc: 0.7606\n",
      "Epoch 2405/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7924 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7562\n",
      "Epoch 2406/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7871 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7602\n",
      "Epoch 2407/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7905 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7609\n",
      "Epoch 2408/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7878 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7573\n",
      "Epoch 2409/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7880 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7580\n",
      "Epoch 2410/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7878 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7602\n",
      "Epoch 2411/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7878 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7613\n",
      "Epoch 2412/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7892 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7602\n",
      "Epoch 2413/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7905 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7613\n",
      "Epoch 2414/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7910 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7620\n",
      "Epoch 2415/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7918 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7620\n",
      "Epoch 2416/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7916 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7624\n",
      "Epoch 2417/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7919 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7627\n",
      "Epoch 2418/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7931 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7620\n",
      "Epoch 2419/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7907 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7678\n",
      "Epoch 2420/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7945 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7675\n",
      "Epoch 2421/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7931 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7714\n",
      "Epoch 2422/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.8048 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7732\n",
      "Epoch 2423/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.8005 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7747\n",
      "Epoch 2424/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7973 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7714\n",
      "Epoch 2425/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7950 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7685\n",
      "Epoch 2426/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7922 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7664\n",
      "Epoch 2427/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7957 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7664\n",
      "Epoch 2428/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7938 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7664\n",
      "Epoch 2429/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7939 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7667\n",
      "Epoch 2430/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7946 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7689\n",
      "Epoch 2431/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7956 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7682\n",
      "Epoch 2432/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7961 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7682\n",
      "Epoch 2433/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7959 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7678\n",
      "Epoch 2434/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7965 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7682\n",
      "Epoch 2435/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7963 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7689\n",
      "Epoch 2436/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7969 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7693\n",
      "Epoch 2437/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7975 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7703\n",
      "Epoch 2438/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7975 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7718\n",
      "Epoch 2439/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7979 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 2440/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7987 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7722\n",
      "Epoch 2441/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7982 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7718\n",
      "Epoch 2442/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7988 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7718\n",
      "Epoch 2443/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7991 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7725\n",
      "Epoch 2444/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7997 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7722\n",
      "Epoch 2445/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8001 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7718\n",
      "Epoch 2446/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7989 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7732\n",
      "Epoch 2447/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8004 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7729\n",
      "Epoch 2448/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8022 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7736\n",
      "Epoch 2449/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8025 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7736\n",
      "Epoch 2450/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8028 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2451/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8030 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2452/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8025 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2453/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8033 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7747\n",
      "Epoch 2454/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8034 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7750\n",
      "Epoch 2455/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8036 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2456/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8037 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2457/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8036 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7747\n",
      "Epoch 2458/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8051 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7754\n",
      "Epoch 2459/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0328 - binary_accuracy: 0.9809 - acc: 0.8010 - val_loss: 0.0559 - val_binary_accuracy: 0.9673 - val_acc: 0.7367\n",
      "Epoch 2460/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0330 - binary_accuracy: 0.9808 - acc: 0.7950 - val_loss: 0.0522 - val_binary_accuracy: 0.9697 - val_acc: 0.7584\n",
      "Epoch 2461/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7943 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.7476\n",
      "Epoch 2462/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.8074 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7447\n",
      "Epoch 2463/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7880 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7646\n",
      "Epoch 2464/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7914 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7526\n",
      "Epoch 2465/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7934 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7602\n",
      "Epoch 2466/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.7999 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7620\n",
      "Epoch 2467/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8009 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7642\n",
      "Epoch 2468/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8007 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7635\n",
      "Epoch 2469/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8010 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7646\n",
      "Epoch 2470/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8014 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7667\n",
      "Epoch 2471/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8051 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7743\n",
      "Epoch 2472/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8032 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7714\n",
      "Epoch 2473/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8026 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7696\n",
      "Epoch 2474/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8008 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7671\n",
      "Epoch 2475/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8007 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7667\n",
      "Epoch 2476/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8005 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7671\n",
      "Epoch 2477/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8012 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7667\n",
      "Epoch 2478/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8004 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7671\n",
      "Epoch 2479/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8010 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7671\n",
      "Epoch 2480/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8007 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7671\n",
      "Epoch 2481/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8003 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7678\n",
      "Epoch 2482/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8003 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7667\n",
      "Epoch 2483/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8002 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7678\n",
      "Epoch 2484/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8005 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7675\n",
      "Epoch 2485/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8003 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7675\n",
      "Epoch 2486/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8004 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7682\n",
      "Epoch 2487/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8008 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7689\n",
      "Epoch 2488/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8009 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7693\n",
      "Epoch 2489/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8012 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7689\n",
      "Epoch 2490/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8014 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7696\n",
      "Epoch 2491/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8020 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7700\n",
      "Epoch 2492/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8019 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7700\n",
      "Epoch 2493/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8021 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7700\n",
      "Epoch 2494/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8020 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7696\n",
      "Epoch 2495/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8021 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7707\n",
      "Epoch 2496/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8023 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7714\n",
      "Epoch 2497/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8023 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7714\n",
      "Epoch 2498/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8062 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7787\n",
      "Epoch 2499/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8010 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7707\n",
      "Epoch 2500/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8040 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7711\n",
      "Epoch 2501/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8021 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7689\n",
      "Epoch 2502/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8017 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7696\n",
      "Epoch 2503/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9811 - acc: 0.8062 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7541\n",
      "Epoch 2504/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7898 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7664\n",
      "Epoch 2505/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8027 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7689\n",
      "Epoch 2506/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7989 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7696\n",
      "Epoch 2507/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8001 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7714\n",
      "Epoch 2508/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8019 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7725\n",
      "Epoch 2509/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8010 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7714\n",
      "Epoch 2510/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8021 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7707\n",
      "Epoch 2511/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8032 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7729\n",
      "Epoch 2512/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8038 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7732\n",
      "Epoch 2513/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8039 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7743\n",
      "Epoch 2514/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8040 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7754\n",
      "Epoch 2515/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8044 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7761\n",
      "Epoch 2516/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8053 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7765\n",
      "Epoch 2517/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8053 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7783\n",
      "Epoch 2518/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8060 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7783\n",
      "Epoch 2519/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8070 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7779\n",
      "Epoch 2520/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8066 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7779\n",
      "Epoch 2521/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8069 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7790\n",
      "Epoch 2522/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8077 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 2523/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8074 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7797\n",
      "Epoch 2524/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8075 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7794\n",
      "Epoch 2525/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8078 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7808\n",
      "Epoch 2526/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8077 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7812\n",
      "Epoch 2527/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8084 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7816\n",
      "Epoch 2528/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8079 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7816\n",
      "Epoch 2529/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8093 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7819\n",
      "Epoch 2530/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8094 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7819\n",
      "Epoch 2531/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8101 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7826\n",
      "Epoch 2532/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8094 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7826\n",
      "Epoch 2533/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8107 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7826\n",
      "Epoch 2534/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8103 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7826\n",
      "Epoch 2535/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8104 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7823\n",
      "Epoch 2536/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8115 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7826\n",
      "Epoch 2537/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8110 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7826\n",
      "Epoch 2538/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8124 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7834\n",
      "Epoch 2539/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8123 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7834\n",
      "Epoch 2540/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8126 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7834\n",
      "Epoch 2541/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8125 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7841\n",
      "Epoch 2542/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8130 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7844\n",
      "Epoch 2543/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8130 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7844\n",
      "Epoch 2544/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8134 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7844\n",
      "Epoch 2545/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8139 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7848\n",
      "Epoch 2546/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8139 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7848\n",
      "Epoch 2547/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8143 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7855\n",
      "Epoch 2548/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8148 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7859\n",
      "Epoch 2549/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8152 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7863\n",
      "Epoch 2550/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8154 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7870\n",
      "Epoch 2551/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8154 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7870\n",
      "Epoch 2552/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8164 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7870\n",
      "Epoch 2553/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8167 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7870\n",
      "Epoch 2554/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8160 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7870\n",
      "Epoch 2555/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8163 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7877\n",
      "Epoch 2556/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8171 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7877\n",
      "Epoch 2557/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8183 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7873\n",
      "Epoch 2558/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8176 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7877\n",
      "Epoch 2559/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8185 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7881\n",
      "Epoch 2560/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8187 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7881\n",
      "Epoch 2561/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8187 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7892\n",
      "Epoch 2562/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8198 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7895\n",
      "Epoch 2563/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.8231 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7899\n",
      "Epoch 2564/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9806 - acc: 0.8010 - val_loss: 0.0549 - val_binary_accuracy: 0.9678 - val_acc: 0.7635\n",
      "Epoch 2565/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9808 - acc: 0.7879 - val_loss: 0.0532 - val_binary_accuracy: 0.9690 - val_acc: 0.7447\n",
      "Epoch 2566/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.7906 - val_loss: 0.0523 - val_binary_accuracy: 0.9697 - val_acc: 0.7910\n",
      "Epoch 2567/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0325 - binary_accuracy: 0.9811 - acc: 0.8026 - val_loss: 0.0519 - val_binary_accuracy: 0.9694 - val_acc: 0.7624\n",
      "Epoch 2568/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7962 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7537\n",
      "Epoch 2569/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7933 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7631\n",
      "Epoch 2570/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7952 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7620\n",
      "Epoch 2571/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7933 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7599\n",
      "Epoch 2572/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7942 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7656\n",
      "Epoch 2573/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7978 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7667\n",
      "Epoch 2574/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7989 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7664\n",
      "Epoch 2575/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7990 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7660\n",
      "Epoch 2576/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7994 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7656\n",
      "Epoch 2577/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7997 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7660\n",
      "Epoch 2578/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7999 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7675\n",
      "Epoch 2579/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7996 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7656\n",
      "Epoch 2580/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7984 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7638\n",
      "Epoch 2581/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7976 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7533\n",
      "Epoch 2582/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7911 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7584\n",
      "Epoch 2583/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7957 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7613\n",
      "Epoch 2584/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7972 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7642\n",
      "Epoch 2585/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7989 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7653\n",
      "Epoch 2586/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7995 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7656\n",
      "Epoch 2587/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8011 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7664\n",
      "Epoch 2588/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8007 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7660\n",
      "Epoch 2589/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8008 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7667\n",
      "Epoch 2590/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8014 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7675\n",
      "Epoch 2591/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8012 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7682\n",
      "Epoch 2592/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8017 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7689\n",
      "Epoch 2593/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8012 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7685\n",
      "Epoch 2594/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8021 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7693\n",
      "Epoch 2595/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8020 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7689\n",
      "Epoch 2596/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8019 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7696\n",
      "Epoch 2597/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8024 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7700\n",
      "Epoch 2598/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8023 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7696\n",
      "Epoch 2599/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8025 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7711\n",
      "Epoch 2600/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8030 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7729\n",
      "Epoch 2601/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8028 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7729\n",
      "Epoch 2602/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8033 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7725\n",
      "Epoch 2603/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8027 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7722\n",
      "Epoch 2604/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8046 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7740\n",
      "Epoch 2605/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8037 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7732\n",
      "Epoch 2606/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8039 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2607/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8044 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2608/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8047 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7736\n",
      "Epoch 2609/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8046 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7740\n",
      "Epoch 2610/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8046 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7750\n",
      "Epoch 2611/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8049 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7758\n",
      "Epoch 2612/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8058 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7754\n",
      "Epoch 2613/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8053 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7750\n",
      "Epoch 2614/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8051 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7750\n",
      "Epoch 2615/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8056 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7747\n",
      "Epoch 2616/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8048 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7729\n",
      "Epoch 2617/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7998 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7627\n",
      "Epoch 2618/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7975 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 2619/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8054 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7743\n",
      "Epoch 2620/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8072 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7747\n",
      "Epoch 2621/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8079 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7758\n",
      "Epoch 2622/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8076 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7758\n",
      "Epoch 2623/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8083 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7754\n",
      "Epoch 2624/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8081 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7765\n",
      "Epoch 2625/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8085 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7765\n",
      "Epoch 2626/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8088 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7765\n",
      "Epoch 2627/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8086 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7772\n",
      "Epoch 2628/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8095 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7776\n",
      "Epoch 2629/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8093 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7790\n",
      "Epoch 2630/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8101 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7787\n",
      "Epoch 2631/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8060 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7761\n",
      "Epoch 2632/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8088 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 2633/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8107 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 2634/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8107 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7797\n",
      "Epoch 2635/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8097 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7797\n",
      "Epoch 2636/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8097 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7794\n",
      "Epoch 2637/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8057 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7714\n",
      "Epoch 2638/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7957 - val_loss: 0.0544 - val_binary_accuracy: 0.9683 - val_acc: 0.7689\n",
      "Epoch 2639/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0333 - binary_accuracy: 0.9807 - acc: 0.7830 - val_loss: 0.0538 - val_binary_accuracy: 0.9685 - val_acc: 0.7541\n",
      "Epoch 2640/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7792 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7320\n",
      "Epoch 2641/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7742 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7331\n",
      "Epoch 2642/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7744 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7660\n",
      "Epoch 2643/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7933 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7570\n",
      "Epoch 2644/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7892 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7570\n",
      "Epoch 2645/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7885 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7573\n",
      "Epoch 2646/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7894 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7591\n",
      "Epoch 2647/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7897 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7602\n",
      "Epoch 2648/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7909 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7606\n",
      "Epoch 2649/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7910 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7602\n",
      "Epoch 2650/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7924 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7595\n",
      "Epoch 2651/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7925 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7606\n",
      "Epoch 2652/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7935 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7602\n",
      "Epoch 2653/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7931 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7599\n",
      "Epoch 2654/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7942 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7599\n",
      "Epoch 2655/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7945 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7602\n",
      "Epoch 2656/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7950 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7606\n",
      "Epoch 2657/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7966 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7620\n",
      "Epoch 2658/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7922 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7552\n",
      "Epoch 2659/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7971 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7599\n",
      "Epoch 2660/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7949 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7620\n",
      "Epoch 2661/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7963 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7635\n",
      "Epoch 2662/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7967 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7642\n",
      "Epoch 2663/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7973 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7660\n",
      "Epoch 2664/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7970 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7696\n",
      "Epoch 2665/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8023 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7642\n",
      "Epoch 2666/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7974 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7638\n",
      "Epoch 2667/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7994 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7642\n",
      "Epoch 2668/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7999 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7696\n",
      "Epoch 2669/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7908 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7335\n",
      "Epoch 2670/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8067 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7548\n",
      "Epoch 2671/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7749 - val_loss: 0.0543 - val_binary_accuracy: 0.9682 - val_acc: 0.7360\n",
      "Epoch 2672/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9811 - acc: 0.7827 - val_loss: 0.0526 - val_binary_accuracy: 0.9693 - val_acc: 0.7154\n",
      "Epoch 2673/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7684 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7439\n",
      "Epoch 2674/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7931 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7591\n",
      "Epoch 2675/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7862 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.6738\n",
      "Epoch 2676/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7817 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7552\n",
      "Epoch 2677/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7883 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7544\n",
      "Epoch 2678/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7877 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7544\n",
      "Epoch 2679/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7894 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7570\n",
      "Epoch 2680/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7901 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7573\n",
      "Epoch 2681/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7922 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7580\n",
      "Epoch 2682/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7931 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7591\n",
      "Epoch 2683/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7932 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7591\n",
      "Epoch 2684/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7943 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7599\n",
      "Epoch 2685/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7948 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7609\n",
      "Epoch 2686/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7947 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7606\n",
      "Epoch 2687/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7953 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7620\n",
      "Epoch 2688/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7958 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7613\n",
      "Epoch 2689/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7966 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7609\n",
      "Epoch 2690/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7963 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7606\n",
      "Epoch 2691/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7970 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7617\n",
      "Epoch 2692/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7969 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7613\n",
      "Epoch 2693/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7978 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7624\n",
      "Epoch 2694/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7980 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7646\n",
      "Epoch 2695/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7982 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7646\n",
      "Epoch 2696/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7989 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7664\n",
      "Epoch 2697/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7994 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7656\n",
      "Epoch 2698/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7993 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7660\n",
      "Epoch 2699/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8000 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7660\n",
      "Epoch 2700/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8010 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7664\n",
      "Epoch 2701/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8012 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7671\n",
      "Epoch 2702/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8017 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7682\n",
      "Epoch 2703/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8020 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7678\n",
      "Epoch 2704/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8021 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7678\n",
      "Epoch 2705/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8021 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7685\n",
      "Epoch 2706/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8030 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7685\n",
      "Epoch 2707/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8029 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7696\n",
      "Epoch 2708/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8033 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7696\n",
      "Epoch 2709/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8042 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7696\n",
      "Epoch 2710/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8042 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7703\n",
      "Epoch 2711/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8051 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 2712/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8051 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 2713/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8053 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 2714/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8061 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7714\n",
      "Epoch 2715/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8060 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7722\n",
      "Epoch 2716/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8064 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7718\n",
      "Epoch 2717/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8070 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 2718/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8075 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 2719/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8072 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 2720/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8078 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7729\n",
      "Epoch 2721/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8081 - val_loss: 0.0507 - val_binary_accuracy: 0.9706 - val_acc: 0.7725\n",
      "Epoch 2722/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8073 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7732\n",
      "Epoch 2723/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9812 - acc: 0.8081 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7722\n",
      "Epoch 2724/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0329 - binary_accuracy: 0.9808 - acc: 0.8056 - val_loss: 0.0545 - val_binary_accuracy: 0.9679 - val_acc: 0.7783\n",
      "Epoch 2725/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7729 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7107\n",
      "Epoch 2726/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7913 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7700\n",
      "Epoch 2727/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.7689 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7378\n",
      "Epoch 2728/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7725 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7476\n",
      "Epoch 2729/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7749 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7454\n",
      "Epoch 2730/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7809 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7552\n",
      "Epoch 2731/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7827 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7566\n",
      "Epoch 2732/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7840 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7566\n",
      "Epoch 2733/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7859 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7573\n",
      "Epoch 2734/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7875 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7577\n",
      "Epoch 2735/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7874 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7573\n",
      "Epoch 2736/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7880 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7584\n",
      "Epoch 2737/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7883 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7599\n",
      "Epoch 2738/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7892 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7613\n",
      "Epoch 2739/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7897 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7627\n",
      "Epoch 2740/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7912 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7642\n",
      "Epoch 2741/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7913 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7649\n",
      "Epoch 2742/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7918 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7653\n",
      "Epoch 2743/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7923 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7656\n",
      "Epoch 2744/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7931 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7653\n",
      "Epoch 2745/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7931 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7660\n",
      "Epoch 2746/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7946 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7664\n",
      "Epoch 2747/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7943 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7664\n",
      "Epoch 2748/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7949 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7667\n",
      "Epoch 2749/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7947 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7675\n",
      "Epoch 2750/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7954 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7678\n",
      "Epoch 2751/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7954 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7675\n",
      "Epoch 2752/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7959 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7667\n",
      "Epoch 2753/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7959 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7678\n",
      "Epoch 2754/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7970 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7667\n",
      "Epoch 2755/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7968 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7664\n",
      "Epoch 2756/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7975 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7664\n",
      "Epoch 2757/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7978 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7667\n",
      "Epoch 2758/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7977 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7671\n",
      "Epoch 2759/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7986 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7675\n",
      "Epoch 2760/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7987 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7675\n",
      "Epoch 2761/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7996 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7678\n",
      "Epoch 2762/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7986 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7682\n",
      "Epoch 2763/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7994 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7685\n",
      "Epoch 2764/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8000 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7682\n",
      "Epoch 2765/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8005 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7685\n",
      "Epoch 2766/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8009 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7689\n",
      "Epoch 2767/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8016 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7689\n",
      "Epoch 2768/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8027 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7696\n",
      "Epoch 2769/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8025 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7689\n",
      "Epoch 2770/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8028 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7689\n",
      "Epoch 2771/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8037 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7696\n",
      "Epoch 2772/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8028 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7682\n",
      "Epoch 2773/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8040 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7685\n",
      "Epoch 2774/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8037 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7696\n",
      "Epoch 2775/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8040 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7696\n",
      "Epoch 2776/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8051 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7714\n",
      "Epoch 2777/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8057 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7707\n",
      "Epoch 2778/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8051 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7711\n",
      "Epoch 2779/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8054 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7714\n",
      "Epoch 2780/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8055 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7722\n",
      "Epoch 2781/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8054 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 2782/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8072 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 2783/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8076 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7732\n",
      "Epoch 2784/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8069 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 2785/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8077 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7736\n",
      "Epoch 2786/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8086 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7736\n",
      "Epoch 2787/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8085 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7747\n",
      "Epoch 2788/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8090 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7758\n",
      "Epoch 2789/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8097 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7765\n",
      "Epoch 2790/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8100 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7779\n",
      "Epoch 2791/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8101 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7805\n",
      "Epoch 2792/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8109 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7772\n",
      "Epoch 2793/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0331 - binary_accuracy: 0.9807 - acc: 0.7881 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.7613\n",
      "Epoch 2794/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7906 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.7805\n",
      "Epoch 2795/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8065 - val_loss: 0.0522 - val_binary_accuracy: 0.9692 - val_acc: 0.7548\n",
      "Epoch 2796/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8044 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7844\n",
      "Epoch 2797/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8082 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7816\n",
      "Epoch 2798/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8019 - val_loss: 0.0517 - val_binary_accuracy: 0.9699 - val_acc: 0.7729\n",
      "Epoch 2799/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8063 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7797\n",
      "Epoch 2800/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8049 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7769\n",
      "Epoch 2801/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8040 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 2802/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8044 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7743\n",
      "Epoch 2803/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8028 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7754\n",
      "Epoch 2804/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8032 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7765\n",
      "Epoch 2805/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8033 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 2806/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8028 - val_loss: 0.0512 - val_binary_accuracy: 0.9698 - val_acc: 0.7761\n",
      "Epoch 2807/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8038 - val_loss: 0.0512 - val_binary_accuracy: 0.9698 - val_acc: 0.7758\n",
      "Epoch 2808/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8040 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7758\n",
      "Epoch 2809/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8046 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7765\n",
      "Epoch 2810/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8047 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7769\n",
      "Epoch 2811/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8049 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7769\n",
      "Epoch 2812/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8054 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7772\n",
      "Epoch 2813/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8056 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7776\n",
      "Epoch 2814/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8056 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7772\n",
      "Epoch 2815/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8058 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7776\n",
      "Epoch 2816/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8065 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 2817/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8068 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 2818/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8070 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 2819/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8073 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7765\n",
      "Epoch 2820/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8076 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 2821/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8078 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7769\n",
      "Epoch 2822/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8078 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7779\n",
      "Epoch 2823/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8082 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 2824/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8084 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 2825/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8092 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 2826/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8093 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7783\n",
      "Epoch 2827/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8090 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 2828/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8092 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7794\n",
      "Epoch 2829/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8098 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7801\n",
      "Epoch 2830/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8099 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 2831/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8100 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7794\n",
      "Epoch 2832/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8102 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7794\n",
      "Epoch 2833/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8105 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7797\n",
      "Epoch 2834/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8113 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7812\n",
      "Epoch 2835/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8111 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 2836/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8114 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7808\n",
      "Epoch 2837/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8118 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7826\n",
      "Epoch 2838/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8116 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7834\n",
      "Epoch 2839/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8123 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7830\n",
      "Epoch 2840/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8122 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7837\n",
      "Epoch 2841/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8118 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7834\n",
      "Epoch 2842/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8121 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7834\n",
      "Epoch 2843/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8130 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7837\n",
      "Epoch 2844/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8130 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7848\n",
      "Epoch 2845/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8134 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7841\n",
      "Epoch 2846/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8137 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7844\n",
      "Epoch 2847/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8141 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7852\n",
      "Epoch 2848/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8143 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7844\n",
      "Epoch 2849/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8143 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7844\n",
      "Epoch 2850/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8149 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7855\n",
      "Epoch 2851/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8153 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7866\n",
      "Epoch 2852/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8153 - val_loss: 0.0521 - val_binary_accuracy: 0.9693 - val_acc: 0.7450\n",
      "Epoch 2853/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9810 - acc: 0.7947 - val_loss: 0.0536 - val_binary_accuracy: 0.9687 - val_acc: 0.7797\n",
      "Epoch 2854/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9811 - acc: 0.7916 - val_loss: 0.0525 - val_binary_accuracy: 0.9694 - val_acc: 0.7139\n",
      "Epoch 2855/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7815 - val_loss: 0.0525 - val_binary_accuracy: 0.9693 - val_acc: 0.7490\n",
      "Epoch 2856/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7941 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7599\n",
      "Epoch 2857/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8042 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7892\n",
      "Epoch 2858/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8145 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7863\n",
      "Epoch 2859/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8147 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7826\n",
      "Epoch 2860/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8116 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7830\n",
      "Epoch 2861/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8111 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7823\n",
      "Epoch 2862/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8107 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 2863/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8113 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7826\n",
      "Epoch 2864/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8129 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7823\n",
      "Epoch 2865/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8122 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 2866/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8118 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7823\n",
      "Epoch 2867/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8122 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7830\n",
      "Epoch 2868/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8116 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7823\n",
      "Epoch 2869/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8121 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7816\n",
      "Epoch 2870/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8136 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7794\n",
      "Epoch 2871/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8054 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7765\n",
      "Epoch 2872/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8114 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7848\n",
      "Epoch 2873/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8125 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 2874/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8122 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7801\n",
      "Epoch 2875/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8121 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7812\n",
      "Epoch 2876/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8121 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7823\n",
      "Epoch 2877/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8125 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7837\n",
      "Epoch 2878/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8134 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7826\n",
      "Epoch 2879/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8132 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7830\n",
      "Epoch 2880/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8134 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7830\n",
      "Epoch 2881/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8136 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7863\n",
      "Epoch 2882/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8142 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7855\n",
      "Epoch 2883/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8145 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7852\n",
      "Epoch 2884/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8148 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7852\n",
      "Epoch 2885/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8148 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7848\n",
      "Epoch 2886/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8150 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7855\n",
      "Epoch 2887/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8161 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7855\n",
      "Epoch 2888/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8163 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7859\n",
      "Epoch 2889/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8169 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7863\n",
      "Epoch 2890/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8164 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7870\n",
      "Epoch 2891/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8170 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7877\n",
      "Epoch 2892/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8174 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7877\n",
      "Epoch 2893/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8179 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7888\n",
      "Epoch 2894/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8171 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7892\n",
      "Epoch 2895/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8180 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7895\n",
      "Epoch 2896/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8177 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7899\n",
      "Epoch 2897/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8185 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7899\n",
      "Epoch 2898/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8188 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7906\n",
      "Epoch 2899/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8193 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7910\n",
      "Epoch 2900/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8194 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7910\n",
      "Epoch 2901/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8194 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7910\n",
      "Epoch 2902/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8184 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7884\n",
      "Epoch 2903/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8180 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7892\n",
      "Epoch 2904/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8183 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7892\n",
      "Epoch 2905/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8194 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7910\n",
      "Epoch 2906/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8192 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7913\n",
      "Epoch 2907/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8206 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7917\n",
      "Epoch 2908/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8210 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7913\n",
      "Epoch 2909/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8205 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7917\n",
      "Epoch 2910/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8213 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7928\n",
      "Epoch 2911/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8210 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7931\n",
      "Epoch 2912/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8209 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7939\n",
      "Epoch 2913/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8221 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7949\n",
      "Epoch 2914/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8226 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2915/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8227 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7949\n",
      "Epoch 2916/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8224 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7942\n",
      "Epoch 2917/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8229 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7949\n",
      "Epoch 2918/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8238 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2919/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8238 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7949\n",
      "Epoch 2920/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8238 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7942\n",
      "Epoch 2921/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8240 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2922/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8246 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7953\n",
      "Epoch 2923/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8244 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2924/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8252 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2925/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8250 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2926/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8256 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2927/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8252 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7953\n",
      "Epoch 2928/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8257 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7960\n",
      "Epoch 2929/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8260 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7960\n",
      "Epoch 2930/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8252 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7964\n",
      "Epoch 2931/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8261 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7964\n",
      "Epoch 2932/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8265 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7960\n",
      "Epoch 2933/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8263 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7975\n",
      "Epoch 2934/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8272 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7975\n",
      "Epoch 2935/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8268 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7975\n",
      "Epoch 2936/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8266 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7975\n",
      "Epoch 2937/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8274 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7975\n",
      "Epoch 2938/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8265 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7975\n",
      "Epoch 2939/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8236 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7939\n",
      "Epoch 2940/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8164 - val_loss: 0.0546 - val_binary_accuracy: 0.9682 - val_acc: 0.7215\n",
      "Epoch 2941/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0327 - binary_accuracy: 0.9810 - acc: 0.7960 - val_loss: 0.0537 - val_binary_accuracy: 0.9684 - val_acc: 0.7808\n",
      "Epoch 2942/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9813 - acc: 0.7966 - val_loss: 0.0528 - val_binary_accuracy: 0.9690 - val_acc: 0.7808\n",
      "Epoch 2943/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.7942 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7722\n",
      "Epoch 2944/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.7975 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7635\n",
      "Epoch 2945/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.7955 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7638\n",
      "Epoch 2946/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.7974 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7682\n",
      "Epoch 2947/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8000 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7700\n",
      "Epoch 2948/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8020 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7714\n",
      "Epoch 2949/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8028 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7732\n",
      "Epoch 2950/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8026 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7743\n",
      "Epoch 2951/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8038 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7754\n",
      "Epoch 2952/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8039 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7696\n",
      "Epoch 2953/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.7998 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7667\n",
      "Epoch 2954/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8050 - val_loss: 0.0516 - val_binary_accuracy: 0.9700 - val_acc: 0.7848\n",
      "Epoch 2955/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8060 - val_loss: 0.0515 - val_binary_accuracy: 0.9697 - val_acc: 0.7429\n",
      "Epoch 2956/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.7928 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7750\n",
      "Epoch 2957/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8068 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7790\n",
      "Epoch 2958/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8065 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7790\n",
      "Epoch 2959/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8072 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7805\n",
      "Epoch 2960/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8079 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7805\n",
      "Epoch 2961/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8074 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7797\n",
      "Epoch 2962/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8074 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7808\n",
      "Epoch 2963/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8077 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7808\n",
      "Epoch 2964/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8074 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7808\n",
      "Epoch 2965/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8088 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7812\n",
      "Epoch 2966/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8090 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7805\n",
      "Epoch 2967/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8090 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7808\n",
      "Epoch 2968/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8094 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7816\n",
      "Epoch 2969/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8090 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7823\n",
      "Epoch 2970/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8092 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7819\n",
      "Epoch 2971/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8092 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7819\n",
      "Epoch 2972/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8101 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7823\n",
      "Epoch 2973/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8102 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7826\n",
      "Epoch 2974/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8102 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7819\n",
      "Epoch 2975/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8104 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7819\n",
      "Epoch 2976/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8112 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7830\n",
      "Epoch 2977/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8107 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7823\n",
      "Epoch 2978/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8111 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7823\n",
      "Epoch 2979/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8116 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7830\n",
      "Epoch 2980/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8113 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7826\n",
      "Epoch 2981/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8117 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7826\n",
      "Epoch 2982/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8120 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7834\n",
      "Epoch 2983/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8123 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7834\n",
      "Epoch 2984/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8124 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7830\n",
      "Epoch 2985/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8125 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7830\n",
      "Epoch 2986/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8127 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7841\n",
      "Epoch 2987/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8133 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7844\n",
      "Epoch 2988/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8135 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7844\n",
      "Epoch 2989/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8132 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7844\n",
      "Epoch 2990/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8131 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7841\n",
      "Epoch 2991/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8136 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7852\n",
      "Epoch 2992/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8139 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7855\n",
      "Epoch 2993/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8141 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7863\n",
      "Epoch 2994/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8141 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7866\n",
      "Epoch 2995/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8148 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7870\n",
      "Epoch 2996/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8162 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7870\n",
      "Epoch 2997/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8126 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7714\n",
      "Epoch 2998/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.8234 - val_loss: 0.0548 - val_binary_accuracy: 0.9678 - val_acc: 0.7631\n",
      "Epoch 2999/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0328 - binary_accuracy: 0.9810 - acc: 0.7936 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7552\n",
      "Epoch 3000/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7982 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7685\n",
      "Epoch 3001/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8049 - val_loss: 0.0518 - val_binary_accuracy: 0.9693 - val_acc: 0.7635\n",
      "Epoch 3002/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.7940 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7693\n",
      "Epoch 3003/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8032 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7624\n",
      "Epoch 3004/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.7997 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7635\n",
      "Epoch 3005/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8032 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7667\n",
      "Epoch 3006/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8044 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7714\n",
      "Epoch 3007/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8051 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7718\n",
      "Epoch 3008/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8060 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7729\n",
      "Epoch 3009/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8070 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7732\n",
      "Epoch 3010/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8077 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7736\n",
      "Epoch 3011/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8076 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7740\n",
      "Epoch 3012/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8087 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7758\n",
      "Epoch 3013/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8087 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7758\n",
      "Epoch 3014/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8088 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7743\n",
      "Epoch 3015/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8095 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7754\n",
      "Epoch 3016/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8098 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7747\n",
      "Epoch 3017/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8103 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7743\n",
      "Epoch 3018/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8107 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7747\n",
      "Epoch 3019/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8110 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7758\n",
      "Epoch 3020/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8115 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7758\n",
      "Epoch 3021/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8113 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7758\n",
      "Epoch 3022/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8122 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7758\n",
      "Epoch 3023/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8123 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7761\n",
      "Epoch 3024/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8128 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7765\n",
      "Epoch 3025/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8132 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7779\n",
      "Epoch 3026/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8129 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7783\n",
      "Epoch 3027/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8132 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7797\n",
      "Epoch 3028/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8142 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7812\n",
      "Epoch 3029/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8146 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7808\n",
      "Epoch 3030/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8146 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 3031/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8150 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7808\n",
      "Epoch 3032/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8150 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7805\n",
      "Epoch 3033/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8146 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7805\n",
      "Epoch 3034/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8146 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7801\n",
      "Epoch 3035/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8150 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7805\n",
      "Epoch 3036/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8150 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7816\n",
      "Epoch 3037/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8158 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7819\n",
      "Epoch 3038/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8159 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7812\n",
      "Epoch 3039/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8160 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7819\n",
      "Epoch 3040/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8168 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7826\n",
      "Epoch 3041/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8169 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7834\n",
      "Epoch 3042/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8175 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7837\n",
      "Epoch 3043/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8190 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7841\n",
      "Epoch 3044/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8186 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7754\n",
      "Epoch 3045/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0326 - binary_accuracy: 0.9810 - acc: 0.8021 - val_loss: 0.0546 - val_binary_accuracy: 0.9681 - val_acc: 0.7877\n",
      "Epoch 3046/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7983 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7892\n",
      "Epoch 3047/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.8302 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7823\n",
      "Epoch 3048/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8221 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7967\n",
      "Epoch 3049/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8228 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7801\n",
      "Epoch 3050/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8148 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7772\n",
      "Epoch 3051/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8129 - val_loss: 0.0514 - val_binary_accuracy: 0.9701 - val_acc: 0.7761\n",
      "Epoch 3052/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8102 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7722\n",
      "Epoch 3053/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8103 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7729\n",
      "Epoch 3054/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8115 - val_loss: 0.0512 - val_binary_accuracy: 0.9703 - val_acc: 0.7740\n",
      "Epoch 3055/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8115 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7732\n",
      "Epoch 3056/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8123 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7736\n",
      "Epoch 3057/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.7950 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7497\n",
      "Epoch 3058/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8009 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7696\n",
      "Epoch 3059/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8037 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7714\n",
      "Epoch 3060/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8002 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7982\n",
      "Epoch 3061/4000\n",
      "15667/15667 [==============================] - 0s 19us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.7968 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7819\n",
      "Epoch 3062/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8044 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7685\n",
      "Epoch 3063/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8002 - val_loss: 0.0514 - val_binary_accuracy: 0.9702 - val_acc: 0.7671\n",
      "Epoch 3064/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.7955 - val_loss: 0.0514 - val_binary_accuracy: 0.9703 - val_acc: 0.7675\n",
      "Epoch 3065/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8025 - val_loss: 0.0513 - val_binary_accuracy: 0.9702 - val_acc: 0.7685\n",
      "Epoch 3066/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8037 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7689\n",
      "Epoch 3067/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8042 - val_loss: 0.0512 - val_binary_accuracy: 0.9703 - val_acc: 0.7700\n",
      "Epoch 3068/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8046 - val_loss: 0.0511 - val_binary_accuracy: 0.9703 - val_acc: 0.7703\n",
      "Epoch 3069/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8053 - val_loss: 0.0511 - val_binary_accuracy: 0.9703 - val_acc: 0.7703\n",
      "Epoch 3070/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8056 - val_loss: 0.0511 - val_binary_accuracy: 0.9703 - val_acc: 0.7707\n",
      "Epoch 3071/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8058 - val_loss: 0.0511 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 3072/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8070 - val_loss: 0.0510 - val_binary_accuracy: 0.9704 - val_acc: 0.7718\n",
      "Epoch 3073/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8070 - val_loss: 0.0510 - val_binary_accuracy: 0.9704 - val_acc: 0.7714\n",
      "Epoch 3074/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8072 - val_loss: 0.0510 - val_binary_accuracy: 0.9705 - val_acc: 0.7722\n",
      "Epoch 3075/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8083 - val_loss: 0.0510 - val_binary_accuracy: 0.9705 - val_acc: 0.7729\n",
      "Epoch 3076/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8080 - val_loss: 0.0509 - val_binary_accuracy: 0.9705 - val_acc: 0.7729\n",
      "Epoch 3077/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8081 - val_loss: 0.0509 - val_binary_accuracy: 0.9705 - val_acc: 0.7725\n",
      "Epoch 3078/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8092 - val_loss: 0.0509 - val_binary_accuracy: 0.9705 - val_acc: 0.7722\n",
      "Epoch 3079/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8090 - val_loss: 0.0509 - val_binary_accuracy: 0.9705 - val_acc: 0.7729\n",
      "Epoch 3080/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8099 - val_loss: 0.0509 - val_binary_accuracy: 0.9705 - val_acc: 0.7722\n",
      "Epoch 3081/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8100 - val_loss: 0.0509 - val_binary_accuracy: 0.9705 - val_acc: 0.7729\n",
      "Epoch 3082/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8105 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7732\n",
      "Epoch 3083/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8111 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7732\n",
      "Epoch 3084/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8107 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7732\n",
      "Epoch 3085/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8107 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7736\n",
      "Epoch 3086/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8111 - val_loss: 0.0510 - val_binary_accuracy: 0.9704 - val_acc: 0.7776\n",
      "Epoch 3087/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8146 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 3088/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8097 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7747\n",
      "Epoch 3089/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8106 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7765\n",
      "Epoch 3090/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8118 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7812\n",
      "Epoch 3091/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0321 - binary_accuracy: 0.9813 - acc: 0.7968 - val_loss: 0.0534 - val_binary_accuracy: 0.9689 - val_acc: 0.7902\n",
      "Epoch 3092/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0323 - binary_accuracy: 0.9812 - acc: 0.8090 - val_loss: 0.0546 - val_binary_accuracy: 0.9680 - val_acc: 0.7975\n",
      "Epoch 3093/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.7995 - val_loss: 0.0528 - val_binary_accuracy: 0.9691 - val_acc: 0.7743\n",
      "Epoch 3094/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8095 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7732\n",
      "Epoch 3095/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8136 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7740\n",
      "Epoch 3096/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8119 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7852\n",
      "Epoch 3097/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.8130 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7754\n",
      "Epoch 3098/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9815 - acc: 0.8097 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7707\n",
      "Epoch 3099/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9815 - acc: 0.8027 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7552\n",
      "Epoch 3100/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9815 - acc: 0.7964 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7638\n",
      "Epoch 3101/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9815 - acc: 0.8024 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7646\n",
      "Epoch 3102/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8034 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.7631\n",
      "Epoch 3103/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9815 - acc: 0.8041 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7635\n",
      "Epoch 3104/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8046 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7714\n",
      "Epoch 3105/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8090 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7758\n",
      "Epoch 3106/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8111 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7779\n",
      "Epoch 3107/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8151 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7808\n",
      "Epoch 3108/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8126 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7787\n",
      "Epoch 3109/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8104 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7801\n",
      "Epoch 3110/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8102 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7797\n",
      "Epoch 3111/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8173 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7776\n",
      "Epoch 3112/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8115 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7776\n",
      "Epoch 3113/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8096 - val_loss: 0.0514 - val_binary_accuracy: 0.9701 - val_acc: 0.7769\n",
      "Epoch 3114/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8095 - val_loss: 0.0514 - val_binary_accuracy: 0.9701 - val_acc: 0.7769\n",
      "Epoch 3115/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8097 - val_loss: 0.0514 - val_binary_accuracy: 0.9701 - val_acc: 0.7772\n",
      "Epoch 3116/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8102 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7761\n",
      "Epoch 3117/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8106 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7772\n",
      "Epoch 3118/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8106 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7776\n",
      "Epoch 3119/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8111 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7776\n",
      "Epoch 3120/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8119 - val_loss: 0.0513 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 3121/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8115 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7776\n",
      "Epoch 3122/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8124 - val_loss: 0.0513 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 3123/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8125 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 3124/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8129 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 3125/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8132 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 3126/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8130 - val_loss: 0.0512 - val_binary_accuracy: 0.9703 - val_acc: 0.7772\n",
      "Epoch 3127/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8134 - val_loss: 0.0512 - val_binary_accuracy: 0.9703 - val_acc: 0.7776\n",
      "Epoch 3128/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8130 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 3129/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8133 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 3130/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8139 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7772\n",
      "Epoch 3131/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8134 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7769\n",
      "Epoch 3132/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8134 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 3133/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8138 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7783\n",
      "Epoch 3134/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8141 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 3135/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8142 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7783\n",
      "Epoch 3136/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8140 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7790\n",
      "Epoch 3137/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8148 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7794\n",
      "Epoch 3138/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8145 - val_loss: 0.0511 - val_binary_accuracy: 0.9703 - val_acc: 0.7790\n",
      "Epoch 3139/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8140 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7805\n",
      "Epoch 3140/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8155 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7797\n",
      "Epoch 3141/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8151 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7794\n",
      "Epoch 3142/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8157 - val_loss: 0.0511 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 3143/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8144 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7790\n",
      "Epoch 3144/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8136 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7787\n",
      "Epoch 3145/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8133 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7790\n",
      "Epoch 3146/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8131 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7787\n",
      "Epoch 3147/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8135 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7797\n",
      "Epoch 3148/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8151 - val_loss: 0.0510 - val_binary_accuracy: 0.9704 - val_acc: 0.7819\n",
      "Epoch 3149/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8165 - val_loss: 0.0529 - val_binary_accuracy: 0.9693 - val_acc: 0.7649\n",
      "Epoch 3150/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0324 - binary_accuracy: 0.9812 - acc: 0.7927 - val_loss: 0.0548 - val_binary_accuracy: 0.9681 - val_acc: 0.7993\n",
      "Epoch 3151/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0322 - binary_accuracy: 0.9813 - acc: 0.7920 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7801\n",
      "Epoch 3152/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.7998 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.8018\n",
      "Epoch 3153/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8160 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 3154/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8136 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7841\n",
      "Epoch 3155/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8188 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7617\n",
      "Epoch 3156/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8017 - val_loss: 0.0512 - val_binary_accuracy: 0.9702 - val_acc: 0.7776\n",
      "Epoch 3157/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8095 - val_loss: 0.0511 - val_binary_accuracy: 0.9703 - val_acc: 0.7736\n",
      "Epoch 3158/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8088 - val_loss: 0.0510 - val_binary_accuracy: 0.9704 - val_acc: 0.7736\n",
      "Epoch 3159/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8077 - val_loss: 0.0510 - val_binary_accuracy: 0.9704 - val_acc: 0.7736\n",
      "Epoch 3160/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8076 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7740\n",
      "Epoch 3161/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8067 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7758\n",
      "Epoch 3162/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8076 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7761\n",
      "Epoch 3163/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8076 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7769\n",
      "Epoch 3164/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8076 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7765\n",
      "Epoch 3165/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8079 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7765\n",
      "Epoch 3166/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8084 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7765\n",
      "Epoch 3167/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8097 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7765\n",
      "Epoch 3168/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8120 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7797\n",
      "Epoch 3169/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8140 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7931\n",
      "Epoch 3170/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8129 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7754\n",
      "Epoch 3171/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8121 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.7472\n",
      "Epoch 3172/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9815 - acc: 0.8077 - val_loss: 0.0523 - val_binary_accuracy: 0.9693 - val_acc: 0.7664\n",
      "Epoch 3173/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.7990 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7675\n",
      "Epoch 3174/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9815 - acc: 0.8051 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7834\n",
      "Epoch 3175/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.7882 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7519\n",
      "Epoch 3176/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.7939 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7714\n",
      "Epoch 3177/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8102 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7700\n",
      "Epoch 3178/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8020 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7783\n",
      "Epoch 3179/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8082 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7801\n",
      "Epoch 3180/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8074 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7855\n",
      "Epoch 3181/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8181 - val_loss: 0.0509 - val_binary_accuracy: 0.9700 - val_acc: 0.7855\n",
      "Epoch 3182/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8128 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.7826\n",
      "Epoch 3183/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8053 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7794\n",
      "Epoch 3184/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8087 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7787\n",
      "Epoch 3185/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8089 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7779\n",
      "Epoch 3186/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8090 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7776\n",
      "Epoch 3187/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8094 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7783\n",
      "Epoch 3188/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8098 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7776\n",
      "Epoch 3189/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8106 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7787\n",
      "Epoch 3190/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8100 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7790\n",
      "Epoch 3191/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8102 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7790\n",
      "Epoch 3192/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8105 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7787\n",
      "Epoch 3193/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8112 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7794\n",
      "Epoch 3194/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8113 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7801\n",
      "Epoch 3195/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8116 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7805\n",
      "Epoch 3196/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8125 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7808\n",
      "Epoch 3197/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8123 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7816\n",
      "Epoch 3198/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8178 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7841\n",
      "Epoch 3199/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8148 - val_loss: 0.0523 - val_binary_accuracy: 0.9695 - val_acc: 0.6633\n",
      "Epoch 3200/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.7983 - val_loss: 0.0546 - val_binary_accuracy: 0.9682 - val_acc: 0.7877\n",
      "Epoch 3201/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.7968 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7736\n",
      "Epoch 3202/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.7949 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7924\n",
      "Epoch 3203/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8059 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7729\n",
      "Epoch 3204/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8093 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7747\n",
      "Epoch 3205/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8008 - val_loss: 0.0515 - val_binary_accuracy: 0.9697 - val_acc: 0.7725\n",
      "Epoch 3206/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8042 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7732\n",
      "Epoch 3207/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8056 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7743\n",
      "Epoch 3208/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8053 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7769\n",
      "Epoch 3209/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8083 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7794\n",
      "Epoch 3210/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.7997 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7609\n",
      "Epoch 3211/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.7961 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7776\n",
      "Epoch 3212/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8140 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7830\n",
      "Epoch 3213/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8139 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7841\n",
      "Epoch 3214/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8134 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7812\n",
      "Epoch 3215/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8107 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7801\n",
      "Epoch 3216/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8105 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7794\n",
      "Epoch 3217/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8102 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7797\n",
      "Epoch 3218/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8093 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7841\n",
      "Epoch 3219/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8099 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7823\n",
      "Epoch 3220/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8097 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7830\n",
      "Epoch 3221/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8099 - val_loss: 0.0509 - val_binary_accuracy: 0.9704 - val_acc: 0.7834\n",
      "Epoch 3222/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8102 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7834\n",
      "Epoch 3223/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8096 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7841\n",
      "Epoch 3224/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8119 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7841\n",
      "Epoch 3225/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8115 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7834\n",
      "Epoch 3226/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8113 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7844\n",
      "Epoch 3227/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8108 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7834\n",
      "Epoch 3228/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8113 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7837\n",
      "Epoch 3229/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8113 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7830\n",
      "Epoch 3230/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8122 - val_loss: 0.0516 - val_binary_accuracy: 0.9699 - val_acc: 0.7978\n",
      "Epoch 3231/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8187 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7812\n",
      "Epoch 3232/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.8019 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7707\n",
      "Epoch 3233/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.7894 - val_loss: 0.0515 - val_binary_accuracy: 0.9696 - val_acc: 0.7566\n",
      "Epoch 3234/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.8024 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7830\n",
      "Epoch 3235/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8012 - val_loss: 0.0531 - val_binary_accuracy: 0.9688 - val_acc: 0.7743\n",
      "Epoch 3236/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.7971 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.7848\n",
      "Epoch 3237/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.7989 - val_loss: 0.0532 - val_binary_accuracy: 0.9689 - val_acc: 0.7613\n",
      "Epoch 3238/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.7901 - val_loss: 0.0531 - val_binary_accuracy: 0.9688 - val_acc: 0.7367\n",
      "Epoch 3239/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.7926 - val_loss: 0.0527 - val_binary_accuracy: 0.9692 - val_acc: 0.7519\n",
      "Epoch 3240/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.7963 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7284\n",
      "Epoch 3241/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.7938 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7642\n",
      "Epoch 3242/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0314 - binary_accuracy: 0.9818 - acc: 0.8012 - val_loss: 0.0515 - val_binary_accuracy: 0.9700 - val_acc: 0.7617\n",
      "Epoch 3243/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8015 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7631\n",
      "Epoch 3244/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8030 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7638\n",
      "Epoch 3245/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8026 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7642\n",
      "Epoch 3246/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8040 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7653\n",
      "Epoch 3247/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8051 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7664\n",
      "Epoch 3248/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8053 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7671\n",
      "Epoch 3249/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8059 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7682\n",
      "Epoch 3250/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8063 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7689\n",
      "Epoch 3251/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8063 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7675\n",
      "Epoch 3252/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8072 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7700\n",
      "Epoch 3253/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8147 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7783\n",
      "Epoch 3254/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8114 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7725\n",
      "Epoch 3255/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8097 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7732\n",
      "Epoch 3256/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8094 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7736\n",
      "Epoch 3257/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8095 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7743\n",
      "Epoch 3258/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8102 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7754\n",
      "Epoch 3259/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8106 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7743\n",
      "Epoch 3260/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8143 - val_loss: 0.0521 - val_binary_accuracy: 0.9693 - val_acc: 0.7917\n",
      "Epoch 3261/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8161 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7732\n",
      "Epoch 3262/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8084 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7769\n",
      "Epoch 3263/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8099 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7801\n",
      "Epoch 3264/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8120 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7805\n",
      "Epoch 3265/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8158 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7834\n",
      "Epoch 3266/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8157 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7783\n",
      "Epoch 3267/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8133 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7808\n",
      "Epoch 3268/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8140 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7787\n",
      "Epoch 3269/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8136 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7794\n",
      "Epoch 3270/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8146 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7826\n",
      "Epoch 3271/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8160 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7823\n",
      "Epoch 3272/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8160 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7812\n",
      "Epoch 3273/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8160 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7801\n",
      "Epoch 3274/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8164 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7812\n",
      "Epoch 3275/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8166 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7808\n",
      "Epoch 3276/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8167 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7819\n",
      "Epoch 3277/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8171 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7826\n",
      "Epoch 3278/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8176 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 3279/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8178 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7823\n",
      "Epoch 3280/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8182 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7819\n",
      "Epoch 3281/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8183 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7826\n",
      "Epoch 3282/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8183 - val_loss: 0.0510 - val_binary_accuracy: 0.9700 - val_acc: 0.7826\n",
      "Epoch 3283/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8178 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7794\n",
      "Epoch 3284/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8116 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7794\n",
      "Epoch 3285/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8093 - val_loss: 0.0525 - val_binary_accuracy: 0.9691 - val_acc: 0.6897\n",
      "Epoch 3286/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0319 - binary_accuracy: 0.9814 - acc: 0.7957 - val_loss: 0.0555 - val_binary_accuracy: 0.9673 - val_acc: 0.7613\n",
      "Epoch 3287/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.7990 - val_loss: 0.0530 - val_binary_accuracy: 0.9689 - val_acc: 0.7722\n",
      "Epoch 3288/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0314 - binary_accuracy: 0.9818 - acc: 0.8030 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.7613\n",
      "Epoch 3289/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8007 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7689\n",
      "Epoch 3290/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8042 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7703\n",
      "Epoch 3291/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8062 - val_loss: 0.0524 - val_binary_accuracy: 0.9694 - val_acc: 0.7729\n",
      "Epoch 3292/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8074 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7729\n",
      "Epoch 3293/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8080 - val_loss: 0.0523 - val_binary_accuracy: 0.9694 - val_acc: 0.7736\n",
      "Epoch 3294/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8076 - val_loss: 0.0522 - val_binary_accuracy: 0.9695 - val_acc: 0.7729\n",
      "Epoch 3295/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8142 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7769\n",
      "Epoch 3296/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8125 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7718\n",
      "Epoch 3297/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8076 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7722\n",
      "Epoch 3298/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8099 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7722\n",
      "Epoch 3299/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8084 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7714\n",
      "Epoch 3300/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8085 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7707\n",
      "Epoch 3301/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8082 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7711\n",
      "Epoch 3302/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8037 - val_loss: 0.0523 - val_binary_accuracy: 0.9692 - val_acc: 0.7707\n",
      "Epoch 3303/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8063 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7729\n",
      "Epoch 3304/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8077 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7725\n",
      "Epoch 3305/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8097 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7732\n",
      "Epoch 3306/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8101 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7729\n",
      "Epoch 3307/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8112 - val_loss: 0.0520 - val_binary_accuracy: 0.9695 - val_acc: 0.7747\n",
      "Epoch 3308/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8112 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7758\n",
      "Epoch 3309/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8115 - val_loss: 0.0519 - val_binary_accuracy: 0.9696 - val_acc: 0.7750\n",
      "Epoch 3310/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8088 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7548\n",
      "Epoch 3311/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8065 - val_loss: 0.0539 - val_binary_accuracy: 0.9686 - val_acc: 0.7685\n",
      "Epoch 3312/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.7940 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7696\n",
      "Epoch 3313/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9818 - acc: 0.8117 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7863\n",
      "Epoch 3314/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.8011 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7700\n",
      "Epoch 3315/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.8120 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7624\n",
      "Epoch 3316/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.7892 - val_loss: 0.0519 - val_binary_accuracy: 0.9695 - val_acc: 0.7599\n",
      "Epoch 3317/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8040 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7703\n",
      "Epoch 3318/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8074 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7732\n",
      "Epoch 3319/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8081 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7758\n",
      "Epoch 3320/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8085 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7754\n",
      "Epoch 3321/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8101 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7765\n",
      "Epoch 3322/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8105 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7765\n",
      "Epoch 3323/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8104 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7761\n",
      "Epoch 3324/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8106 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7761\n",
      "Epoch 3325/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8114 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7772\n",
      "Epoch 3326/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8115 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7776\n",
      "Epoch 3327/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8127 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7779\n",
      "Epoch 3328/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8131 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7783\n",
      "Epoch 3329/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8129 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7794\n",
      "Epoch 3330/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8134 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7790\n",
      "Epoch 3331/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8138 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7805\n",
      "Epoch 3332/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8143 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7812\n",
      "Epoch 3333/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8151 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7816\n",
      "Epoch 3334/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8155 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7826\n",
      "Epoch 3335/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8153 - val_loss: 0.0512 - val_binary_accuracy: 0.9699 - val_acc: 0.7823\n",
      "Epoch 3336/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8158 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7826\n",
      "Epoch 3337/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8155 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7823\n",
      "Epoch 3338/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8163 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 3339/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8163 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 3340/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8169 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7837\n",
      "Epoch 3341/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8169 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7837\n",
      "Epoch 3342/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8169 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7837\n",
      "Epoch 3343/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8172 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7834\n",
      "Epoch 3344/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8175 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7844\n",
      "Epoch 3345/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8178 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7844\n",
      "Epoch 3346/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8181 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7841\n",
      "Epoch 3347/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8178 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7848\n",
      "Epoch 3348/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8179 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7848\n",
      "Epoch 3349/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8181 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7852\n",
      "Epoch 3350/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8184 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7844\n",
      "Epoch 3351/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8193 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7848\n",
      "Epoch 3352/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8202 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7852\n",
      "Epoch 3353/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8198 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7855\n",
      "Epoch 3354/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8201 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7859\n",
      "Epoch 3355/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8201 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7859\n",
      "Epoch 3356/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8206 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7859\n",
      "Epoch 3357/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8212 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7859\n",
      "Epoch 3358/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8212 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7859\n",
      "Epoch 3359/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8212 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7859\n",
      "Epoch 3360/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8220 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7863\n",
      "Epoch 3361/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8217 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7870\n",
      "Epoch 3362/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8226 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7870\n",
      "Epoch 3363/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8226 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7873\n",
      "Epoch 3364/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8226 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7873\n",
      "Epoch 3365/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8229 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7888\n",
      "Epoch 3366/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8232 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7892\n",
      "Epoch 3367/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8231 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7899\n",
      "Epoch 3368/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8232 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7902\n",
      "Epoch 3369/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8235 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7902\n",
      "Epoch 3370/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8236 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7902\n",
      "Epoch 3371/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8238 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7902\n",
      "Epoch 3372/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8243 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7913\n",
      "Epoch 3373/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8240 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7910\n",
      "Epoch 3374/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8242 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7917\n",
      "Epoch 3375/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8245 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7920\n",
      "Epoch 3376/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8245 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7917\n",
      "Epoch 3377/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8246 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7913\n",
      "Epoch 3378/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8251 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7953\n",
      "Epoch 3379/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8287 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7906\n",
      "Epoch 3380/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8247 - val_loss: 0.0544 - val_binary_accuracy: 0.9683 - val_acc: 0.7707\n",
      "Epoch 3381/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.7977 - val_loss: 0.0532 - val_binary_accuracy: 0.9688 - val_acc: 0.7201\n",
      "Epoch 3382/4000\n",
      "15667/15667 [==============================] - 0s 20us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.8039 - val_loss: 0.0524 - val_binary_accuracy: 0.9693 - val_acc: 0.7884\n",
      "Epoch 3383/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8208 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7895\n",
      "Epoch 3384/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8145 - val_loss: 0.0518 - val_binary_accuracy: 0.9696 - val_acc: 0.7877\n",
      "Epoch 3385/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8131 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7895\n",
      "Epoch 3386/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8140 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7888\n",
      "Epoch 3387/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8139 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7877\n",
      "Epoch 3388/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8134 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7852\n",
      "Epoch 3389/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8134 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7873\n",
      "Epoch 3390/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8136 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7892\n",
      "Epoch 3391/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8145 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7899\n",
      "Epoch 3392/4000\n",
      "15667/15667 [==============================] - 0s 18us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8172 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7888\n",
      "Epoch 3393/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8139 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7975\n",
      "Epoch 3394/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8215 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7913\n",
      "Epoch 3395/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8023 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.7913\n",
      "Epoch 3396/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8137 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7826\n",
      "Epoch 3397/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8077 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7830\n",
      "Epoch 3398/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8100 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7852\n",
      "Epoch 3399/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8103 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7855\n",
      "Epoch 3400/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8107 - val_loss: 0.0515 - val_binary_accuracy: 0.9697 - val_acc: 0.7873\n",
      "Epoch 3401/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8111 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7877\n",
      "Epoch 3402/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8123 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7884\n",
      "Epoch 3403/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8128 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7873\n",
      "Epoch 3404/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8132 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7877\n",
      "Epoch 3405/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8123 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7881\n",
      "Epoch 3406/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8128 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7852\n",
      "Epoch 3407/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8125 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7895\n",
      "Epoch 3408/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8148 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7902\n",
      "Epoch 3409/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8161 - val_loss: 0.0513 - val_binary_accuracy: 0.9698 - val_acc: 0.7902\n",
      "Epoch 3410/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8172 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7913\n",
      "Epoch 3411/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8164 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7906\n",
      "Epoch 3412/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8176 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7917\n",
      "Epoch 3413/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8180 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7917\n",
      "Epoch 3414/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8183 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7924\n",
      "Epoch 3415/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8179 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7920\n",
      "Epoch 3416/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8186 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7924\n",
      "Epoch 3417/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8188 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7928\n",
      "Epoch 3418/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8196 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7935\n",
      "Epoch 3419/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8197 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7928\n",
      "Epoch 3420/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8192 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7924\n",
      "Epoch 3421/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8199 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7924\n",
      "Epoch 3422/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8205 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7935\n",
      "Epoch 3423/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8204 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7935\n",
      "Epoch 3424/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8201 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3425/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8209 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3426/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8213 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3427/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8212 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3428/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8219 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3429/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8226 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3430/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8220 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7942\n",
      "Epoch 3431/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8221 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7939\n",
      "Epoch 3432/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8226 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7942\n",
      "Epoch 3433/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8223 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7946\n",
      "Epoch 3434/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8249 - val_loss: 0.0525 - val_binary_accuracy: 0.9692 - val_acc: 0.7953\n",
      "Epoch 3435/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0317 - binary_accuracy: 0.9816 - acc: 0.8124 - val_loss: 0.0542 - val_binary_accuracy: 0.9683 - val_acc: 0.7823\n",
      "Epoch 3436/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0315 - binary_accuracy: 0.9817 - acc: 0.7929 - val_loss: 0.0533 - val_binary_accuracy: 0.9689 - val_acc: 0.7722\n",
      "Epoch 3437/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.8093 - val_loss: 0.0526 - val_binary_accuracy: 0.9692 - val_acc: 0.7591\n",
      "Epoch 3438/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.7884 - val_loss: 0.0521 - val_binary_accuracy: 0.9694 - val_acc: 0.7429\n",
      "Epoch 3439/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.7992 - val_loss: 0.0518 - val_binary_accuracy: 0.9698 - val_acc: 0.7447\n",
      "Epoch 3440/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.7944 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7714\n",
      "Epoch 3441/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8067 - val_loss: 0.0514 - val_binary_accuracy: 0.9700 - val_acc: 0.7718\n",
      "Epoch 3442/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8047 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7736\n",
      "Epoch 3443/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8081 - val_loss: 0.0513 - val_binary_accuracy: 0.9701 - val_acc: 0.7769\n",
      "Epoch 3444/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8093 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7779\n",
      "Epoch 3445/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8097 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7776\n",
      "Epoch 3446/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8101 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7783\n",
      "Epoch 3447/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8109 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7787\n",
      "Epoch 3448/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8115 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7787\n",
      "Epoch 3449/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8125 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7787\n",
      "Epoch 3450/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8127 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7790\n",
      "Epoch 3451/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8128 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7801\n",
      "Epoch 3452/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8132 - val_loss: 0.0511 - val_binary_accuracy: 0.9702 - val_acc: 0.7801\n",
      "Epoch 3453/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8135 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7823\n",
      "Epoch 3454/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8143 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7816\n",
      "Epoch 3455/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8149 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7816\n",
      "Epoch 3456/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8149 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7816\n",
      "Epoch 3457/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8153 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7816\n",
      "Epoch 3458/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8158 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7816\n",
      "Epoch 3459/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8163 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7823\n",
      "Epoch 3460/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8166 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7837\n",
      "Epoch 3461/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8173 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7848\n",
      "Epoch 3462/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8175 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7848\n",
      "Epoch 3463/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8175 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7859\n",
      "Epoch 3464/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8176 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7863\n",
      "Epoch 3465/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8176 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7866\n",
      "Epoch 3466/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8175 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7855\n",
      "Epoch 3467/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9819 - acc: 0.8177 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7844\n",
      "Epoch 3468/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8187 - val_loss: 0.0531 - val_binary_accuracy: 0.9689 - val_acc: 0.7722\n",
      "Epoch 3469/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.7901 - val_loss: 0.0534 - val_binary_accuracy: 0.9687 - val_acc: 0.7794\n",
      "Epoch 3470/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.8027 - val_loss: 0.0528 - val_binary_accuracy: 0.9693 - val_acc: 0.7816\n",
      "Epoch 3471/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.7999 - val_loss: 0.0520 - val_binary_accuracy: 0.9698 - val_acc: 0.7895\n",
      "Epoch 3472/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8077 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7743\n",
      "Epoch 3473/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.7909 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.7591\n",
      "Epoch 3474/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.7974 - val_loss: 0.0517 - val_binary_accuracy: 0.9696 - val_acc: 0.7740\n",
      "Epoch 3475/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8040 - val_loss: 0.0516 - val_binary_accuracy: 0.9697 - val_acc: 0.7750\n",
      "Epoch 3476/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8060 - val_loss: 0.0515 - val_binary_accuracy: 0.9697 - val_acc: 0.7754\n",
      "Epoch 3477/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8070 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7750\n",
      "Epoch 3478/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8081 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7772\n",
      "Epoch 3479/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8100 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7797\n",
      "Epoch 3480/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8102 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7841\n",
      "Epoch 3481/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8153 - val_loss: 0.0517 - val_binary_accuracy: 0.9697 - val_acc: 0.7855\n",
      "Epoch 3482/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8122 - val_loss: 0.0516 - val_binary_accuracy: 0.9698 - val_acc: 0.7844\n",
      "Epoch 3483/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8109 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7816\n",
      "Epoch 3484/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8123 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7837\n",
      "Epoch 3485/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8130 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7844\n",
      "Epoch 3486/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8155 - val_loss: 0.0515 - val_binary_accuracy: 0.9697 - val_acc: 0.7783\n",
      "Epoch 3487/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8110 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7808\n",
      "Epoch 3488/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8131 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7830\n",
      "Epoch 3489/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8149 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.7830\n",
      "Epoch 3490/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8154 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7830\n",
      "Epoch 3491/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8161 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7826\n",
      "Epoch 3492/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8165 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7834\n",
      "Epoch 3493/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8171 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7834\n",
      "Epoch 3494/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8165 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7834\n",
      "Epoch 3495/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8171 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7834\n",
      "Epoch 3496/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8168 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7834\n",
      "Epoch 3497/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8175 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.7837\n",
      "Epoch 3498/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8175 - val_loss: 0.0511 - val_binary_accuracy: 0.9700 - val_acc: 0.7834\n",
      "Epoch 3499/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8180 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7830\n",
      "Epoch 3500/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8182 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7837\n",
      "Epoch 3501/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8187 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7844\n",
      "Epoch 3502/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8185 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7852\n",
      "Epoch 3503/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8189 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7866\n",
      "Epoch 3504/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8196 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7859\n",
      "Epoch 3505/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8192 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7866\n",
      "Epoch 3506/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8197 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7873\n",
      "Epoch 3507/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8196 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7870\n",
      "Epoch 3508/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8202 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7859\n",
      "Epoch 3509/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8209 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7866\n",
      "Epoch 3510/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8212 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7873\n",
      "Epoch 3511/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8215 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7866\n",
      "Epoch 3512/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8215 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7866\n",
      "Epoch 3513/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8216 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7877\n",
      "Epoch 3514/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8221 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7895\n",
      "Epoch 3515/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8217 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7892\n",
      "Epoch 3516/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8219 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7895\n",
      "Epoch 3517/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8222 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7906\n",
      "Epoch 3518/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8222 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7910\n",
      "Epoch 3519/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8226 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7913\n",
      "Epoch 3520/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8229 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7920\n",
      "Epoch 3521/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8224 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7920\n",
      "Epoch 3522/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8234 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7928\n",
      "Epoch 3523/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8240 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7920\n",
      "Epoch 3524/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8240 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7931\n",
      "Epoch 3525/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8247 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7939\n",
      "Epoch 3526/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8240 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7939\n",
      "Epoch 3527/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8244 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7942\n",
      "Epoch 3528/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8246 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7942\n",
      "Epoch 3529/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8253 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7942\n",
      "Epoch 3530/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8249 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7939\n",
      "Epoch 3531/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8257 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7949\n",
      "Epoch 3532/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8257 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7946\n",
      "Epoch 3533/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8268 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.7946\n",
      "Epoch 3534/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8268 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7946\n",
      "Epoch 3535/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8262 - val_loss: 0.0512 - val_binary_accuracy: 0.9701 - val_acc: 0.7928\n",
      "Epoch 3536/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8256 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7939\n",
      "Epoch 3537/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8267 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7964\n",
      "Epoch 3538/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8271 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7967\n",
      "Epoch 3539/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8278 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7953\n",
      "Epoch 3540/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8284 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7971\n",
      "Epoch 3541/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8283 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7982\n",
      "Epoch 3542/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8291 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7978\n",
      "Epoch 3543/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8290 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7986\n",
      "Epoch 3544/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8299 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7982\n",
      "Epoch 3545/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8304 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7986\n",
      "Epoch 3546/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8305 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7986\n",
      "Epoch 3547/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8306 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3548/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8310 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3549/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8310 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3550/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8307 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3551/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8314 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7986\n",
      "Epoch 3552/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8317 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3553/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8325 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3554/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8321 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3555/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8325 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7993\n",
      "Epoch 3556/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8326 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7993\n",
      "Epoch 3557/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8332 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3558/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8327 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7989\n",
      "Epoch 3559/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8339 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7996\n",
      "Epoch 3560/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8333 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8000\n",
      "Epoch 3561/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8342 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7996\n",
      "Epoch 3562/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8349 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7996\n",
      "Epoch 3563/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8341 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8000\n",
      "Epoch 3564/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8346 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8007\n",
      "Epoch 3565/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8350 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8007\n",
      "Epoch 3566/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8358 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8007\n",
      "Epoch 3567/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8358 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8014\n",
      "Epoch 3568/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8362 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8011\n",
      "Epoch 3569/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8369 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8033\n",
      "Epoch 3570/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8375 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8029\n",
      "Epoch 3571/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8378 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8022\n",
      "Epoch 3572/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8378 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8033\n",
      "Epoch 3573/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8379 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8029\n",
      "Epoch 3574/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8382 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8036\n",
      "Epoch 3575/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8382 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8040\n",
      "Epoch 3576/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8383 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8043\n",
      "Epoch 3577/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8390 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8040\n",
      "Epoch 3578/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8385 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8047\n",
      "Epoch 3579/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8392 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8051\n",
      "Epoch 3580/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8392 - val_loss: 0.0507 - val_binary_accuracy: 0.9702 - val_acc: 0.8054\n",
      "Epoch 3581/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8395 - val_loss: 0.0557 - val_binary_accuracy: 0.9673 - val_acc: 0.7215\n",
      "Epoch 3582/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0320 - binary_accuracy: 0.9814 - acc: 0.8261 - val_loss: 0.0529 - val_binary_accuracy: 0.9691 - val_acc: 0.8040\n",
      "Epoch 3583/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.8332 - val_loss: 0.0521 - val_binary_accuracy: 0.9695 - val_acc: 0.7667\n",
      "Epoch 3584/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0310 - binary_accuracy: 0.9820 - acc: 0.8125 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7816\n",
      "Epoch 3585/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8109 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7743\n",
      "Epoch 3586/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8056 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7729\n",
      "Epoch 3587/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8123 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7805\n",
      "Epoch 3588/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8154 - val_loss: 0.0510 - val_binary_accuracy: 0.9702 - val_acc: 0.7848\n",
      "Epoch 3589/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8171 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7855\n",
      "Epoch 3590/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8175 - val_loss: 0.0510 - val_binary_accuracy: 0.9703 - val_acc: 0.7834\n",
      "Epoch 3591/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8172 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7873\n",
      "Epoch 3592/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8203 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7881\n",
      "Epoch 3593/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8249 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7884\n",
      "Epoch 3594/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8233 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7877\n",
      "Epoch 3595/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8217 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7863\n",
      "Epoch 3596/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8223 - val_loss: 0.0508 - val_binary_accuracy: 0.9703 - val_acc: 0.7870\n",
      "Epoch 3597/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8220 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7873\n",
      "Epoch 3598/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8230 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7870\n",
      "Epoch 3599/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8234 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7873\n",
      "Epoch 3600/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8233 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7881\n",
      "Epoch 3601/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8240 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7884\n",
      "Epoch 3602/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8243 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7895\n",
      "Epoch 3603/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8252 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7917\n",
      "Epoch 3604/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8261 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7917\n",
      "Epoch 3605/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8263 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7913\n",
      "Epoch 3606/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8269 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7928\n",
      "Epoch 3607/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8270 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7939\n",
      "Epoch 3608/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8274 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7942\n",
      "Epoch 3609/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8273 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7946\n",
      "Epoch 3610/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8277 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7949\n",
      "Epoch 3611/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8277 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7946\n",
      "Epoch 3612/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8275 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7946\n",
      "Epoch 3613/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8282 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7953\n",
      "Epoch 3614/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8282 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7953\n",
      "Epoch 3615/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8285 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7960\n",
      "Epoch 3616/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8289 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7964\n",
      "Epoch 3617/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8292 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7971\n",
      "Epoch 3618/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8295 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7971\n",
      "Epoch 3619/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8294 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7975\n",
      "Epoch 3620/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8298 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7986\n",
      "Epoch 3621/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8300 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.7989\n",
      "Epoch 3622/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8302 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8004\n",
      "Epoch 3623/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8292 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.7978\n",
      "Epoch 3624/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8319 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7931\n",
      "Epoch 3625/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9820 - acc: 0.8261 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7949\n",
      "Epoch 3626/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9820 - acc: 0.8295 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.8123\n",
      "Epoch 3627/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8413 - val_loss: 0.0533 - val_binary_accuracy: 0.9687 - val_acc: 0.7899\n",
      "Epoch 3628/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0314 - binary_accuracy: 0.9817 - acc: 0.8017 - val_loss: 0.0542 - val_binary_accuracy: 0.9684 - val_acc: 0.7291\n",
      "Epoch 3629/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8143 - val_loss: 0.0522 - val_binary_accuracy: 0.9694 - val_acc: 0.7508\n",
      "Epoch 3630/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8125 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.7573\n",
      "Epoch 3631/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8219 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.7844\n",
      "Epoch 3632/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9820 - acc: 0.8098 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7816\n",
      "Epoch 3633/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8055 - val_loss: 0.0508 - val_binary_accuracy: 0.9705 - val_acc: 0.7649\n",
      "Epoch 3634/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8072 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7722\n",
      "Epoch 3635/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8109 - val_loss: 0.0507 - val_binary_accuracy: 0.9706 - val_acc: 0.7747\n",
      "Epoch 3636/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8139 - val_loss: 0.0507 - val_binary_accuracy: 0.9706 - val_acc: 0.7779\n",
      "Epoch 3637/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8159 - val_loss: 0.0506 - val_binary_accuracy: 0.9706 - val_acc: 0.7797\n",
      "Epoch 3638/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8164 - val_loss: 0.0506 - val_binary_accuracy: 0.9706 - val_acc: 0.7805\n",
      "Epoch 3639/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8185 - val_loss: 0.0506 - val_binary_accuracy: 0.9706 - val_acc: 0.7823\n",
      "Epoch 3640/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8189 - val_loss: 0.0506 - val_binary_accuracy: 0.9706 - val_acc: 0.7834\n",
      "Epoch 3641/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8194 - val_loss: 0.0505 - val_binary_accuracy: 0.9707 - val_acc: 0.7830\n",
      "Epoch 3642/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8196 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7841\n",
      "Epoch 3643/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8203 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7852\n",
      "Epoch 3644/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8204 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7852\n",
      "Epoch 3645/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8210 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7859\n",
      "Epoch 3646/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8214 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7859\n",
      "Epoch 3647/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8220 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7877\n",
      "Epoch 3648/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8245 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7888\n",
      "Epoch 3649/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8232 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7873\n",
      "Epoch 3650/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8226 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7870\n",
      "Epoch 3651/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8224 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7863\n",
      "Epoch 3652/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8224 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7866\n",
      "Epoch 3653/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8224 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.7870\n",
      "Epoch 3654/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8228 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.7866\n",
      "Epoch 3655/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8224 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.7873\n",
      "Epoch 3656/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8225 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.7881\n",
      "Epoch 3657/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8233 - val_loss: 0.0504 - val_binary_accuracy: 0.9707 - val_acc: 0.7881\n",
      "Epoch 3658/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8234 - val_loss: 0.0504 - val_binary_accuracy: 0.9707 - val_acc: 0.7877\n",
      "Epoch 3659/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8235 - val_loss: 0.0504 - val_binary_accuracy: 0.9707 - val_acc: 0.7884\n",
      "Epoch 3660/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8238 - val_loss: 0.0504 - val_binary_accuracy: 0.9707 - val_acc: 0.7884\n",
      "Epoch 3661/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8238 - val_loss: 0.0504 - val_binary_accuracy: 0.9707 - val_acc: 0.7884\n",
      "Epoch 3662/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8242 - val_loss: 0.0503 - val_binary_accuracy: 0.9707 - val_acc: 0.7884\n",
      "Epoch 3663/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8245 - val_loss: 0.0503 - val_binary_accuracy: 0.9707 - val_acc: 0.7877\n",
      "Epoch 3664/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8245 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7884\n",
      "Epoch 3665/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8247 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7884\n",
      "Epoch 3666/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8250 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7892\n",
      "Epoch 3667/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8257 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7899\n",
      "Epoch 3668/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8257 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7899\n",
      "Epoch 3669/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8258 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7902\n",
      "Epoch 3670/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8256 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7899\n",
      "Epoch 3671/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8258 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7895\n",
      "Epoch 3672/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8257 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7902\n",
      "Epoch 3673/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8259 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7899\n",
      "Epoch 3674/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8260 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7899\n",
      "Epoch 3675/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8261 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7892\n",
      "Epoch 3676/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8265 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7892\n",
      "Epoch 3677/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8265 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7895\n",
      "Epoch 3678/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8258 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7899\n",
      "Epoch 3679/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8267 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7910\n",
      "Epoch 3680/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8266 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7910\n",
      "Epoch 3681/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8263 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7910\n",
      "Epoch 3682/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8268 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7917\n",
      "Epoch 3683/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8272 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7920\n",
      "Epoch 3684/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8273 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7931\n",
      "Epoch 3685/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8275 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7931\n",
      "Epoch 3686/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8277 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7931\n",
      "Epoch 3687/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8276 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7931\n",
      "Epoch 3688/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8276 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7935\n",
      "Epoch 3689/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8279 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7935\n",
      "Epoch 3690/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8280 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7939\n",
      "Epoch 3691/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8280 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7935\n",
      "Epoch 3692/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8284 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7935\n",
      "Epoch 3693/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8289 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7935\n",
      "Epoch 3694/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8291 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7935\n",
      "Epoch 3695/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8295 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7949\n",
      "Epoch 3696/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8294 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7942\n",
      "Epoch 3697/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8296 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7946\n",
      "Epoch 3698/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8298 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7953\n",
      "Epoch 3699/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8299 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7953\n",
      "Epoch 3700/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8298 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7953\n",
      "Epoch 3701/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8299 - val_loss: 0.0522 - val_binary_accuracy: 0.9693 - val_acc: 0.8188\n",
      "Epoch 3702/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0316 - binary_accuracy: 0.9816 - acc: 0.8075 - val_loss: 0.0544 - val_binary_accuracy: 0.9681 - val_acc: 0.7852\n",
      "Epoch 3703/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0312 - binary_accuracy: 0.9819 - acc: 0.8107 - val_loss: 0.0521 - val_binary_accuracy: 0.9696 - val_acc: 0.7816\n",
      "Epoch 3704/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0309 - binary_accuracy: 0.9821 - acc: 0.8052 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.7769\n",
      "Epoch 3705/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8100 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.7816\n",
      "Epoch 3706/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8164 - val_loss: 0.0509 - val_binary_accuracy: 0.9700 - val_acc: 0.7812\n",
      "Epoch 3707/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8160 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.7797\n",
      "Epoch 3708/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8155 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.7783\n",
      "Epoch 3709/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8148 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7779\n",
      "Epoch 3710/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8160 - val_loss: 0.0507 - val_binary_accuracy: 0.9702 - val_acc: 0.7790\n",
      "Epoch 3711/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8171 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 3712/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8169 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7801\n",
      "Epoch 3713/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8174 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7819\n",
      "Epoch 3714/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8175 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7823\n",
      "Epoch 3715/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8181 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7823\n",
      "Epoch 3716/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8178 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7830\n",
      "Epoch 3717/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8185 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7837\n",
      "Epoch 3718/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8197 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7837\n",
      "Epoch 3719/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8200 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7870\n",
      "Epoch 3720/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8169 - val_loss: 0.0512 - val_binary_accuracy: 0.9698 - val_acc: 0.7779\n",
      "Epoch 3721/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8193 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.7834\n",
      "Epoch 3722/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8273 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7953\n",
      "Epoch 3723/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8277 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7870\n",
      "Epoch 3724/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8238 - val_loss: 0.0508 - val_binary_accuracy: 0.9704 - val_acc: 0.7892\n",
      "Epoch 3725/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8243 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7899\n",
      "Epoch 3726/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8242 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7899\n",
      "Epoch 3727/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8240 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7917\n",
      "Epoch 3728/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8238 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7928\n",
      "Epoch 3729/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8233 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7928\n",
      "Epoch 3730/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8231 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7935\n",
      "Epoch 3731/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8234 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7942\n",
      "Epoch 3732/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8240 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7946\n",
      "Epoch 3733/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8245 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7949\n",
      "Epoch 3734/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8253 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7957\n",
      "Epoch 3735/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8257 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7957\n",
      "Epoch 3736/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8293 - val_loss: 0.0507 - val_binary_accuracy: 0.9705 - val_acc: 0.7942\n",
      "Epoch 3737/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8272 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7939\n",
      "Epoch 3738/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8275 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7960\n",
      "Epoch 3739/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8277 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7953\n",
      "Epoch 3740/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8275 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7953\n",
      "Epoch 3741/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8232 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.7902\n",
      "Epoch 3742/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8244 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7957\n",
      "Epoch 3743/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8263 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.7989\n",
      "Epoch 3744/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8298 - val_loss: 0.0510 - val_binary_accuracy: 0.9699 - val_acc: 0.8025\n",
      "Epoch 3745/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8285 - val_loss: 0.0509 - val_binary_accuracy: 0.9700 - val_acc: 0.8022\n",
      "Epoch 3746/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8286 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8022\n",
      "Epoch 3747/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8287 - val_loss: 0.0507 - val_binary_accuracy: 0.9701 - val_acc: 0.8007\n",
      "Epoch 3748/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8286 - val_loss: 0.0507 - val_binary_accuracy: 0.9701 - val_acc: 0.8007\n",
      "Epoch 3749/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8282 - val_loss: 0.0506 - val_binary_accuracy: 0.9701 - val_acc: 0.8000\n",
      "Epoch 3750/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8296 - val_loss: 0.0506 - val_binary_accuracy: 0.9702 - val_acc: 0.8000\n",
      "Epoch 3751/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8287 - val_loss: 0.0505 - val_binary_accuracy: 0.9702 - val_acc: 0.8000\n",
      "Epoch 3752/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8282 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.8004\n",
      "Epoch 3753/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8296 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8014\n",
      "Epoch 3754/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8314 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.8018\n",
      "Epoch 3755/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8328 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.8014\n",
      "Epoch 3756/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8310 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.8007\n",
      "Epoch 3757/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8305 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8007\n",
      "Epoch 3758/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8305 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.8004\n",
      "Epoch 3759/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8305 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8004\n",
      "Epoch 3760/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8302 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3761/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8304 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3762/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8305 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3763/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8307 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3764/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8307 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7993\n",
      "Epoch 3765/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8306 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3766/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8310 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8000\n",
      "Epoch 3767/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8314 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7996\n",
      "Epoch 3768/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8316 - val_loss: 0.0503 - val_binary_accuracy: 0.9705 - val_acc: 0.7993\n",
      "Epoch 3769/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8316 - val_loss: 0.0503 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3770/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8324 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7996\n",
      "Epoch 3771/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8325 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7993\n",
      "Epoch 3772/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8325 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7996\n",
      "Epoch 3773/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8327 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7993\n",
      "Epoch 3774/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8327 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7982\n",
      "Epoch 3775/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8336 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7993\n",
      "Epoch 3776/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8336 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7986\n",
      "Epoch 3777/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8335 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7989\n",
      "Epoch 3778/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8339 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.7996\n",
      "Epoch 3779/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8337 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8000\n",
      "Epoch 3780/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8338 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8000\n",
      "Epoch 3781/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8347 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8007\n",
      "Epoch 3782/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8346 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8011\n",
      "Epoch 3783/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8348 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8011\n",
      "Epoch 3784/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8353 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8007\n",
      "Epoch 3785/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8351 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8011\n",
      "Epoch 3786/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8353 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8011\n",
      "Epoch 3787/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8353 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8022\n",
      "Epoch 3788/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8359 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8022\n",
      "Epoch 3789/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8359 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8022\n",
      "Epoch 3790/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8351 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8022\n",
      "Epoch 3791/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8367 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8036\n",
      "Epoch 3792/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8365 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8029\n",
      "Epoch 3793/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8363 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8033\n",
      "Epoch 3794/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8369 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8040\n",
      "Epoch 3795/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8373 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8047\n",
      "Epoch 3796/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8370 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8043\n",
      "Epoch 3797/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8377 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8054\n",
      "Epoch 3798/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8381 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8051\n",
      "Epoch 3799/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8388 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8058\n",
      "Epoch 3800/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8379 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8061\n",
      "Epoch 3801/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8379 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8061\n",
      "Epoch 3802/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8391 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8061\n",
      "Epoch 3803/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8395 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8061\n",
      "Epoch 3804/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8394 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8065\n",
      "Epoch 3805/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8395 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8069\n",
      "Epoch 3806/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8400 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8072\n",
      "Epoch 3807/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8399 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8076\n",
      "Epoch 3808/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8415 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8076\n",
      "Epoch 3809/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8414 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8076\n",
      "Epoch 3810/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8413 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8080\n",
      "Epoch 3811/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8402 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8076\n",
      "Epoch 3812/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8415 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8080\n",
      "Epoch 3813/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8417 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8083\n",
      "Epoch 3814/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8420 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8087\n",
      "Epoch 3815/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8432 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8080\n",
      "Epoch 3816/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8434 - val_loss: 0.0502 - val_binary_accuracy: 0.9708 - val_acc: 0.8083\n",
      "Epoch 3817/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8429 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8080\n",
      "Epoch 3818/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8441 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8094\n",
      "Epoch 3819/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8445 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8116\n",
      "Epoch 3820/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8446 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8203\n",
      "Epoch 3821/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8436 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8054\n",
      "Epoch 3822/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8422 - val_loss: 0.0503 - val_binary_accuracy: 0.9705 - val_acc: 0.8098\n",
      "Epoch 3823/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8436 - val_loss: 0.0502 - val_binary_accuracy: 0.9705 - val_acc: 0.8094\n",
      "Epoch 3824/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8443 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8112\n",
      "Epoch 3825/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8456 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8108\n",
      "Epoch 3826/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8459 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8112\n",
      "Epoch 3827/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8466 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8119\n",
      "Epoch 3828/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8459 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8123\n",
      "Epoch 3829/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8474 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8123\n",
      "Epoch 3830/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8465 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8130\n",
      "Epoch 3831/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8467 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8127\n",
      "Epoch 3832/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8462 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8123\n",
      "Epoch 3833/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8469 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8137\n",
      "Epoch 3834/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8468 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.8134\n",
      "Epoch 3835/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8468 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.8134\n",
      "Epoch 3836/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8469 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.8141\n",
      "Epoch 3837/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8473 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8148\n",
      "Epoch 3838/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8477 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8152\n",
      "Epoch 3839/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8480 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8159\n",
      "Epoch 3840/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8497 - val_loss: 0.0541 - val_binary_accuracy: 0.9683 - val_acc: 0.8174\n",
      "Epoch 3841/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0318 - binary_accuracy: 0.9815 - acc: 0.8127 - val_loss: 0.0535 - val_binary_accuracy: 0.9685 - val_acc: 0.7960\n",
      "Epoch 3842/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0311 - binary_accuracy: 0.9819 - acc: 0.8242 - val_loss: 0.0524 - val_binary_accuracy: 0.9692 - val_acc: 0.8148\n",
      "Epoch 3843/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8430 - val_loss: 0.0519 - val_binary_accuracy: 0.9697 - val_acc: 0.8141\n",
      "Epoch 3844/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8427 - val_loss: 0.0518 - val_binary_accuracy: 0.9697 - val_acc: 0.8231\n",
      "Epoch 3845/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8391 - val_loss: 0.0515 - val_binary_accuracy: 0.9699 - val_acc: 0.7946\n",
      "Epoch 3846/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8277 - val_loss: 0.0515 - val_binary_accuracy: 0.9698 - val_acc: 0.7982\n",
      "Epoch 3847/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8289 - val_loss: 0.0514 - val_binary_accuracy: 0.9698 - val_acc: 0.8025\n",
      "Epoch 3848/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8323 - val_loss: 0.0513 - val_binary_accuracy: 0.9699 - val_acc: 0.8033\n",
      "Epoch 3849/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8335 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.8036\n",
      "Epoch 3850/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8339 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.8043\n",
      "Epoch 3851/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8347 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.8058\n",
      "Epoch 3852/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8351 - val_loss: 0.0512 - val_binary_accuracy: 0.9700 - val_acc: 0.8065\n",
      "Epoch 3853/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8356 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.8065\n",
      "Epoch 3854/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8361 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.8069\n",
      "Epoch 3855/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8360 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3856/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8360 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3857/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8362 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3858/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8367 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.8065\n",
      "Epoch 3859/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8367 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3860/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8369 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3861/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8368 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.8058\n",
      "Epoch 3862/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8371 - val_loss: 0.0509 - val_binary_accuracy: 0.9702 - val_acc: 0.8054\n",
      "Epoch 3863/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8371 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.8054\n",
      "Epoch 3864/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8370 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3865/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8372 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8061\n",
      "Epoch 3866/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8371 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8069\n",
      "Epoch 3867/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8371 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8069\n",
      "Epoch 3868/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8369 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8069\n",
      "Epoch 3869/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8370 - val_loss: 0.0508 - val_binary_accuracy: 0.9702 - val_acc: 0.8069\n",
      "Epoch 3870/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8369 - val_loss: 0.0507 - val_binary_accuracy: 0.9702 - val_acc: 0.8072\n",
      "Epoch 3871/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8369 - val_loss: 0.0507 - val_binary_accuracy: 0.9702 - val_acc: 0.8072\n",
      "Epoch 3872/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8371 - val_loss: 0.0507 - val_binary_accuracy: 0.9702 - val_acc: 0.8072\n",
      "Epoch 3873/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8369 - val_loss: 0.0507 - val_binary_accuracy: 0.9702 - val_acc: 0.8072\n",
      "Epoch 3874/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8375 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.8072\n",
      "Epoch 3875/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8376 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.8072\n",
      "Epoch 3876/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8374 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8072\n",
      "Epoch 3877/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8372 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8072\n",
      "Epoch 3878/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8371 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8072\n",
      "Epoch 3879/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8372 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8069\n",
      "Epoch 3880/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8374 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8069\n",
      "Epoch 3881/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8377 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.8069\n",
      "Epoch 3882/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8381 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.8069\n",
      "Epoch 3883/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8381 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8069\n",
      "Epoch 3884/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8383 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8069\n",
      "Epoch 3885/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8383 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8072\n",
      "Epoch 3886/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8383 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8072\n",
      "Epoch 3887/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8386 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8072\n",
      "Epoch 3888/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8390 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8072\n",
      "Epoch 3889/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8393 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8069\n",
      "Epoch 3890/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8396 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.8069\n",
      "Epoch 3891/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8399 - val_loss: 0.0504 - val_binary_accuracy: 0.9704 - val_acc: 0.8083\n",
      "Epoch 3892/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8396 - val_loss: 0.0504 - val_binary_accuracy: 0.9704 - val_acc: 0.8076\n",
      "Epoch 3893/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8399 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8076\n",
      "Epoch 3894/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8402 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8087\n",
      "Epoch 3895/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8404 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8083\n",
      "Epoch 3896/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8404 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3897/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8407 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8083\n",
      "Epoch 3898/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8406 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.8072\n",
      "Epoch 3899/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8409 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.8072\n",
      "Epoch 3900/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8411 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.8072\n",
      "Epoch 3901/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8412 - val_loss: 0.0504 - val_binary_accuracy: 0.9706 - val_acc: 0.8072\n",
      "Epoch 3902/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8413 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8072\n",
      "Epoch 3903/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8417 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8076\n",
      "Epoch 3904/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8418 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8076\n",
      "Epoch 3905/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8416 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8072\n",
      "Epoch 3906/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8414 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3907/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8417 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8087\n",
      "Epoch 3908/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8417 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3909/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8418 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3910/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8416 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8080\n",
      "Epoch 3911/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8415 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3912/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8416 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8080\n",
      "Epoch 3913/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8416 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3914/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8418 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8087\n",
      "Epoch 3915/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8419 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8090\n",
      "Epoch 3916/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8418 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8090\n",
      "Epoch 3917/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8424 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8087\n",
      "Epoch 3918/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8423 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8087\n",
      "Epoch 3919/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8426 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8087\n",
      "Epoch 3920/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8430 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8090\n",
      "Epoch 3921/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8426 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.8083\n",
      "Epoch 3922/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8430 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8090\n",
      "Epoch 3923/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8428 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8087\n",
      "Epoch 3924/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8434 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8094\n",
      "Epoch 3925/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8430 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8090\n",
      "Epoch 3926/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8433 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8090\n",
      "Epoch 3927/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8441 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.8098\n",
      "Epoch 3928/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8445 - val_loss: 0.0509 - val_binary_accuracy: 0.9703 - val_acc: 0.8036\n",
      "Epoch 3929/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8351 - val_loss: 0.0548 - val_binary_accuracy: 0.9677 - val_acc: 0.7479\n",
      "Epoch 3930/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0313 - binary_accuracy: 0.9818 - acc: 0.8248 - val_loss: 0.0526 - val_binary_accuracy: 0.9691 - val_acc: 0.8000\n",
      "Epoch 3931/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8192 - val_loss: 0.0520 - val_binary_accuracy: 0.9697 - val_acc: 0.8141\n",
      "Epoch 3932/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8443 - val_loss: 0.0514 - val_binary_accuracy: 0.9699 - val_acc: 0.8083\n",
      "Epoch 3933/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9822 - acc: 0.8372 - val_loss: 0.0513 - val_binary_accuracy: 0.9700 - val_acc: 0.7986\n",
      "Epoch 3934/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0307 - binary_accuracy: 0.9822 - acc: 0.8314 - val_loss: 0.0510 - val_binary_accuracy: 0.9701 - val_acc: 0.8014\n",
      "Epoch 3935/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8385 - val_loss: 0.0511 - val_binary_accuracy: 0.9701 - val_acc: 0.8054\n",
      "Epoch 3936/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8342 - val_loss: 0.0509 - val_binary_accuracy: 0.9701 - val_acc: 0.8033\n",
      "Epoch 3937/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8351 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8014\n",
      "Epoch 3938/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8338 - val_loss: 0.0508 - val_binary_accuracy: 0.9701 - val_acc: 0.8004\n",
      "Epoch 3939/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8343 - val_loss: 0.0507 - val_binary_accuracy: 0.9701 - val_acc: 0.7996\n",
      "Epoch 3940/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8342 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7996\n",
      "Epoch 3941/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8335 - val_loss: 0.0507 - val_binary_accuracy: 0.9703 - val_acc: 0.7989\n",
      "Epoch 3942/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8333 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7996\n",
      "Epoch 3943/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8337 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7996\n",
      "Epoch 3944/4000\n",
      "15667/15667 [==============================] - 0s 14us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8333 - val_loss: 0.0506 - val_binary_accuracy: 0.9703 - val_acc: 0.7996\n",
      "Epoch 3945/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8337 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7996\n",
      "Epoch 3946/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8333 - val_loss: 0.0506 - val_binary_accuracy: 0.9704 - val_acc: 0.7993\n",
      "Epoch 3947/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8336 - val_loss: 0.0506 - val_binary_accuracy: 0.9705 - val_acc: 0.7993\n",
      "Epoch 3948/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8336 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7993\n",
      "Epoch 3949/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8336 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7993\n",
      "Epoch 3950/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8336 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7989\n",
      "Epoch 3951/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8337 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7989\n",
      "Epoch 3952/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8342 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7986\n",
      "Epoch 3953/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8340 - val_loss: 0.0505 - val_binary_accuracy: 0.9704 - val_acc: 0.7993\n",
      "Epoch 3954/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8342 - val_loss: 0.0505 - val_binary_accuracy: 0.9705 - val_acc: 0.7996\n",
      "Epoch 3955/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8345 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8004\n",
      "Epoch 3956/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8342 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8000\n",
      "Epoch 3957/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8342 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8007\n",
      "Epoch 3958/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8345 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8007\n",
      "Epoch 3959/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8337 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8000\n",
      "Epoch 3960/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8344 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.8000\n",
      "Epoch 3961/4000\n",
      "15667/15667 [==============================] - 0s 17us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8363 - val_loss: 0.0505 - val_binary_accuracy: 0.9703 - val_acc: 0.7982\n",
      "Epoch 3962/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9822 - acc: 0.8425 - val_loss: 0.0517 - val_binary_accuracy: 0.9698 - val_acc: 0.7986\n",
      "Epoch 3963/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8222 - val_loss: 0.0522 - val_binary_accuracy: 0.9696 - val_acc: 0.7957\n",
      "Epoch 3964/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0308 - binary_accuracy: 0.9821 - acc: 0.8257 - val_loss: 0.0520 - val_binary_accuracy: 0.9696 - val_acc: 0.8156\n",
      "Epoch 3965/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9821 - acc: 0.8203 - val_loss: 0.0511 - val_binary_accuracy: 0.9699 - val_acc: 0.7902\n",
      "Epoch 3966/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0307 - binary_accuracy: 0.9822 - acc: 0.8269 - val_loss: 0.0507 - val_binary_accuracy: 0.9704 - val_acc: 0.7772\n",
      "Epoch 3967/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8324 - val_loss: 0.0501 - val_binary_accuracy: 0.9708 - val_acc: 0.8018\n",
      "Epoch 3968/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8284 - val_loss: 0.0505 - val_binary_accuracy: 0.9706 - val_acc: 0.7917\n",
      "Epoch 3969/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8261 - val_loss: 0.0504 - val_binary_accuracy: 0.9705 - val_acc: 0.7946\n",
      "Epoch 3970/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8301 - val_loss: 0.0503 - val_binary_accuracy: 0.9705 - val_acc: 0.7964\n",
      "Epoch 3971/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8316 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7975\n",
      "Epoch 3972/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8319 - val_loss: 0.0502 - val_binary_accuracy: 0.9707 - val_acc: 0.7982\n",
      "Epoch 3973/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8321 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7993\n",
      "Epoch 3974/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8324 - val_loss: 0.0501 - val_binary_accuracy: 0.9706 - val_acc: 0.8000\n",
      "Epoch 3975/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8498 - val_loss: 0.0503 - val_binary_accuracy: 0.9706 - val_acc: 0.8116\n",
      "Epoch 3976/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8427 - val_loss: 0.0504 - val_binary_accuracy: 0.9704 - val_acc: 0.7935\n",
      "Epoch 3977/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8284 - val_loss: 0.0502 - val_binary_accuracy: 0.9706 - val_acc: 0.7924\n",
      "Epoch 3978/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8321 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.7957\n",
      "Epoch 3979/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8332 - val_loss: 0.0501 - val_binary_accuracy: 0.9706 - val_acc: 0.7964\n",
      "Epoch 3980/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8335 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.7971\n",
      "Epoch 3981/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8337 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.7971\n",
      "Epoch 3982/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8340 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7978\n",
      "Epoch 3983/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8344 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7982\n",
      "Epoch 3984/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8347 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7978\n",
      "Epoch 3985/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8348 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7982\n",
      "Epoch 3986/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8347 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7986\n",
      "Epoch 3987/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8347 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7986\n",
      "Epoch 3988/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8349 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7986\n",
      "Epoch 3989/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8356 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7982\n",
      "Epoch 3990/4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8349 - val_loss: 0.0500 - val_binary_accuracy: 0.9708 - val_acc: 0.7978\n",
      "Epoch 3991/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8349 - val_loss: 0.0500 - val_binary_accuracy: 0.9708 - val_acc: 0.7978\n",
      "Epoch 3992/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8349 - val_loss: 0.0500 - val_binary_accuracy: 0.9708 - val_acc: 0.7982\n",
      "Epoch 3993/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8353 - val_loss: 0.0500 - val_binary_accuracy: 0.9708 - val_acc: 0.7986\n",
      "Epoch 3994/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8361 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7993\n",
      "Epoch 3995/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8349 - val_loss: 0.0501 - val_binary_accuracy: 0.9707 - val_acc: 0.7946\n",
      "Epoch 3996/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8305 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7967\n",
      "Epoch 3997/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8328 - val_loss: 0.0500 - val_binary_accuracy: 0.9707 - val_acc: 0.7986\n",
      "Epoch 3998/4000\n",
      "15667/15667 [==============================] - 0s 16us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8346 - val_loss: 0.0499 - val_binary_accuracy: 0.9707 - val_acc: 0.7989\n",
      "Epoch 3999/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8353 - val_loss: 0.0499 - val_binary_accuracy: 0.9707 - val_acc: 0.8004\n",
      "Epoch 4000/4000\n",
      "15667/15667 [==============================] - 0s 15us/step - loss: 0.0306 - binary_accuracy: 0.9822 - acc: 0.8356 - val_loss: 0.0499 - val_binary_accuracy: 0.9708 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fef2f123358>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=train_data, y=train_labels, \n",
    "          validation_split=0.15,  \n",
    "          shuffle=True, \n",
    "          epochs=4000, \n",
    "          batch_size=256, \n",
    "          callbacks=[history, MCP],\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlyPXZiMU1rS"
   },
   "source": [
    "# Check model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "c1i0ncKMU1rS"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_error_stats(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2172,
     "status": "ok",
     "timestamp": 1523702430537,
     "user": {
      "displayName": "Roman Kravtsov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "111193078234152704111"
     },
     "user_tz": -180
    },
    "id": "yAH-gGIMU1rg",
    "outputId": "3dd4b6d6-4411-4369-92e6-f8ad13442bd7"
   },
   "outputs": [],
   "source": [
    "accuracy = binary_accuracy(test_labels, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot and optionally save graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJIAAAJcCAYAAACi347hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XmcZFV9///XqaW36enZN2ZhZtgXWQdEBUTRKKDiioKoEQkuIcbExKgxrjEm+bkkGo0xft1NlBg1iqiAiogoOMgi6zAMA7Mw+9I93dNLVZ3fH7eqp3vonq4epuZWTb+ej0c/uurec+/9VFUD3W8+59wQY0SSJEmSJEkaSybtAiRJkiRJktQYDJIkSZIkSZJUFYMkSZIkSZIkVcUgSZIkSZIkSVUxSJIkSZIkSVJVDJIkSZIkSZJUFYMkSZIkSZIkVcUgSZIkEUJYHULYHULYNeTr+rTrkiRJUn3JpV2AJEmqGy+OMd6YdhGSJEmqX3YkSZKkMYUQvhJC+Pshz68LIcQQQq78/KYQwpVD9j8vhLB6yPN3hxAeCSF0hRDuDyG8bMi+Pw4h/DqE8G8hhJ0hhAdDCOcP2f9Uzp0JIXwuhLC53GXVG0K4aZTXuGPImOKQzqzXlve/JIRwX3ncTSGE48rbF+/1Xuz9fKz6jyuP2VE+/0uG7GsNIXwihPBY+b25pbzt7nJtu0MIpSG1vrd8XAwhHLnvT3XwGjGEcPeQ59kQwroQwtpqaizvv3Kv92zY9UMIV4QQHgghbA8h/DSEcPhexw/tiOsPIXyjvP28veq4pHzuK5EkSakwSJIkSeMSQngOcNI4D3sEOAeYAnwI+EYIYd6Q/U8vj5kJfAD4bghh+gE49x8BLwNOijG2A1ePdpIY49TymLcAv4kxtpe/vhlCOBr4b+AdwCzgOuCHIYQmoFQ+xbh/rwoh5IEfAtcDs4E/A74ZQjimPOTjwOnAM4HpwLuAUozx5HKtFwDrh9T6D+OtoawphHBG+fFFwM5x1AgQgJsrdez1Gi8G3gu8nOS9+xXJezlUBnhR+dgRX0O5jo8AT+zXK5QkSQeEQZIkSar4frnjZEsI4bYQwkv3HhBCCMA/A+8fz4ljjP8TY1wfYyzFGL8NPAycOWTIJuBfYowD5f0PkQQaB+LcAciOp94RvBr4UYzxhhjjAEnA00oS8GwE+klCq/E6C2gH/jHG2B9j/DlwLXBpCCEDXAH8eYxxXYyxGGO8NcbY9xRfy0j+H1Dp8rmy/HzMGoeMaSV5D0byFuBjMcYHYowFkqDolL26kpr2cXzFm4HbgBVVvB5JklQjBkmSJKnipTHGqcBckqDkmhDCUXuNuQTYAvx8hOM/XQ6idgDfH7ojhPD6EMJdQ/afSNJ9VLEuxhiHPH8MOOwAnPt64OvAwyGETuDTY74LIzusXBMAMcYSsAaYXw52/hT4j/L17xnh+NHqPwxYUz5fxWPA/PJraCHpuNofvy9fc1UI4Z1jjL0WOK88HW0ecEeVNVbMBTaPcu7DgX8d8vq3kYR782EwnJwKbB+tuBDCZJJurL8b43VIkqQaM0iSJEnDxBgLMcb/IZneNHQKW2Vq0d+Mcujby9PDpgKD3UzlzpP/JJlWNqO8/16SMKFifjlQqFgErH+q5y6HH9eQhBwLgbdX9y48yXqSQKRy3VA+37rydb4YY5xfvv5I0/5GrL983oXl7qOKReXzbgF6gSP2s+bTytd7CfD3IYRj9zG2AHwP+A7wlb327avGilOBuxnZGuDNlddf/mqNMd5a3n84yQ1gVu2jvr8GrokxPraPMZIk6SAwSJIkScOExMXANOD+IbteB9waYxyp42ZfJgGRcsdKCOGNJF1DQ80G3h5CyIcQXgUcR7IO0VM6d3nB6y8CfxFj3DniGapzDXBRCOH88lo97wT6gFv3fdiYbgN6gHeVX/t5wIuBb5VDsC8BnwwhHFZeBPsZIYTmcV5jB8k6TmP93vcF4AHgm9XWCBBCeBpwLvA/o5z388B7QggnlMdPKX/GlU6jDwDXxxh7Rjl+MvBG4KNj1C9Jkg6CXNoFSJKkuvHDEEKRJJhZC7wpxvjAkP3T2I+pRTHG+0MInwB+QxJofA349V7DbgOOIunC2Qi8Msa49QCc+13A6hjj/4637r2u81AI4XLgMyRTsu4CXhxjHGtdn7HO2x9CeDHwOeA9JF0+r48xPlge8lfAx4DfkaxTdDfwgipP/6vy51kE/iHGeP++BscYV1Fe92hoc9i+agwhLALuJAmp7h3eVMYPgeNijN8LIbQD3yp3kO0EbiAJnj5D8nO1r7uwdQB/H2McdeqbJEk6eMLw5QgkSZIOrhDCHwNXxhjPTrsWjU8IYTHwlRjjeSPsuzHG+LyDXZMkSaotp7ZJkiRpfxUYfZHt0bZLkqQG5tQ2SZIk7ZcY41rgVaPsu/QglyNJkg4Cp7ZJkiRJkiSpKk5tkyRJkiRJUlUabmrbzJkz4+LFi9MuQ5IkSZIk6ZBxxx13bIkxzhprXMMFSYsXL2b58uVplyFJkiRJknTICCE8Vs04p7ZJkiRJkiSpKgZJkiRJkiRJqopBkiRJkiRJkqpikCRJkiRJkqSqGCRJkiRJkiSpKgZJkiRJkiRJqopBkiRJkiRJkqpikCRJkiRJkqSqGCRJkiRJkiSpKgZJkiRJkiRJqopBkiRJkiRJkqpikCRJkiRJkqSqGCRJkiRJkiSpKgZJkiRJkiRJqopBkiRJkiRJkqpikCRJkiRJkqSqGCRJkiRJkiSpKgZJkiRJkiRJqopBkiRJkiRJkqpikCRJkiRJkqSq1CxICiF8KYSwKYRw7yj7Qwjh0yGElSGEe0IIp9WqFkmSJEmSJD11texI+grwwn3svwA4qvx1FfDvNaxFkiRJkiRJT1GuVieOMd4cQli8jyEXA1+LMUbgtyGEqSGEeTHGJ2pVk6Q6VSpBJgMDu6FUhGweMjkIGdi1EYr9UCok45rboTgA/bsglqBtBmxZkTwe/IqQa07OsXsHZLLQvSXZR9xz3Vh+nMlBx2Gw7ZHk3KXi8HFjybdB61TY8fiQGkjOUamlaRL0bIVC754aK/ubJ8Pu7cnjEJKxneuTWipjYE9NlWMhqTXflpy3ODC+933rSph1TPLexhIQklr7u6s7fudaaJkC+ZYhddXIzrUw4wgY6E3qheS9IsDG+5LXUeyHWEzek0Iv9O2CSTPHd539eg3jPGZ/rtG5Hjrmjf84SZIk1d4bfzz+3zsbWM2CpCrMB9YMeb62vO1JQVII4SqSriUWLVp0UIqTtJcYkz9mB3qS59tXw8410NsJu7clQUR/T/J4oBcKu2Hbo5BtglxL8sd/sS/Z17UeOuZD9+YhIcYEkcknAVkIyXta7Eu2N09JtvXuSJ63z01CMwBC+VsY/rx/F3SuSx7POjYJ4Cr7xtLXBdsfha0Pw7yTk89g4/3J5zJpZlLjvpQKsOWh5PHCs55c24HUtT75edv+KBx+NuSaku0xwupflcdsgNnH7gkgH705CblmHLEfF9yP1xDGe8w4xvfuTN7rLV1w/Ev341qSJEmqqUw27QoOqjSDpKrFGL8AfAFg2bJlNfxf3pLo3gqP/hKeuAs23AtdTySdND3boDRKx0u2OfnjPZOF9tnQ1J50tux4LNl/zIXJvmxT0iHUtT75ftbbkvDj1s8kHSRn/wW0TktCivu+Dxvugee+DybPSwKCvi647q+S0OS8d8PWR5KumhNfkXTxhEzyVSrAly9IQpsrb4BiAdpnQRjyL/ihf4x/6oTk+5tvhikLk1rHClIqSkX4p8OTx+9dn9RJ2NMtEwJ8+tTkvbjql3DYKcOPv+YNyet5znuS553rk86s6UvHDgyKBfjIjOTxn95WXb0Vmx+Cz54Jp7wWXvq5PefLZKsLKkol+PC05PGbfjq+a4/XLZ+CGz8Iy66AF31q+L7uLcn+Z74dJs/Zs31gd/JZZPO1re1giBE+NDV5fMlX061FkiRJE16aQdI6YOGQ5wvK2yQdTH1dcO934bFbYf3vk2likIQ+s45NAo0Fy6B1OkxZAC1ToXtT8of6ya9Jng92zuzle2+FJefAKZft2RYj3PVfcMwF0DY92XbW25KOk/lD1tx/1l8kHUtDwwGAw58FUxcm08H25fX/B7OPT4KtsZz9l7Dip0lnzlPRNGnk7Zd8FZZ/GeY+beR9Q3UcVv31suV/hS84o/pjKmYdA1dcD/NPf/L5qpHJwPnvh8NOHf+1x+uYi+Cmf4Qzr3ryvkkz4QUfffL2fGvt6zpY7ECSJElSHQmxhmtalNdIujbGeOII+y4CrgYuBJ4OfDrGeOZY51y2bFlcvnz5Aa5UmkBiTEKbVb+AR34OD9+QdAO1zUiCo8VnJ18Lz9ozhUj79sEpQIAP7jj41+7tTEK/yjpFOjR9cEoyRfR9G9OuRJIkSYeoEMIdMcZlY42rWUdSCOG/gfOAmSGEtcAHgDxAjPHzwHUkIdJKoAd4Y61qkSa0UhG2rYLVt8Da5XDPt/YsVjx5Hpz2ejjxlbDwTDsf9tef3w25lDpgWjrSua4OrneuODSm6UmSJKnh1fKubZeOsT8Cf1qr60sTWs82WPkzeOhHsOqm5I5gkExDm386HPdiWHxOMpXL8Oipm7Y47Qp0qNt7iqckSZKUkoZYbFvSKGJM7ui0dSVs+EPyfc3tsPb2ZP+k2clC1/NOSaarzT7O4EiSJEmStN8MkqRG0dcF636f3AK9awM8/htYf9ee28VDcve02cfBee+BRWclXUcT7FaUkiRJkqTaMUiS6lGMybpGm+6HR36RdBlteQiK/XvGzDwalp6X3Als5lEw50RonzP6HdQkSZIkSXqKDJKkNA3shi0PQ+c62PYo7HgMnrgHNj+wZ12jfFuyEPbSq+CI58L0JcnCzu1zkluwS5IkSZJ0kBgkSbUWI+zaCJsegI33JmsZbVsFu3fA9tVQGtgzNt8G04+AY18EC86AuSfC7OMhn9IdwSRJkiRJGsIgSTpQioUkKFp/JzxxV7KO0fbVsPkhIO4Z1zEfZhwBbTPhqD+COccn09RmHAktU1zTSJIkSZJUtwySpP3RtRE61ybdRWt+l0xFW3fHnv0tU2HqQmidBke/AI58HrTPhkXPhPZZ6dUtSZIkSdJTYJAkjaXQBw9eC/d9D3q2JdPSup7Ys79tRrLQ9amvS+6SNv90mL7U9YukOlQsRWKMZDOBEELa5UjSuMUYxx40bPw4zz++4eOvZ9znH+f4cV5hvOffH/X4GrKZQLF0EF68NEG05rNkMhPnd0uDJGmogd7kTmnr7ki6jTbeCxvvg0Jvsn/eKbD0OTD7WJh5DEyaBfNPA/8g1VMUY2Tzrj5mtTczUIys2rKLY+ZMZu323fQOFMlnM+SygZZ8lvbmHM25TM2DkJ7+Aps6+yiUkuAlGwKZTPLLZzaT1NKWz7JqSze3rtxCoRTpL5boHSjRVyhSLMbBsZWvXCaQy2bIZzM05zJMa2uiozXHvCktTGrO0daUo69QBKA5m6UUI9lsoC2fpWegyJ2P7+BnD2zk4Y272NjVS0dLnqufcyTnHj2Ltdt76Oot8LvV25g7pYWT5k/lR394gjXbe1ixoYuNXb1s3dVPT39y/kxIXksmJHVlyq+pJZ+hKZsp15yhKZehKRsIDH+/m/MZ5k9tpXegSEs+y+SWHL0DpXJIBZ27C+SzgeZchknNOfoKJXr6ixSKyZhCKVIqRUoxUopQipEYk7Ar2RbpHSjRks8wuSXPhy4+gTXbetjZM8ARs9vZsLOX1Vu72bCzlw2dvWzu6qOrt0B3X4HtPf2UYvJzFUn+yIgk56/8wTHiPir7hz4fMq78mDj8j8HWpj1TcvPlkK7yx2VlXOU6lcd772PUfXGvcQw/9wjjK8/3nGuEc4+yL5MJ5Mf5i2Cj/2E87j8lG7z+egs+JEmN7/b3ns/sjpa0yzhownj/Y5q2ZcuWxeXLl6ddhg4FxYFk/aIN9yTrGj36q2SKWkXrNJj7tKTb6MjzYfYJ0DEvvXp1wMQY6ekvkglh2B/Am7p6WblxF5t39bGtu59dvQUymUBbU5ZJzTk6WnJ0tOSZ3JKnozVHPpthZnvzYAixu7/IdX94gu09/XT3FekvFpk3pZWmbIYXnDCXW1Zu4f/dsoqTF07lkc3dHDalhWceOZMTD+vgsv+8jQ2dvYQAb3jGYr5y6+p9voZsJjCtrYnFM9p470XH8a3bH+eetTvpL5TYsXuA1nyW5nyGjpY8mQChHJbksxny2UB7S55j507mc79YSaEUed7xc5je1kRX7wB3PL6dHT0DdPUW9vs9bsplyGcCxRgpliIDxQP335r25hxHzm5n3pQWfrNqKzPbm1m9pZvCKP9ndWpbnqNnT+awqUlYNaejZTCsKZaGfMVIT1+RnoEipfK2QikyUCzRXygNO2ehVGLrrn527h4gAgHo7i/Qks/S3VcgE5LPZ1dfgd6BIhFoyWVobcqRywQisRzMhcEwKwTIhECm/B2gd6DI6q09Y74nbU1ZZk9upqM1z6SmHNMm5clmMgSSnDv5Xo7CAgTCkO1DnpcHjLivfA722h5jEjpWcs2hn3UljqnsqxwzdFtlVOUae49/8r7hIU+lluHHDdlXqXmvoobVMmR8oRQpFONeseHYxpvrjjcIHndsPN56xnnAuF/v+Ibvx/nrq/7xXmCivT+1/udlvPbn9I38nsYIpUj594NxXkjSiF779MOZ1Nz4fTohhDtijMvGHGeQpAmjtxMe/y08dF2yGPbG+6HYl+zLt8HCp8OcE2DKQjjuRcmi2P7X9aAaKJa4e80OZrY305LPMqejmTse285jW3toyWdZuWkXF500l6Zsli3dfRw/r4Oecnjz2NZuHt60i67eAtlMYNH0Np6xdAbPPmYWKzZ28dEfPcCOngE6ewfo7itQyRyacxkWTm/jVacv4GM/fnC/6p7ckuPCE+fx7eVrRh0zY1ITW7v7x3XeV56+gJMWTGH6pCYGiiUGCpHdA0V29SVdJ9+87XF27t5z179zjprJ5JYc09qaknG9Bbr7k1CjFJMwp1As0V8sce+6zlGvO7Utz8UnH8acKS3MmdxCPpcZDFYqgcuOngH+6SfJ+3X8vA4+fempzO5opimbdPOM1NpbKh9beS19hSKbd/WxqauPzt0DdPcV6ekv0JzPQkxeaz6b4VcPb+HnD24C4M+eeyR/9tyjaMolU0ff/t938oO71w+7zitOW8D//n4tAN++6iyevnTGuN73evPLFZt5w5duB+DDF5/Aqs3dzJ3SwtKZk1gycxLzprbSfgj84iJJkqR0VRsk+ZunDm2F/mRto/u+B4/8PAmOmibD/FPh6VfB3JNh3snJXdS8W9oBE2Mc9n8PN3f1cf8TnazfsZubV2zmkjMWctqiafx21VY2d/Uxf1or2RB4x7fvYtuQsOWEwzq4b/3wwONTN64Y9bpzO1pYOmsSKzft4vZHt/GdO9YO7lswrZWzls5gckuOyS05WvJZfvPIViKRX6/cOhgi/e2Fx3HeMbOY2d5MW3OWQjHS3V+gb6BEV2+Bzt6kU6dz9wC7+grc+fh2vn/X+sEQ6bVPX8SlZy5i6axJBAJbdvXx3E/cxNbufg6f0cZnLzuNw2e08cATXTy4oZP3/999ADxt/hT+6gXHDAYG//LqU3jpqfP3+T4/bf4U3vrN3wPw3guP5apzjxjzs6n47u/X8pfX3A3Ar971HG5+eDN/+717Abj+HeeO2Zq7q68wGCRd9+fnVHXNTCaQIemKogkgz+yOFk4Y47hiKfLzBzfx8lPn884/OmbYvs7ePUHa7e89n2mTkhCtEiQ1eogE0JTds97a68463LWdJEmSlCqDJB26Vt4IP3kPbFkBk2bDGW+CI56bLIidnzjzVw+GWF7j5b71O/n8Lx/hZw9soq9QYmpbnhMPm8ItK7cMG//jezeMeJ5F09t423lHcP/6Tr575zruW9/JUbPbefcFx9KSz/LQhi4+fO39Tzrub154LJeduYgpbXkgqeOiT98yuL+tKcuX/vgMjp4zedhxf/qcI+krFDnmfT8B4JtXPp1nHTlz2JjmHPtsUz1iVjvfvyvpiPnte85n7pThP1sLp7cNTvV523lHcOL8KQCcuWQ6zbk9AcG333wWbU3JdZqymTFDJICWfBJ+LpjWOq4QCRjsYDlzyXQWTm/jNWcs4shZ7ZyxeHpVCwVOajp4wWvl/Zs5uflJ+46f18FND23mF3913mD4lc9m+M5bnsHU8s9Do2vO7/k5MUSSJElS2gySdOjZtgp++rfJFLbpS+GVX4ZjLoB8a9qVNbTegSKrNnezYHormRA48QM/BZKpYX17rR9TsaNn4Ekh0tJZk1i1uXvw+f++9Rm84t9/A8Dfv/REzj16FgDrd+7mt6u2cdnTF3H+cXMA6O5L1uw5YtYkfvbO8/jGbx/jd6u3ccXZi2nO7Qk2Olr2BAiP/MOF7B4ojjr1Z2i3x+mHT6vuzRiitWnP8XuHSHu74GnD19jqaE3qfOEJcwdDpN++53xy2erCgkrAsD+BSXM5hMqXr5XNhHF171QCjYMR1lTWJxr6WVW843lH89JT57Nk5qRh25ctnl7zug6WSuCYm0B3ApEkSVL9MkjSoaNvF9zySbj1M5Btgud9CM56K+Se3MWgsa3Z1sOvV25hRnszf/K10dclGylE+s17nkt3X4HnffJmAG7+6+fwyOZdPOOIGXz42vtZtbmbPz//KP7i+UcPO+7YuXs6hv7pFSexZVc/py2aOrhtcjkgqnQIXX7W4Vx+1uFPuv7klj3/astmwj7Xjxna4VHp8BmPyjH7ahSpLEg8NOACWDJzEp+97DTOO2bW4LaxwqihKgFDdj+6VErl9fGymSeHM9W67u3nMGuELqEDbaCY/IwN7eCqaMplntRpdqipvO6mEV6/JEmSdLAZJKnxFQfgnmvg5x+BrifgpNfA8z7oHdbGoa9Q5MEnuvjJfRuY2d7MR0aYPlZxzJzJPLSxC4C7P/BH3L1mB8fN62D11m7Wbd/NRSfNI5/NUCj/8X/0nHYWzWhj0Yw2IJmGBXDu0XumkL345MP44d3rh4USh8+YxOEzhneZVIzUmTJUJTg6GA0clU6ivUOioW5993MZKIx8Y4OLTtr/n9Ohtysfr8oR7c37P0Xt+MM69vvY8bji7CU8snkXr3vGk0PDiaDSbZcf4+dekiRJOhgMktTY1vwOfvJuWLc8WTT7VV+FRU9Pu6q6duP9Gzl23mQ+dcPD7Oob4OYVW9g9UBxxbEdLjs7eAsfOncxHXnoipy+aRiYTeHBDJ49s6mZKa35wKtqsyc2csXjPsblshh9efTaHTR3eYXPVOUt51hEzOXnhnk6jT7zqZD5y8Qljrv9y1Jx2AK48Z8k+x+WyGd5zwbGcfdTMfY47ECoZzoz2plHHzJtSm2mVlTvP7U9H0tlHzuTN5y7lT85deoCrOvCmT2ri3y8/Pe0yUlOZ6mhHkiRJkuqBQZIaU6kIN30Mbv44tE6Dl38RTnwFPIVpOvUuxkhfIbl1e09fkb/7v3tpymX48EtOoFCKdPUOcNeanRw2tYWfP7CJqW15ZrQ38683Pkxbc3bYukT7ctTsdkox8n9Xnz3qlLBj53Zw7Nyxu1GetmDKk7blsplhIRIkfyA35UYPYipmtjez+h8vGnMcwJufPb7Fp/fXwmltvPFZi3ndCFPsam3prKRja386dXLZDO+58LgDXZJqoNKJdPKCqWOMlCRJkmovxDjydIt6tWzZsrh8+ejrtWgC6FwP17wB1t4Op7wWLvhnaG5Pu6r9Vvln8IEnuhgolujuL/DTezfw0/s2smhGG7c/uq2m1//85adx2qJp3LlmB88/bs5+TZNqdO/93h+Y29HC288/Ku1SpBHdtmorJ86fss87CEqSJElPRQjhjhjjsjHHGSSpoay7A77xSij0woUfh1Mu2/cqx3WgVIqEABs6e5nSmmfFxl385pGt3PboVm56aPO4z9eaz9LWlGVrd//gttMWTeXwGZP41cOb2bKrf9j4D7z4eD70w/v5/OWnEUJg665+Vmzs4h3PO4qpbWN3AUmSJEmSDn3VBkn+r001jtW/hv+6BNpmwJtugJlHpl3RML0DRb7060e56cHN3L76qXcRLZ7RxuqtPfzJOUt4+WkLaM1nWTzkFucxxhHXFOrsHSBGaGvKUoqR5lyWNz5r32sKSZIkSZJUDYMkNYbVtySdSFMXwuv/DzoOS7WcnbsHuHfdTn65YjMPbeji1yu3UCiN3d13wYlzmTW5mQ07ezl2XgdXnrOEpmyGfDZDAH758GbOPWoW2fL0svvW7+S4uR0jTjcbbWHqfd09TJIkSZKkp8IgSfVv6yPwrcuSEOmNP4ZJtb8TFyQdRtffv5FP3bCCXCbw8KZdVR33xdcv49yjZxEC7B4okgmBbAj0F0pMadt3yPOcY2YPe37CYU9erFqSJEmSpLQYJKm+9XUlIVLIwmu/U7MQqbuvwO2rt7FmWw/fu3Md96/vpK9QGnX8pKYsf3PBscxsb+b4eR20t+To6i3Qms8yd8qe291X7rYE0NqUrUntkiRJkiQdLAZJql+lEnzvLbBlBbzu+zDtwN1e/fGtPfzrzx7mD+t2sGLj6J1Gl565iP5CiVctW0B3X4HzjplNJow8rWxme/MBq0+SJEmSpHpkkKT69dvPwYPXwgs+Bkuf/ZROVSpFvnPHWt71v/cQAgy9WWFTLkN/ufvomDmTefHJ87jq3CPY3V8ccyqaJEmSJEkTiUGS6tOWlfDzj8DRF8BZb93v09x4/0au/NryYdtihNMWTeUNz1zMmUumM29K64jHNuUyI26XJEmSJGmiMkhS/SmV4AdXQ64ZXvQpGOXuZKNZs62Hf//lI/zgrvXs6isMbv/rFxzDZWcuYtqkpgNdsSRJkiRJE4JBkurPXd+Ax38DF38WOuZVfdjqLd18/PqHuPaeJwa3nbF4Gu++4DhOWTiVbGZ8gZQkSZIkSRrOIEn1Zec6+On7YNEz4JTXVnXIpq5ezvzoz4Zt+/9eeRIXnzLf6WmSJEmSJB1ABkmqH4V++PZrobAbXvJNfs83AAAgAElEQVRvY05p297dz7v+9x5uuH/j4LYvvn4ZZx0xg/Zmf7QlSZIkSTrQ/Gtb9eOmf4D1d8IlX4OZR+5z6O2PbuOS//gNAHM6mnn7+Udx6RmLyDh9TZIkSZKkmjFIUn144Idwy6fgtNfD8RePOizGyH/cvIp//PGDAFx00jw+ecnJNOeyB6tSSZIkSZImLIMkpW/zCvj+22D+6XDhx0cdVipF3vbN3/OT+zYA8KlXn8zLTl1wsKqUJEmSJGnCM0hSujqfgG++EnLN8KqvJt9HsHP3ACd/6HoAnn/8HD5/+enehU2SJEmSpIPMIEnp6dkGX38Z9GyFN/wApi4cdehHf3Q/AJcsW8A/veIkwhgLcUuSJEmSpAPPIEnp6OtKOpG2rYLLv5NMaxvFT+7dwDXL13LBiXMNkSRJkiRJSpFBkg6+YgGueQOsvwte/XVYcu6oQ79522P87ffu5di5k/nUq08xRJIkSZIkKUWZtAvQBNOzDb51KTzyM7jo43DsRaMOvWftDj5y7f2cvHAq17zlGbTkvTObJEmSJElpsiNJB8+jN8N33wzdm+CiT8KyK0YdurNngMu/eBvT25r4z9edTkdL/iAWKkmSJEmSRmKQpNorFeGX/wy//CeYcSRceiMcduqow2OM/PV37qazt8BXrjiT2R0tB7FYSZIkSZI0GoMk1VbXRvjOFfDYLXDyZcl0tqZJ+zzkH3/8INffv5E3Pmsxpy2adpAKlSRJkiRJYzFIUu08+iv47lXQsxVe8hk49XUwxmLZd6/ZwX/cvIrXnLGQ97/o+INUqCRJkiRJqoZBkg68bY/CDe+HB34AUxfBlTfAvJPHPKyrd4CLP/trAK5+7pHeoU2SJEmSpDpjkKQDZ+N9cNPH4MEfQa4FnvM+eObVkG8d89AYI1d97Q4AXr1sIQumtdW6WkmSJEmSNE4GSXpqigVYdRPc8WV48Fpo7oBnvQPO/BPoOKyqUxSKJS77z9u4ffU23nfRcbzp7CW1rVmSJEmSJO0XgySNX3EAHvs1PPQTuO+7sGsjNE+BZ78bnv5maJte9am6+wq88cu/4/bV23jRSfO44llLnNImSZIkSVKdMkhSdXq2wcqfwYofw8M3Qt9OyDbDkc+DUy6Fo/4Ics3jOuW196zn6v+6E4Czlk7nX159CpmMIZIkSZIkSfXKIEnDFfphx2OwdSVsvBeeuAc2/AG2P5rsnzQLjn8xHH0BHPEcaJo07kv09Bf45588xFduXQ3AP7zsaVx65kI7kSRJkiRJqnMGSRPVQG8SGG1+EDY9sOdr2yNQKuwZN20JzH0anPJaWHoezD8dMplxXy7GyNd/+xj/euPDbO3uB5JFtd/x/KOYN2XsxbglSZIkSVL6DJIOVf3d0Lketj8GOx+Hrg2wYw1sX518da0fMjjAtMUw+3g47kUw82iYvhRmHQstHeO6bF+hyM7dA9yzZie7B4o8uqWbT96wgo6WHJ29SUDV3pzj4686mReeOPdAvVpJkiRJknQQGCTVsdjfQ6FzI5liL8WBPmKpBEQo9BEHuqGvG3ZvJ/RuJ/RsJWxfTWbHY4TONWR6dww/F4FS+1yKUw6nuOgcih2H09+xiDjzaHa0LWEg20KxFCmVoBgju/uL9Dy6m527O2nKZegbKLFlVx+lCJu7+nhi5242dfVxx2PbmdySY1pbE8VSZN2O3SO+lv5iiXc+/2heuWyBHUiSJEmSJDUog6Q61NPdyaOffjEn9N1FvrwtO8Yx/THL43E2j8U5rIvLWB9n8kSczro4kzVxFpuZSrE3C1v2PnILI2zcp9Z8ltkdzXT3FQkBunoLdLTkmdPRzPyprZy5ZDqzJjfT0ZqjvTnPOUfNpCU/1iuQJEmSJEn1ziCpDq389ns5qe8ubp51GX1Tj2Qg0wq5HIQkjClmmilmWyhkW+lrmkJ/birFXCuEQAiBAMwOMAc4tbyAdQgQyg9C+Xk2BPoKJaa25clnM2RCIJsJZDOQz2Zoa8oyfVIzfYUiTdkMuUyGyS05prblXRhbkiRJkqQJyCCpnvT3sO3a93PS41/nhrYLef6f/nvaFUmSJEmSJA0ySKoXMfLoZ1/Kkp238Y3C+Zzwyk+mXZEkSZIkSdIw47+Pu2pi+7oVLNl5G58tvISj3/RFTl06L+2SJEmSJEmShjFIqhMPrngIgGc+72WcuWR6ytVIkiRJkiQ9mUFSnejbvh6ApUuOTLkSSZIkSZKkkRkk1Yls9wYA2mYsSLkSSZIkSZKkkRkk1Ylczyb6Yp78pGlplyJJkiRJkjQig6Q60dK7iS1hGoSQdimSJEmSJEkjMkiqE219W9iecZFtSZIkSZJUvwyS6sTkgS3szM1MuwxJkiRJkqRRGSTVg1KJGYVNdDbNTrsSSZIkSZKkURkk1YPOtTTTx/bWRWlXIkmSJEmSNCqDpHqw9ncAbOk4PuVCJEmSJEmSRpdLuwBBfPy39MRmemeekHYpkiRJkiRJo7IjqQ4Utq5mdZzL9Pa2tEuRJEmSJEkalUFSHSju2szW2MHM9ua0S5EkSZIkSRqVQVIdKO3awjYms3jmpLRLkSRJkiRJGpVBUj3o62IXrRwxyyBJkiRJkiTVL4OkelDso31SO5Nb8mlXIkmSJEmSNCqDpDqQiwPM6GhPuwxJkiRJkqR9MkhKW4w0UYBsU9qVSJIkSZIk7ZNBUtqKAwDEnHdskyRJkiRJ9c0gKWWlgd7kgR1JkiRJkiSpzhkkpay/PwmSgh1JkiRJkiSpzhkkpay/r9yRZJAkSZIkSZLqnEFSygb6dgN2JEmSJEmSpPpnkJSyQnmNpEzONZIkSZIkSVJ9M0hKWaG3B4CQb0u5EkmSJEmSpH0zSEpZsa8cJDW1plyJJEmSJEnSvhkkpawSJGWa7EiSJEmSJEn1zSApZcX+bsAgSZIkSZIk1T+DpJSV+ssdSc2TUq5EkiRJkiRp3wySUhbLQVKu2Y4kSZIkSZJU3wyS0lae2pZrnpxyIZIkSZIkSftmkJSy0LsTgGzblJQrkSRJkiRJ2jeDpJRl+nfSGVtpasqnXYokSZIkSdI+GSSlLNvfSRdtNOX8KCRJkiRJUn2raXoRQnhhCOGhEMLKEMK7R9h/eAjhZyGEe0IIN4UQFtSynnqUGeihO7bQbJAkSZIkSZLqXM3SixBCFvgscAFwPHBpCOH4vYZ9HPhajPEk4MPAx2pVT70qFfoZIEd7cy7tUiRJkiRJkvaplm0wZwIrY4yrYoz9wLeAi/caczzw8/LjX4yw/5AXC/0UQo6WfDbtUiRJkiRJkvaplkHSfGDNkOdry9uGuht4efnxy4DJIYQZe58ohHBVCGF5CGH55s2ba1JsWkrFAUrBhbYlSZIkSVL9S3thnr8Cnh1CuBN4NrAOKO49KMb4hRjjshjjslmzZh3sGmur2A9ZgyRJkiRJklT/arkwzzpg4ZDnC8rbBsUY11PuSAohtAOviDHuqGFN9ac4QMy0pV2FJEmSJEnSmGrZkfQ74KgQwpIQQhPwGuAHQweEEGaGECo1vAf4Ug3rqUuhNECwI0mSJEmSJDWAmgVJMcYCcDXwU+AB4JoY430hhA+HEF5SHnYe8FAIYQUwB/horeqpV5nSAGSb0i5DkiRJkiRpTDW953yM8Trgur22vX/I4+8A36llDfUuUyoQcgZJkiRJkiSp/qW92PaEl2MAMk5tkyRJkiRJ9c8gKWW5WKRkkCRJkiRJkhqAQVLKchSImZrOMJQkSZIkSTogDJJSlqVIDNm0y5AkSZIkSRqTQVLKspQgY5AkSZIkSZLqn0FSyjKUwI4kSZIkSZLUAAySUhRjJEuJaEeSJEmSJElqAAZJKSpFCERC8GOQJEmSJEn1zwQjRcVS0pGEQZIkSZIkSWoAJhgpKsVILji1TZIkSZIkNQaDpBQVi0UAgottS5IkSZKkBmCQlKJisZA8sCNJkiRJkiQ1AIOkFBUL5SDJjiRJkiRJktQADJJSZEeSJEmSJElqJAZJKYqVNZIMkiRJkiRJUgMwSEpRsZR0JBkkSZIkSZKkRmCQlKLS4F3b/BgkSZIkSVL9M8FIUalYSh7YkSRJkiRJkhqAQVKKSiUX25YkSZIkSY3DIClFlbu2uUaSJEmSJElqBAZJKYol79omSZIkSZIah0FSikp2JEmSJEmSpAZikJSiyl3bXCNJkiRJkiQ1AoOkFMVSpSMpl3IlkiRJkiRJYzNISlGpWAKc2iZJkiRJkhqDQVKKYmkAMEiSJEmSJEmNwSApRYOLbWfzKVciSZIkSZI0NoOkFMVC0pFE1jWSJEmSJElS/TNISlNlalu2KeVCJEmSJEmSxmaQlKJY6Aec2iZJkiRJkhqDQVKKYrHckZQzSJIkSZIkSfXPIClFg0FSxqltkiRJkiSp/hkkpWhPR5JBkiRJkiRJqn8GSSkKxWSNpIxT2yRJkiRJUgMwSEpRLN+1zSBJkiRJkiQ1AoOkNFWmtmWd2iZJkiRJkuqfQVKaSgUAMq6RJEmSJEmSGoBBUprKHUmZrFPbJEmSJElS/TNISlEYvGubQZIkSZIkSap/BklpcrFtSZIkSZLUQAyS0lReIymba065EEmSJEmSpLEZJKUoFPsByGRzKVciSZIkSZI0NoOkNJUK9McsuawfgyRJkiRJqn8mGCmKhQEK5GjOZdMuRZIkSZIkaUwGSSmKxX4GyNKc82OQJEmSJEn1zwQjRbHYT4EcmUxIuxRJkiRJkqQxGSSlqVigEJzWJkmSJEmSGoNBUppKAxTxjm2SJEmSJKkxGCSlqdhPMRgkSZIkSZKkxmCQlKZiwSBJkiRJkiQ1DIOkFIVYJLpGkiRJkiRJahAGSakqUfIjkCRJkiRJDcIUI0UhRiIh7TIkSZIkSZKqYpCUokCJGPwIJEmSJElSYzDFSJMdSZIkSZIkqYEYJKUoUCL6EUiSJEmSpAZhipGiEJ3aJkmSJEmSGocpRopcbFuSJEmSJDUSg6QUudi2JEmSJElqJKYYKbIjSZIkSZIkNRKDpBTZkSRJkiRJkhqJKUaKAiWwI0mSJEmSJDUIg6Q0xWhHkiRJkiRJahimGCnKUCL6EUiSJEmSpAZhipGiECMxOLVNkiRJkiQ1BoOkFCVrJPkRSJIkSZKkxmCKkaKAayRJkiRJkqTGYYqRohBLTm2TJEmSJEkNwyApRYGIH4EkSZIkSWoUphgpCpSc2iZJkiRJkhqGKUaKApGIU9skSZIkSVJjMEhKUYglsCNJkiRJkiQ1CFOMFGW8a5skSZIkSWogphgpCpTAqW2SJEmSJKlBGCSlKNiRJEmSJEmSGogpRooyrpEkSZIkSZIaiClGigIRPwJJkiRJktQoTDFSFIjEjGskSZIkSZKkxmCQlKKMi21LkiRJkqQGYpCUokB0jSRJkiRJktQwTDFSZJAkSZIkSZIaiSlGigySJEmSJElSIzHFSFEmloiukSRJkiRJkhqEQVKK7EiSJEmSJEmNxBQjRRkiwSBJkiRJkiQ1CFOMFAVKkPEjkCRJkiRJjcEUI0UZp7ZJkiRJkqQGYoqRkhijQZIkSZIkSWoophgpKcVkalsI2bRLkSRJkiRJqopBUkqKpUpHUki7FEmSJEmSpKoYJKWkVJna5mLbkiRJkiSpQdQ0xQghvDCE8FAIYWUI4d0j7F8UQvhFCOHOEMI9IYQLa1lPPSkWS2RCJLhGkiRJkiRJahA1SzFCsvjPZ4ELgOOBS0MIx+817H3ANTHGU4HXAJ+rVT31phhLAAZJkiRJkiSpYVSdYoQQLgohrA0hPBFCeG0Vh5wJrIwxroox9gPfAi7ea0wEOsqPpwDrq62n0ZWKxeSBi21LkiRJkqQGMZ52mPcD5wEnAu+sYvx8YM2Q52vL24b6IHB5CGEtcB3wZyOdKIRwVQhheQhh+ebNm8dRcv0qloOk4BpJkiRJkiSpQYwnxcjHGFfGGLcCuw7Q9S8FvhJjXABcCHw9jDDXK8b4hRjjshjjslmzZh2gS6erWCp3JBkkSZIkSZKkBpEba0AI4TMkU9AWhBA+DQRgaRXnXgcsHPJ8QXnbUG8CXggQY/xNCKEFmAlsquL8Da1UdI0kSZIkSZLUWMYMkoDl5e93jLBtX34HHBVCWEISIL0GuGyvMY8D5wNfCSEcB7QAh8bctTGUSgZJkiRJkiSpsVQTJDXHGL8w3hPHGAshhKuBnwJZ4EsxxvtCCB8GlscYf0Cy1tJ/hhD+gqTr6Y9jjHG812pEg4ttO7VNkiRJkiQ1iGqCpLcA4w6SAGKM15Esoj102/uHPL4feNb+nLvRlcprJNmRJEmSJEmSGkU1QdLUEMLL994YY/xuDeqZMCqLbWfsSJIkSZIkSQ2imiBpCvAikkW2KyJgkPQUVBbbJmTTLUSSJEmSJKlK1QRJj8cYr6h5JRNMKZanttmRJEmSJEmSGkQ1KcZ9Na9iAqostu0aSZIkSZIkqVFUk2L8XQihpfIkhNAaQlhcs4omiFgqT22zI0mSJEmSJDWIalKM/wFKQ54Xy9v0FMQYATuSJEmSJElS46gmxcjFGPsrT8qPm2pX0gRRXiOpuo9AkiRJkiQpfdWkGJtDCC+pPAkhXAxsqV1JE4NT2yRJkiRJUqOp5q5tbwG+GUL4bPn5GuB1tStpgihPbSOEdOuQJEmSJEmq0phBUozxEeCsEEJ7+fmumlc1AcTK1LaQTbcQSZIkSZKkKo05ryqEMCWE8EngJuCmEMInQghTal7ZoS6Wp7bZkSRJkiRJkhpENQv0fAnoAi4pf3UCX65lURPB4BpJdiRJkiRJkqQGUc0aSUfEGF8x5PmHQgh31aqgCcOOJEmSJEmS1GCq6UjaHUI4u/IkhPAsYHftSpogykFS8K5tkiRJkiSpQVTTkfRW4KvldZECsA3441oWNREMTm3DqW2SJEmSJKkxVHPXtruAk0MIHeXnnTWvaiIYnNqWbhmSJEmSJEnVGjNICiG8f6/nAMQYP1yjmiaEGCOw5/2UJEmSJEmqd9Us0NNd/vqTIY+7a1nUhFAOkgiukSRJkiRJkhpDNVPbPgEQQri88lhPXawstm1HkiRJkiRJahDjaYeJNatiAtrzZhokSZIkSZKkxlDNGkk/JMk9loYQflDZHmN8SS0LO+QNrpGUch2SJEmSJElVGjNIAj5e/u60tgMoVnqSTJIkSZIkSVKDqGaNpF8ejEImnFK5I8mpbZIkSZIkqUFUM7Wti+HrIwUgxhg7albVBDD4hpojSZIkSZKkBjHmYtsxxskxxo5ycPRI5flBqO2QVrlr2/jWO5ckSZIkSUrPeFOMatZUUlWSnqSMHUmSJEmSJKlBVDO17TPlhycDt9W2nIkjVua2ZexIkiRJkiRJjaGaDqPlQAn4LnBTTauZQGKsLLYtSZIkSZLUGKpZI+mrwPXAJOCiEMLsmlc1EVRakoJRkiRJkiRJagxjBkkhhEuA24FXAZcAt4UQXlnrwg51kUpHklPbJEmSJElSY6hmatvfAmfEGDcBhBBmATcC36llYYe8wY6kdMuQJEmSJEmqVjXtMJlKiFS2tcrjtA+VjiRJkiRJkqRGUU1H0k9CCD8F/rv8/NXAdbUraYIoJd8ywUxOkiRJkiQ1hjGDpBjjX4cQXg6cXd70hRjj92pb1qFvsCPJxbYlSZIkSVKDGDNICiF8MMb4QeC7tS9n4ojlNZLMkSRJkiRJUqOoZl7VS2pexUQ0GCQ5tU2SJEmSJDWGatZImh1C+Mu9N8YYP1mDeiYQ79omSZIkSZIaSzVBUhZox8jjgIqDOZJvqyRJkiRJagzVBEkbYowfrnklE0xlsW3XSJIkSZIkSY2imgV6bqh5FRNRLCXfXSNJkiRJkiQ1iDFTjBjjuw5GIRPN4NQ2W5IkSZIkSVKDsB0mNeWpba6RJEmSJEmSGoRBUkrinpakdAuRJEmSJEmqkkFSWqKLbUuSJEmSpMYy5l3bQggFoAcIQAvQC8QYY0eNazukxcFHZnmSJEmSJKkxVJNi/CHG2BFjnAzcG2OcbIh0AJTv2mZHkiRJkiRJahTVBEnNACGEJmBpCOGDNa1ogqgskWSSJEmSJEmSGkU1QdLNIYS7gbuAfwE6Qwg/rm1ZE0cmOLVNkiRJkiQ1hjHXSIoxviWEcCJQjDE+ABBC+G3NKzvExfLUNkmSJEmSpEYxZpAEEGO8d6/nt9amnAmkcte2jFPbJEmSJElSYxhzXlUI4awQwu9CCLtCCP0hhGIIofNgFHdIqwRJGCRJkiRJkqTGUM0CPf8GXAo8DLQCVwKfrWVRE0FlrW0X25YkSZIkSY2iqpWeY4wrgWyMsRhj/DLwwtqWNQEMdiRJkiRJkiQ1hmrWSOoJITQBd4UQ/hl4gioDKI0uVnqSXCNJkiRJkiQ1iGoCodcBWeBqoBtYCPz/7d17uF1lfSfw7y8hNAwIAnKrUclYWlGwiBGlKqZqhVGEeqlAGTA+vTgCTqcXFSgqiO20JQoz0MdOtQpoO0ixdBSpInJzhloSMGoAIVSCJqUmBgWDgJi888fZiYeQyw7JZmWd8/k8z/astfbaK7/s96xz8Jv39+43jbKoSWEwI2lKyeQAAACAftjkjKTW2j2DzYeSnDXaciaP1tqmTwIAAADYhmwySKqquzNubeg1Wmv/cSQVTRZr1kgyIwkAAADoiWHWSJqVsTWhr0nyq6MtZzJZEyR1XAYAAADAkIZpbVuRJFX10zXbbLk1nW0lSQIAAAB6YpjWtt0Gm1OratcMPrG+tXbfKAub+NZ0CwqSAAAAgH4YprXt5oylHpXklsGxlsQaSVug/WxKUreFAAAAAAxpmNa2mU9GIZOV1jYAAACgL4ZpbZue5KQkL8vYTKSvJPmr1trDI65tYlvzqW0dlwEAAAAwrGFa2y5O8qMk5w/2fzPJJ5P8xqiKmhwGQdKUKR3XAQAAADCcYYKkA1przx23f21V3TaqgiYPi20DAAAA/TLMdJhbquola3aq6sVJ5o+upMmhrc2RBEkAAABAPwwzI+mFSW6squ8M9p+Z5I6q+maS1lp7/siqm9CskQQAAAD0yzBB0hEjr2ISqjVBkhlJAAAAQE9sMkhqrd2TJFW1Z5Lp445/Z4MvYpPWtraZkwQAAAD0xCbXSKqqo6pqUZK7k1yfZHGSfxpxXZPAmhlJHZcBAAAAMKRhFts+O8lLktzZWpuZ5FVJvjrSqiaDNVOSJEkAAABATwwTJD3aWluRZEpVTWmtXZtk1ojrmgTWfmxbp1UAAAAADGuYxbZ/WFU7Jbkhyd9W1bIkD462rMmjpgiSAAAAgH4YZkbS0UkeSvL7Sb6Q5F+TvH6URU0KzYwkAAAAoF+G+dS28bOPLhphLZOLIAkAAADomU0GSVX1o4wt6LNDxmYmVZLWWtt5xLVNaGtjJIttAwAAAD0xzIykpyRJVX2ttfaC0Zc0OdQgShIjAQAAAH0xzBpJa7RNn8LQ1rS2mZEEAAAA9MQwrW0HDzZ3qKoXZDCJprV2yygLm+jaIEiq2pwsDwAAAKA7mwySknxo8PXfk3x4sN2SvHIkFU0y1kgCAAAA+mKYNZJ+9ckoZPJZMyOp4zIAAAAAhjRMa9sfrO94a+3D6zvOkJolpwAAAIB+Gaa17b1J7kly+YhrmVTWxEjWSAIAAAD6Ypgg6dlJTkvyqiQfaK1dPdqSJofyIXgAAABAz2xyOkxr7b7W2ruSHJvkN6rqC1X1otGXNsGtaW2zSBIAAADQE8OskfS5jOvESvLMJF9NMnWEdU0C499SAAAAgG3fMK1tc0dexWRmRhIAAADQE5sMklpr16/ZrqrdW2srRlvSJOFT2wAAAICe2eAaSVV19rjtF1fVd5PcWlXLq+p1T0p1E5rWNgAAAKBfNrbY9viw6E+T/EZrbe8kLx/sszVobQMAAAB6YmNB0viEY7fW2leTpLX2rSSrR1rVZKC1DQAAAOiZjQVJbQPb69tfr6o6oqruqKq7qurU9Tx/blUtGDzurKofDnPdiaBpbQMAAAB6ZmOLbf9yVT2QsaRjh8F2BvvTN3Xhqpqa5C+T/FqSJUnmVdVnW2u3rTmntfb7485/Z5IXbP5foZ/Wxkda2wAAAICe2GCQ1FqbuoXXPiTJXa21bydJVV2S5Ogkt23g/OOSvH8L/8ze+FlnmyAJAAAA6IeNtbZtqacn+e64/SWDY49TVc9KMjPJNRt4/neran5VzV++fPlWL7QblpkCAAAA+mWUQdLmODbJZa21Vet7srX21621Wa21WXvssceTXNpo1JopSVrbAAAAgJ4YZZC0NMkzxu3PGBxbn2OT/O8R1rINEyQBAAAA/TDKIGlekv2qamZVbZ+xsOiz655UVc9JsmuSfx5hLQAAAABsoZEFSa21nyY5JckXk9ye5NLW2q1V9YGqOmrcqccmuaS1ny0/PSm0wRpJWtsAAACAntjgp7ZtDa21K5Ncuc6x962zf+Yoa9j2CZIAAACAfthWFtuedNbOvzIjCQAAAOgJQVJnJlcnHwAAANB/gqSOlCAJAAAA6BlBUke0tgEAAAB9I0jqjBlJAAAAQL8Ikjrys9Y2M5IAAACAfhAkdWVNb5vWNgAAAKAnBEmdEyQBAAAA/SBI6ow1kgAAAIB+ESR1RWsbAAAA0DOCpM4JkgAAAIB+ECR1pGltAwAAAHpGkNSRWpMjaW0DAAAAekKQ1JnVg6+CJAAAAKAfBEkdWdvYZkYSAAAA0BOCpI5Us0YSAAAA0C+CpM6ZkQQAAAD0gyCpI1rbAAAAgL4RJHWkorUNAAAA6BdBUlfWrpFkRhIAAADQD4KkjqydkaS1DQAAAOgJQVLnBEkAAABAPwiSutKskQQAAAD0iyCpM1rbAAAAgH4RJHVOkAQAAAD0gyCpK1rbAAAAgJ4RJHVGaxsAAADQL4KkrqyZkCRIAgAAAHpCkAQAAADAUARJnVnddQEAAAAAm0WQ1JWWrPaJbYoj56sAABzWSURBVAAAAECPCJI61ARJAAAAQI8IkjrTNn0KAAAAwDZEkNSZJkoCAAAAekWQ1JFKS7S2AQAAAD0iSOqQNZIAAACAPhEkdaVpbAMAAAD6RZDUGWskAQAAAP0iSOqU1jYAAACgPwRJXdHaBgAAAPSMIKkzzWLbAAAAQK8IkjpSiTWSAAAAgF4RJHWlxYwkAAAAoFcESZ1Z3XUBAAAAAJtFkNQpM5IAAACA/hAkdUhrGwAAANAngqSuNEttAwAAAP0iSOpIpfnUNgAAAKBXBEmdabFGEgAAANAngqSOtGaNJAAAAKBfBEkdKY1tAAAAQM8IkjrUTEgCAAAAekSQ1ClJEgAAANAfgqTOaG0DAAAA+kWQ1JFqzWLbAAAAQK8IkjojSAIAAAD6RZAEAAAAwFAESZ2xRhIAAADQL4KkrlgjCQAAAOgZQVKnBEkAAABAfwiSOlJa2wAAAICeESR1SJQEAAAA9IkgqSutpZXWNgAAAKA/BEmdEiQBAAAA/SFI6ozGNgAAAKBfBEkdqbQ0M5IAAACAHhEkAQAAADAUQVJXmtY2AAAAoF8ESZ3R2gYAAAD0iyCpI9ZIAgAAAPpGkNQpQRIAAADQH4KkrlgiCQAAAOgZQVJHxlrbAAAAAPpDkNSRliSltQ0AAADoD0FSR8p8JAAAAKBnBEmd8altAAAAQL8IkjpSrcWntgEAAAB9IkjqkOY2AAAAoE8ESZ0RIwEAAAD9IkjqSI37XwAAAIA+ECR1pCUW2wYAAAB6RZDUkWrNhCQAAACgVwRJnfGpbQAAAEC/CJI6UmmW2wYAAAB6RZDUEWskAQAAAH0jSOpImY8EAAAA9IwgqSstsUYSAAAA0CeCpA61EiQBAAAA/SFI6khZIQkAAADoGUFSZ5ooCQAAAOgVQVJHKs1y2wAAAECvjDRIqqojquqOqrqrqk7dwDlvqarbqurWqvq7UdazLRkLkcxIAgAAAPpju1FduKqmJvnLJL+WZEmSeVX12dbabePO2S/JaUle2lr7QVXtOap6tjVlOhIAAADQM6OckXRIkrtaa99urf0kySVJjl7nnN9J8pettR8kSWtt2Qjr2ca0mJEEAAAA9Mkog6SnJ/nuuP0lg2Pj/WKSX6yq/1dVX62qI9Z3oar63aqaX1Xzly9fPqJyn3wW2wYAAAD6pOvFtrdLsl+S2UmOS/LRqnrquie11v66tTartTZrjz32eJJLHI1KMyEJAAAA6JVRBklLkzxj3P6MwbHxliT5bGvt0dba3UnuzFiwNAlYJAkAAADol1EGSfOS7FdVM6tq+yTHJvnsOuf8Y8ZmI6WqnpaxVrdvj7CmbUalaW0DAAAAemVkQVJr7adJTknyxSS3J7m0tXZrVX2gqo4anPbFJCuq6rYk1yZ5V2ttxahq2vYIkgAAAID+2G6UF2+tXZnkynWOvW/cdkvyB4PH5NKskQQAAAD0S9eLbU9aFZ/aBgAAAPSLIKlLJUgCAAAA+kOQ1Bmf2gYAAAD0iyCpIyVIAgAAAHpGkNSV1qyRBAAAAPSKIKlL1kgCAAAAekSQ1BEREgAAANA3gqTOaG0DAAAA+kWQ1ClBEgAAANAfgqTO+NQ2AAAAoF8ESR2pNFESAAAA0CuCpI5U4lPbAAAAgF4RJHVKkAQAAAD0hyCpK01jGwAAANAvgqSOjK2RZEYSAAAA0B+CpE4JkgAAAID+ECR1RmsbAAAA0C+CpI741DYAAACgbwRJnWnmJAEAAAC9IkjqlBlJAAAAQH8IkjpSzXwkAAAAoF8ESZ1pMSMJAAAA6BNBUoeaxbYBAACAHhEkdaQstQ0AAAD0jCCpIzXufwEAAAD6QJDUGTOSAAAAgH4RJHXIGkkAAABAnwiSOlJpGtsAAACAXhEkdUiUBAAAAPSJIKlTgiQAAACgPwRJHak0ORIAAADQK4KkjlRaJEkAAABAnwiSutKskQQAAAD0iyCpU4IkAAAAoD8ESR0Za20DAAAA6A9BUkcstg0AAAD0zXZdFzBZjc1HkiQBAAAA/SFI6ojWNgAAAKBvtLZ1pNJ8ahsAAADQK4KkLpUgCQAAAOgPQVKnBEkAAABAfwiSOmKNJAAAAKBvBEkdGQuSzEgCAAAA+kOQ1KFmjSQAAACgRwRJAAAAAAxFkNSRatZIAgAAAPpFkNQRayQBAAAAfSNI6pA1kgAAAIA+ESR1ppmPBAAAAPSKIKkjFVESAAAA0C/bdV3AZPWs3f9DsvfOXZcBAAAAMDRBUkemVhJrJAEAAAA9orWtK60JkgAAAIBeESR1piXWSAIAAAB6RJDUJTOSAAAAgB4RJHWlta4rAAAAANgsgqTOaG0DAAAA+kWQ1CWtbQAAAECPCJK6orUNAAAA6BlBUme0tgEAAAD9IkjqSovWNgAAAKBXBEmdEiQBAAAA/SFI6ow1kgAAAIB+ESR1pTWtbQAAAECvCJI6JUgCAAAA+kOQ1BmtbQAAAEC/CJK60poJSQAAAECvCJI60yJJAgAAAPpEkNQli20DAAAAPSJI6kqzRhIAAADQL4KkzmhtAwAAAPpFkNQlrW0AAABAjwiSuqK1DQAAAOgZQVJntLYBAAAA/SJI6kprWtsAAACAXtmu6wImN0ESAAAAk9ejjz6aJUuW5OGHH+66lElj+vTpmTFjRqZNm/aEXi9I6ow1kgAAAJjclixZkqc85SnZd999U7p2Rq61lhUrVmTJkiWZOXPmE7qG1rauaG0DAABgknv44Yez++67C5GeJFWV3XfffYtmgAmSOuVGAQAAYHITIj25tvT9FiR1RmsbAAAA0C+CpK5obQMAAIDOTZ06NQcddFB++Zd/OQcffHBuvPHGrkvapllsuzMtWtsAAACgWzvssEMWLFiQJPniF7+Y0047Lddff33HVW27BEldMiMJAAAAkiRnfe7W3PZvD2zVaz7353fO+1//vKHPf+CBB7LrrrsmSVauXJmjjz46P/jBD/Loo4/mgx/8YI4++ugkyeLFi7P//vvnl37pl3LfffflqKOOygUXXJDZs2dn7ty5mTVrVs4444ycd955WblyZZJk/vz5mT17dn7hF37hMa9ZvHhxTjjhhDz44INJkgsuuCC/8iu/kuuuuy5z587NFVdckSSZO3duVq5cmTPPPDMXXnhh5s+fnwsuuCB33HFHnve85+WSSy7Jm9/85nz+85/Pu9/97kybNi1Lly7NOeeckzlz5my191SQ1BVLJAEAAEDnHnrooRx00EF5+OGHc++99+aaa65JkkyfPj2XX355dt5553z/+9/PS17ykhx11FGpqqxatSr77bdfFixYsDbUGW/ZsmX58pe//Jhjq1atyiGHHJJrrrnmMa/Zc88986UvfSnTp0/PokWLctxxxz3uehvz3ve+N/vvv//a/fe973256KKLMmvWrJxyyilP9G3ZIEFSZ7S2AQAAwBqbM3Noaxrf2vbP//zPOfHEE7Nw4cK01nL66afnhhtuyJQpU7J06dJ873vfy957752HHnoo06dP3+A1zz777Jx++uk57rjj1h5buXJldtttt8ed++ijj+aUU07JggULMnXq1Nx5551D1z5//vysXr06L3zhC9cemzp1an70ox8NfY3NJUjqktY2AAAA2GYceuih+f73v5/ly5fnyiuvzPLly3PzzTdn2rRp2XffffPwww8nSf7t3/4tP//zP7/eayxevDgLFy7M+eef/5jjd999d2bMmPG4888999zstdde+frXv57Vq1dvNKBa13vf+958+MMfzp//+Z+vPfahD30oJ5xwQqZPn54VK1Zk1qxZQ19vGD61rStNbxsAAABsS771rW9l1apV2X333XP//fdnzz33zLRp03LttdfmnnvuWXve3//93+elL33peq9x1lln5ayzznrMsdZaPvOZz+TII4983Pn3339/9tlnn0yZMiWf/OQns2rVqqFqvf7667PPPvs8pq0tSZ7+9Kdnn332yfz583PMMccMda3NYUZSZ7S2AQAAQNfWrJGUjAU+F110UaZOnZrjjz8+r3/963PggQdm1qxZec5znpMkefe7350HH3wwJ5988nqvN2PGjBx22GGPOfae97wnX/jCF7J06dJMmTIl9913Xx566KHMmTMnJ510Ut70pjfl4osvzhFHHJEdd9xx7etuvPHGvOxlL0uSLF26NKtWrVq74PeiRYvy+c9//jF/ziOPPJK3vvWt+djHPpaddtpp67xB66jWs5kxs2bNapuz6NQ2638dljzvDcnLfr/rSgAAAKATt99+++Nm1ExEc+bMyZlnnpl999137bELLrggBxxwQGbPnj30dc4888zMnj17s16zPut736vq5tbaJvvgzEjqyttv6LoCAAAA4Enwjne8I3vsscdjjh1++OHZZZddNus6r3zlK/OsZz1ra5a22QRJAAAAACP04he/+HHH9ttvv82+zrotc10Y6WLbVXVEVd1RVXdV1anreX5OVS2vqgWDx2+Psh4AAAAAnriRzUiqqqlJ/jLJryVZkmReVX22tXbbOqd+urV2yqjqAAAAAGDrGOWMpEOS3NVa+3Zr7SdJLkly9Aj/PAAAAABGaJRB0tOTfHfc/pLBsXW9qaq+UVWXVdUz1nehqvrdqppfVfOXL18+iloBAAAA2ISRrpE0hM8l2be19vwkX0py0fpOaq39dWttVmtt1rqrnAMAAAA8UUuWLMnRRx+d/fbbL89+9rPze7/3e/nJT36SJLnhhhvy2te+NoccckiOPPLIjivdNowySFqaZPwMoxmDY2u11la01h4Z7H4syQtHWA8AAADAWq21vPGNb8yv//qvZ9GiRbnzzjuzcuXK/PEf/3Fuu+22nHHGGbngggty00035Yorrui63G3CyBbbTjIvyX5VNTNjAdKxSX5z/AlVtU9r7d7B7lFJbh9hPQAAAMC26p9OTf79m1v3mnsfmPynP9vg09dcc02mT5+et73tbUmSqVOn5txzz83MmTNTVamqHHnkkZk6dWrOOOOMHHPMMTnxxBPXhk9Jcvzxx+ctb3lLvva1r2WnnXbKH/3RH2Xx4sU58sgjs3DhwqxatSqnnnpqrrvuujzyyCM5+eST8/a3vz3XXXdd5s6duzagmjt3blauXJkzzzwzs2fPzty5czNr1qycccYZOe+887Jy5cokyTnnnJNLL700jzzySN7whjfkrLPO2rrv2SaMbEZSa+2nSU5J8sWMBUSXttZuraoPVNVRg9P+a1XdWlVfT/Jfk8wZVT0AAAAA491666154Qsf2xy1884755nPfGbmzZuX7bffPt/85jdz9dVX513velfuvffe/NZv/VYuvPDCJMn999+fG2+8Ma973esyZcqUtNYe92f8zd/8TXbZZZfMmzcv8+bNy0c/+tHcfffdQ9W3bNmyfPnLX167f9VVV2XRokW56aabsmDBgtx888254YYbnvgb8ASMckZSWmtXJrlynWPvG7d9WpLTRlkDAAAA0AMbmTnUhV133XXtbKS99torr3jFKzJv3rwcddRROemkk7J8+fJ85jOfyZve9KZst912mTFjRq6++urHXeeqq67KN77xjVx22WVJxsKnRYsWZfvtt89XvvKVHHTQQUmS5cuX53d+53ce89qzzz47p59+eo477ri117rqqqvyghe8IEmycuXKLFq0KIcddtgo34rHGGmQBAAAALCteu5zn7s24FnjgQceyHe+85286EUv2uDrTjzxxHzqU5/KJZdckk984hNJkmOOOSaf+9zncsABB2T16tWZMmWsCay1lvPPPz+HH374Y65x3XXX5eUvf/njWtvWWLx4cRYuXJjzzz9/7bHWWk477bS8/e1v37K/+Bbo+lPbAAAAADrxqle9Kj/+8Y9z8cUXJ0lWrVqVP/zDP8ycOXPyile8Ip/+9KezatWqLF++PDfccEMOOeSQJMmcOXNy3nnnJRkLo5Jkxx13zOWXX56FCxfmyit/1px1+OGH5yMf+UgeffTRJMmdd96ZBx98cJO1nXXWWY9b/+jwww/Pxz/+8bWB09KlS7Ns2bItfBc2jxlJAAAAwKRUVbn88stz0kkn5eyzz87q1avz2te+Nn/6p3+a7bbbLjfeeGOe//znZ+rUqTnnnHOy9957J0n22muv7L///msX3N6Y3/7t387ixYtz8MEHp7WWPfbYI//4j/+4ydfNmDHjcS1rr3nNa3L77bfn0EMPTZLstNNO+dSnPpU999zzCfztn5ha30JQ27JZs2a1+fPnd10GAAAAsIVuv/327L///l2Xsdl+/OMf58ADD8wtt9ySXXbZpetyNtv63vequrm1NmtTr9XaBgAAADCkq6++Ovvvv3/e+c539jJE2lJa2wAAAACG9OpXvzr33HNP12V0xowkAAAAoDN9W3Kn77b0/RYkAQAAAJ2YPn16VqxYIUx6krTWsmLFikyfPv0JX0NrGwAAANCJGTNmZMmSJVm+fHnXpUwa06dPz4wZM57w6wVJAAAAQCemTZuWmTNndl0Gm0FrGwAAAABDESQBAAAAMBRBEgAAAABDqb6tjF5Vy5Pc03UdW8nTkny/6yLohLGfvIz95GTcJy9jP3kZ+8nL2E9exn7ymihj/6zW2h6bOql3QdJEUlXzW2uzuq6DJ5+xn7yM/eRk3CcvYz95GfvJy9hPXsZ+8ppsY6+1DQAAAIChCJIAAAAAGIogqVt/3XUBdMbYT17GfnIy7pOXsZ+8jP3kZewnL2M/eU2qsbdGEgAAAABDMSMJAAAAgKEIkgAAAAAYiiCpA1V1RFXdUVV3VdWpXdfD1ldVi6vqm1W1oKrmD47tVlVfqqpFg6+7Do5XVf3PwffDN6rq4G6rZ3NU1cerallVLRx3bLPHuqreOjh/UVW9tYu/C5tnA2N/ZlUtHdz7C6rqteOeO20w9ndU1eHjjvud0DNV9YyquraqbquqW6vq9wbH3fsT2EbG3X0/wVXV9Kq6qaq+Phj7swbHZ1bVvwzG8dNVtf3g+M8N9u8aPL/vuGut93uCbdNGxv7Cqrp73H1/0OC4n/cTTFVNraqvVdUVg333fZK01jyexEeSqUn+Ncl/TLJ9kq8neW7XdXls9XFenORp6xz7iySnDrZPTfLng+3XJvmnJJXkJUn+pev6PTZrrA9LcnCShU90rJPsluTbg6+7DrZ37frv5vGExv7MJH+0nnOfO/h5/3NJZg5+D0z1O6GfjyT7JDl4sP2UJHcOxti9P4EfGxl39/0Efwzu3Z0G29OS/MvgXr40ybGD43+V5B2D7ZOS/NVg+9gkn97Y90TXfz+PJzT2FyZ583rO9/N+gj2S/EGSv0tyxWDffd+aGUkdOCTJXa21b7fWfpLkkiRHd1wTT46jk1w02L4oya+PO35xG/PVJE+tqn26KJDN11q7Icl96xze3LE+PMmXWmv3tdZ+kORLSY4YffVsiQ2M/YYcneSS1tojrbW7k9yVsd8Hfif0UGvt3tbaLYPtHyW5PcnT496f0DYy7hvivp8gBvfuysHutMGjJXllkssGx9e959f8LLgsyauqqrLh7wm2URsZ+w3x834CqaoZSV6X5GOD/Yr7PonWti48Pcl3x+0vycb/I4R+akmuqqqbq+p3B8f2aq3dO9j+9yR7DbZ9T0w8mzvWvgcmllMG09k/vqa1KcZ+whpMXX9Bxv6V2r0/Sawz7on7fsIbtLcsSLIsYyHAvyb5YWvtp4NTxo/j2jEePH9/kt1j7Htp3bFvra257/9kcN+fW1U/Nzjmvp9Yzkvy7iSrB/u7x32fRJAEo/Ky1trBSf5TkpOr6rDxT7axeY4b+9cMJghjPel8JMmzkxyU5N4kH+q2HEapqnZK8pkk/6219sD459z7E9d6xt19Pwm01la11g5KMiNjswme03FJPEnWHfuqOiDJaRn7HnhRxtrV3tNhiYxAVR2ZZFlr7eaua9kWCZKefEuTPGPc/ozBMSaQ1trSwddlSS7P2H9wfG9Ny9rg67LB6b4nJp7NHWvfAxNEa+17g//gXJ3ko/nZ1GVjP8FU1bSMhQl/21r7h8Fh9/4Et75xd99PLq21Hya5NsmhGWtb2m7w1PhxXDvGg+d3SbIixr7Xxo39EYNW19ZaeyTJJ+K+n4hemuSoqlqcsRbkVyb5H3HfJxEkdWFekv0Gq71vn7GFuD7bcU1sRVW1Y1U9Zc12ktckWZixcV7zCQ1vTfJ/BtufTXLi4FMeXpLk/nGtEfTT5o71F5O8pqp2HbREvGZwjJ5ZZ32zN2Ts3k/Gxv7YwSd6zEyyX5Kb4ndCLw3WPPibJLe31j487in3/gS2oXF33098VbVHVT11sL1Dkl/L2BpZ1yZ58+C0de/5NT8L3pzkmsEsxQ19T7CN2sDYf2vcPxpUxtbIGX/f+3k/AbTWTmutzWit7Zuxn9PXtNaOj/s+SbLdpk9ha2qt/bSqTsnYD46pST7eWru147LYuvZKcvnY75Vsl+TvWmtfqKp5SS6tqt9Kck+StwzOvzJjn/BwV5IfJ3nbk18yT1RV/e8ks5M8raqWJHl/kj/LZox1a+2+qjo7Y//nIkk+0FobdhFnOrKBsZ9dYx8B3DL26Y1vT5LW2q1VdWmS25L8NMnJrbVVg+v4ndA/L01yQpJvDtbNSJLT496f6DY07se57ye8fZJcVFVTM/YP8Ze21q6oqtuSXFJVH0zytYwFjRl8/WRV3ZWxD2U4Ntn49wTbrA2N/TVVtUfGPp1tQZL/Mjjfz/uJ7z1x36fGQjIAAAAA2DitbQAAAAAMRZAEAAAAwFAESQAAAAAMRZAEAAAAwFAESQAAAAAMRZAEAExYVbVynf05VXVBV/UAAPSdIAkAAACAoQiSAIBJqar2raprquobVfXlqnrm4PiFVbWkqqYO9t9RVa2q9h3s/+equqmqFlTV/xp33sqqOreqbh1cb4/1/Jlfqapbqur/VdXLBsdmV9X9g+stqKqlVXXm4LmDquqrgxovr6pdq2q7qppXVbMH5/z3qvqTwfbiqnraYPtTVbVwtO8iADDZCJIAgIlsh3EBzYIkHxj33PlJLmqtPT/J3yb5n+OeW5rk8MH20UnuSpKq2j/JMUle2lo7KMmqJMcPztsxyfzW2vOSXJ/k/eup59WttYOTvCHJ+VW10+D4V1prBw2uee648y9O8p5Bjd9M8v7W2k+TzEnykap6dZIjkpw1/g+pqgOTHLDptwcAYPNs13UBAAAj9NAgnEkytkZSklmD3UOTvHGw/ckkfzHudZ9MckJVfSfJoiQzBsdfleSFSeZVVZLskGTZ4LnVST492P5Ukn9YTz2vr6ozBtv7JnnBhgqvql2SPLW1dv3g0EVJ/j5JWmu3VtUnk1yR5NDW2k/WefkHMxZk/cmGrg8A8EQIkgAAHu/fk0xL8q4k/yPJrw6OV8ZmMZ02xDXa4w60dlmSy5Kkqq7bwhoPTPLDJHuuc/xXkqxM8vUtvD4AwONobQMAJqsbkxw72D4+yVfWef4TSfZsrd0y7tiXk7y5qvZMkqraraqeNXhuSpI3D7Z/M8n/XfcPrKp9Bl9nJfnFJF/bUHGttfuT/KCqXj44dELGWuZSVW9MsluSwzLWIvfUcS89M8n7NnRdAIAtYUYSADBZvTPJJ6rqXUmWJ3nb+Cdba59P8vl1jt02aE27qqqmJHk0yclJ7knyYJJDBs8vy9haSuv6h6raMWNrKx3XWls5aJHbkLcm+auq+g9Jvp3kbYPFtP8syataa9+tqgsyNmvqrYPX/Etr7V/XLA4OALA1VWuPm3UNAMBmqqqVrbWdNn0mAEB/aW0DAAAAYChmJAEAAAAwFDOSAAAAABiKIAkAAACAoQiSAAAAABiKIAkAAACAoQiSAAAAABjK/wflZLhqltYgxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history_fields(history=h, fields=['loss', 'accuracy', 'binary_accuracy'], save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = np.array(h['val_acc'])\n",
    "ac.argmax(), ac.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(model_directory + 'train_data.csv', train_data, delimiter=';')\n",
    "np.savetxt(model_directory + 'test_data.csv', test_data, delimiter=';')\n",
    "np.savetxt(model_directory + 'train_labels.csv', train_labels, delimiter=';')\n",
    "np.savetxt(model_directory + 'test_labels.csv', test_labels, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(h, open(model_directory + 'history.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = model_directory + 'last_model.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(file_name, custom_objects={'exploss': exploss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_directory + 'history.json') as f:\n",
    "    h = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkrHtfD4glIL"
   },
   "source": [
    "0. Сделать датасет поменьше\n",
    "1. Поменять кодирующую матрицу Хэмминга (генерирующую - g.txt) -> Попробовать потренировать\n",
    "2. Прочитать статью Бернштейна и оттуда перенять архитектуру\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xhXimS4dzb-A"
   },
   "source": [
    "1. смотреть насколько маски ошибки отличаются от предикта\n",
    "2. гиперпараметры (генеративная матрица, количество слоев, что предсказывается)\n",
    "3. напомнить про ЛСТМ\n",
    "4. попробовать GRU\n",
    "5. добавлять 20 ошибо, а не в каждый бит (случайно)\n",
    "6. генерить не первае 2**16, а рандомные слова"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "hamming-codes.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
